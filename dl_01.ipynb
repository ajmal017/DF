{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "import util.performance_metrics as pm\n",
    " \n",
    "reload(pm)\n",
    "\n",
    "url =  \"https://raw.githubusercontent.com/xuda1979/DF/master/sp500_companies/data/constituents.csv\"\n",
    "df_symbols =pd.read_csv('./sp500_companies/data/constituents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_symbols.head()\n",
    "all_symbols = list(df_symbols['Symbol'].unique())\n",
    "all_symbols.append('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AGN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BHGE: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BBT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: 1d data not available for startTime=-2208988800 and endTime=1609449511. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBG: 1d data not available for startTime=-2208988800 and endTime=1609449516. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CELG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DWDP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: 1d data not available for startTime=-2208988800 and endTime=1609449541. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: 1d data not available for startTime=-2208988800 and endTime=1609449569. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HRS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JEC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LUK: 1d data not available for startTime=-2208988800 and endTime=1609449607. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KORS: 1d data not available for startTime=-2208988800 and endTime=1609449622. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCLN: 1d data not available for startTime=-2208988800 and endTime=1609449660. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RTN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TMK: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UTX: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCN: 1d data not available for startTime=-2208988800 and endTime=1609449738. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: 1d data not available for startTime=-2208988800 and endTime=1609449744. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Import yfinance\n",
    "import yfinance as yf  \n",
    " \n",
    "# Get the data for the stock Apple by specifying the stock ticker, start date, and end date\n",
    "data_all =pd.DataFrame({})\n",
    "for symbol in all_symbols:\n",
    "    \n",
    "    data = yf.download(symbol)#,'2016-01-01','2018-01-01')\n",
    "    data['Symbol'] = symbol\n",
    "    if(len(data)>0):\n",
    "        data_all = pd.concat([data_all,data])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "vix=yf.download('^VIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>22.469999</td>\n",
       "      <td>22.830000</td>\n",
       "      <td>21.389999</td>\n",
       "      <td>21.530001</td>\n",
       "      <td>21.530001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>22.110001</td>\n",
       "      <td>22.120001</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>21.610001</td>\n",
       "      <td>23.719999</td>\n",
       "      <td>20.990000</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>22.580000</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>22.410000</td>\n",
       "      <td>22.770000</td>\n",
       "      <td>22.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>22.990000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>21.240000</td>\n",
       "      <td>22.610001</td>\n",
       "      <td>22.610001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7812 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close  Volume\n",
       "Date                                                                     \n",
       "1990-01-02  17.240000  17.240000  17.240000  17.240000  17.240000       0\n",
       "1990-01-03  18.190001  18.190001  18.190001  18.190001  18.190001       0\n",
       "1990-01-04  19.219999  19.219999  19.219999  19.219999  19.219999       0\n",
       "1990-01-05  20.110001  20.110001  20.110001  20.110001  20.110001       0\n",
       "1990-01-08  20.260000  20.260000  20.260000  20.260000  20.260000       0\n",
       "...               ...        ...        ...        ...        ...     ...\n",
       "2020-12-24  22.469999  22.830000  21.389999  21.530001  21.530001       0\n",
       "2020-12-28  22.110001  22.120001  21.150000  21.700001  21.700001       0\n",
       "2020-12-29  21.610001  23.719999  20.990000  23.080000  23.080000       0\n",
       "2020-12-30  22.580000  23.150000  22.410000  22.770000  22.770000       0\n",
       "2020-12-31  22.990000  23.250000  21.240000  22.610001  22.610001       0\n",
       "\n",
       "[7812 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>1.483333</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>1.491789</td>\n",
       "      <td>446400.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-06</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>6.882812</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>1.507011</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-07</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>7.015625</td>\n",
       "      <td>6.945312</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.515469</td>\n",
       "      <td>164800.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.109375</td>\n",
       "      <td>6.984375</td>\n",
       "      <td>7.093750</td>\n",
       "      <td>1.535765</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0 1970-01-02  6.851562  6.890625  6.843750  6.851562   1.483333   72000.0   \n",
       "1 1970-01-05  6.859375  6.898438  6.859375  6.890625   1.491789  446400.0   \n",
       "2 1970-01-06  6.890625  6.960938  6.882812  6.960938   1.507011  176000.0   \n",
       "3 1970-01-07  6.960938  7.015625  6.945312  7.000000   1.515469  164800.0   \n",
       "4 1970-01-08  7.000000  7.109375  6.984375  7.093750   1.535765  304000.0   \n",
       "\n",
       "  Symbol  \n",
       "0    MMM  \n",
       "1    MMM  \n",
       "2    MMM  \n",
       "3    MMM  \n",
       "4    MMM  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = list(data_all['Symbol'].unique())\n",
    "\n",
    "data_all.reset_index(inplace=True)\n",
    "\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_date = '2015-01-15'\n",
    "training_end_date = '2020-09-30'\n",
    "mask = data_all['Date'] >= training_start_date\n",
    "mask &= data_all['Date'] <= training_end_date\n",
    "\n",
    "data_training= data_all[mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_filter(df, start_date, end_date):\n",
    "    mask = df['Date'] >=  start_date\n",
    "    mask &= df['Date'] <= end_date\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.85042934e-04 7.44584306e-06]\n",
      " [7.44584306e-06 3.88371563e-04]]\n"
     ]
    }
   ],
   "source": [
    "def covariance(df, date, symbols, history):\n",
    "    df_recent = pd.DataFrame({})\n",
    "    dates = list(df['Date'].unique())\n",
    "    dates.sort()\n",
    "    df_recent['Date']= dates[-(history+1):-1]\n",
    "    for symbol in symbols:\n",
    "        mask = df['Symbol'] == symbol\n",
    " \n",
    "        if all([date in list(df[mask]['Date'].unique()) for date in dates[-(history+1):-1]]):\n",
    "            #print(df[mask]['Close'][-(history+1):-1])\n",
    "            df_recent[symbol] = df[mask]['Close'].to_list()[-(history+1):-1]\n",
    "    df_return = pd.DataFrame({})\n",
    "    df_return['Date'] = df_recent['Date']\n",
    "    for symbol in df_recent.columns:\n",
    "        if symbol !='Date':\n",
    "            #print(symbol,df_recent[symbol].div(df_recent[symbol].shift(1)))\n",
    "            df_return[symbol] = df_recent[symbol].div(df_recent[symbol].shift(1))\n",
    "    return df_return[1:].set_index('Date').cov() \n",
    " \n",
    "            \n",
    "symbols = ['AAPL', 'MMM']\n",
    "df_cov = covariance(data_training, list(data_training['Date'].unique())[-1], symbols, 10)\n",
    "cov=df_cov.to_numpy() \n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.0006603349124938092\n",
      "            Iterations: 2\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-988-e88c3116b488>:11: OptimizeWarning: Unknown solver options: gtol\n",
      "  res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25038093, 1.24961907])"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(x):\n",
    "    l = len(x)\n",
    "    assert l == cov.shape[0]\n",
    "    return x.dot(cov.dot(x))\n",
    "\n",
    "def constraint(x):\n",
    "    return np.atleast_1d(np.sum(np.abs(x)) - 1.5)\n",
    "\n",
    " \n",
    "bounds=[[0, 1], [1, 2]]\n",
    "res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n",
    "res.x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def portfolio_optimization(cov, k):        \n",
    " \n",
    "    assert 2*k == cov.shape[0]\n",
    "    def objective(x):\n",
    "        return x.dot(cov.dot(x))\n",
    "\n",
    "    def constraint(x):\n",
    "        return np.atleast_1d(np.sum(np.abs(x))-1)\n",
    "    x0 = [1/(2*k)]*k+[-1/(2*k)]*k\n",
    "    x0 = np.array(x0)\n",
    "    bounds = []\n",
    "    for i in range(k):\n",
    "        bounds.append([1/(4*k),1/k])\n",
    "    for i in range(k):\n",
    "        bounds.append([-1/k, -1/(4*k)])\n",
    "        \n",
    "    res=optimize.minimize(objective, x0, constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': False}, bounds=bounds )\n",
    "    s= sum(np.abs(res.x))\n",
    "    return res.x/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genearte DataFrames of various returns for each symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training_return = {}\n",
    " \n",
    "for symbol in symbols:\n",
    "#     print(symbol)\n",
    "    mask = data_training['Symbol'] == symbol\n",
    "    data_training_return[symbol] = pd.DataFrame({})\n",
    "    data_training_return[symbol]['Date'] = data_training[mask]['Date']\n",
    "    \n",
    "    data_training_return[symbol]['close_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Close'].shift(1))-1  \n",
    "    data_training_return[symbol]['open_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Open'] )-1\n",
    "    data_training_return[symbol]['close_open_return']  = data_training[mask]['Open'].div(data_training[mask]['Close'].shift(1) )-1\n",
    "    data_training_return[symbol]['vwap_open_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['High'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Low'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Close'].shift(1))-1\n",
    "    \n",
    "    data_training_return[symbol]['vwap_close_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open']+ \\\n",
    "                                                                                        data_training[mask]['High']+ \\\n",
    "                                                                                        data_training[mask]['Low']+ \\\n",
    "                                                                                        data_training[mask]['Close'])-1\n",
    "    \n",
    "    \n",
    "    data_training_return[symbol].fillna(0, inplace=True)\n",
    "    data_training_return[symbol].reset_index(inplace=True,drop=True)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = data_training_return['SPY']['close_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y =  data_training_return[symbol][mask]['close_close_return'] \n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_here = data_training_return['SPY'][mask]['close_close_return'] \n",
    "        X_here = np.expand_dims(X_here, axis=1)\n",
    "       # print(X_here.shape, y.shape, symbol)\n",
    "        if X_here.shape[0] == len(dates_X):\n",
    "            reg = LinearRegression().fit(X_here, y)\n",
    "            reg_map[symbol] = reg\n",
    " \n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade at open using pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= 0.0003\n",
    "\n",
    "\n",
    "\n",
    "k= 1\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['close_open_return'].to_numpy()\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "pm.Performance(result, c)\n",
    "pm.VIX(result,'Open')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using vwap open return instead of close open return\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k= 1\n",
    "c=0.0003\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['vwap_open_return'].to_numpy()\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['vwap_open_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "pm.Performance(result, c)\n",
    "pm.VIX(result,'Open')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade at close using pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.0032214814630648785\n",
      "Sharp ratio:  1.2048526167398115\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                 Least Squares   F-statistic:                  0.005290\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):              0.942\n",
      "Time:                        23:04:14   Log-Likelihood:                 436.33\n",
      "No. Observations:                 250   AIC:                            -868.7\n",
      "Df Residuals:                     248   BIC:                            -861.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0042      0.006      0.732      0.465      -0.007       0.015\n",
      "Close      -1.394e-05      0.000     -0.073      0.942      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      115.975   Durbin-Watson:                   2.247\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6994.849\n",
      "Skew:                          -0.934   Prob(JB):                         0.00\n",
      "Kurtosis:                      28.846   Cond. No.                         63.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fef9a104c70>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k=1\n",
    "c=0.0003\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-250:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['vwap_close_return']\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['vwap_close_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list) and index+1<len(testing_dates): \n",
    "            try:\n",
    "                symbol = error_list[j][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                symbol = error_list[-j-1][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "\n",
    " \n",
    " \n",
    "pm.Performance(result,c)\n",
    "pm.VIX(result,'Close')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Reverse Effect at opening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close open error as a regressor at opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_open_close = data_training_return['SPY']['open_close_return'] \n",
    "X_close_open = data_training_return['SPY']['open_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map_reverse = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y_open_close =  data_training_return[symbol][mask]['open_close_return']\n",
    "#         y_open_close = np.expand_dims(y_open_close, axis=1)\n",
    "        y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "        y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_open_close = data_training_return['SPY'][mask]['open_close_return'] \n",
    "        X_open_close = np.expand_dims(X_open_close, axis=1)\n",
    "        \n",
    "        X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "        X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "        \n",
    "        if symbol in reg_map:\n",
    "            pred_close_open = reg_map[symbol].predict(X_close_open)\n",
    "            pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "            error_close_open = y_close_open-pred_close_open\n",
    "  \n",
    "            X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    " \n",
    "            if len(X)>0 and X.shape[0] == len(y_open_close):\n",
    "                reg = LinearRegression().fit(X, y_open_close)\n",
    "                reg_map_reverse[symbol] = reg\n",
    " \n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade at Open(close-open error as regressor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.003420394518567898\n",
      "Sharp ratio:  4.3365644254001605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.Performance at 0x7fcff31e7b20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 0.0006\n",
    "k= 5\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "result.head()\n",
    "\n",
    " \n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    " \n",
    "        \n",
    "        if symbol in reg_map and symbol in reg_map_reverse and symbol !='SPY' and reg_map_reverse[symbol].coef_[1] < 0:\n",
    "  \n",
    "\n",
    "   \n",
    "\n",
    " \n",
    "#             try:\n",
    " \n",
    "            mask = data_training_return[symbol]['Date'] == date     \n",
    "            y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "            y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "            mask = data_training_return['SPY']['Date'] == date     \n",
    "            X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "            X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "            \n",
    "            X_open_close =  np.zeros([len(X_close_open),1])\n",
    "\n",
    "            if X_open_close.shape == X_close_open.shape == y_close_open.shape:\n",
    "\n",
    "                pred_close_open = reg_map[symbol].predict(X_close_open)\n",
    "                pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "                error_close_open = y_close_open-pred_close_open\n",
    "                \n",
    "                X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    "#                 print(X.shape)\n",
    "\n",
    "                pred = reg_map_reverse[symbol].predict(X)\n",
    "\n",
    "                error_map[pred[0]] = symbol\n",
    "#             except:\n",
    "#                 pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "            \n",
    "\n",
    "pm.Performance(result, c)\n",
    " \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trade at Close(open close error as regressor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87633934 -0.03968184]]\n",
      "[[1.20186789 0.02018615]]\n",
      "[[0.89871129 0.11020738]]\n",
      "[[0.9412648  0.02656301]]\n",
      "[[1.00942267 0.04549461]]\n",
      "[[ 1.31440331 -0.02069873]]\n",
      "[[ 1.13812032 -0.09489471]]\n",
      "[[1.21766337 0.05103626]]\n",
      "[[0.79390771 0.03257613]]\n",
      "[[ 1.87635525 -0.03937646]]\n",
      "[[0.65856373 0.01670917]]\n",
      "[[ 1.40667812 -0.04010685]]\n",
      "[[ 0.92218792 -0.03010474]]\n",
      "[[1.12514427 0.08901187]]\n",
      "[[0.93258187 0.06554611]]\n",
      "[[1.05797977 0.07961114]]\n",
      "[[ 0.97789008 -0.02376775]]\n",
      "[[ 1.17862203 -0.03620403]]\n",
      "[[0.52694646 0.0042412 ]]\n",
      "[[1.09886982 0.05027293]]\n",
      "[[ 1.17751209 -0.08241091]]\n",
      "[[ 0.91498046 -0.02096731]]\n",
      "[[1.02736076 0.04500753]]\n",
      "[[0.2194318  0.01877074]]\n",
      "[[ 0.74568733 -0.01428044]]\n",
      "[[ 1.1856343  -0.00453171]]\n",
      "[[1.19146264 0.0154215 ]]\n",
      "[[ 0.66754668 -0.0844241 ]]\n",
      "[[1.36654121 0.08950003]]\n",
      "[[0.23248536 0.0229671 ]]\n",
      "[[ 1.27155955 -0.03676953]]\n",
      "[[0.21354501 0.02813489]]\n",
      "[[ 0.91483252 -0.0396084 ]]\n",
      "[[ 1.13782097 -0.0202112 ]]\n",
      "[[0.59833729 0.05206952]]\n",
      "[[0.26393502 0.01378676]]\n",
      "[[ 1.27234965 -0.05771015]]\n",
      "[[0.77811097 0.03237747]]\n",
      "[[1.104159   0.05515931]]\n",
      "[[0.90665148 0.00286883]]\n",
      "[[ 1.08374652e+00 -4.63066861e-04]]\n",
      "[[ 1.26237736 -0.03988509]]\n",
      "[[ 1.01504292 -0.04251216]]\n",
      "[[0.79430532 0.04341334]]\n",
      "[[0.8138934  0.06265867]]\n",
      "[[ 1.41218204 -0.02307504]]\n",
      "[[ 0.50823262 -0.06139982]]\n",
      "[[ 1.34563686 -0.06525385]]\n",
      "[[ 1.34561734 -0.03809986]]\n",
      "[[ 1.3769507  -0.00395235]]\n",
      "[[0.81285084 0.00188311]]\n",
      "[[ 0.80537914 -0.00551106]]\n",
      "[[ 0.80853316 -0.02029145]]\n",
      "[[ 0.59398851 -0.03270526]]\n",
      "[[ 1.30598787 -0.00648519]]\n",
      "[[ 0.98578413 -0.04412734]]\n",
      "[[ 0.69404006 -0.07518606]]\n",
      "[[ 0.41913844 -0.01271373]]\n",
      "[[0.9681108  0.02949889]]\n",
      "[[0.95355163 0.02965152]]\n",
      "[[ 1.47269016 -0.12722775]]\n",
      "[[0.76813302 0.03287774]]\n",
      "[[ 7.58847472e-01 -1.20540673e-04]]\n",
      "[[1.09261486 0.09051489]]\n",
      "[[1.03603778 0.02009927]]\n",
      "[[ 1.26979045 -0.01827489]]\n",
      "[[0.77397481 0.02348298]]\n",
      "[[ 1.23701367 -0.03137238]]\n",
      "[[ 1.41719179 -0.04639574]]\n",
      "[[0.53021149 0.03529092]]\n",
      "[[ 0.9255317  -0.01056826]]\n",
      "[[0.74733603 0.06550465]]\n",
      "[[1.48263179 0.01646171]]\n",
      "[[ 0.78076309 -0.0013683 ]]\n",
      "[[1.05040964 0.00967651]]\n",
      "[[ 0.98123772 -0.01643505]]\n",
      "[[ 0.4529625  -0.00372895]]\n",
      "[[1.23096441 0.04081737]]\n",
      "[[0.87049115 0.07338739]]\n",
      "[[1.05720518 0.00737255]]\n",
      "[[1.02625923 0.12718636]]\n",
      "[[ 1.40889759 -0.01978503]]\n",
      "[[ 0.53691789 -0.05699376]]\n",
      "[[1.03237358 0.01499707]]\n",
      "[[0.40861261 0.00264014]]\n",
      "[[0.84544504 0.02100935]]\n",
      "[[ 0.88625158 -0.04853896]]\n",
      "[[ 1.24182073 -0.01681168]]\n",
      "[[ 1.56524611 -0.00738774]]\n",
      "[[ 0.828783   -0.08537772]]\n",
      "[[2.19085    0.00382607]]\n",
      "[[ 0.97993858 -0.07028052]]\n",
      "[[ 0.71220461 -0.03483804]]\n",
      "[[ 0.75060471 -0.0784135 ]]\n",
      "[[0.48834066 0.03638977]]\n",
      "[[ 0.84858439 -0.03552249]]\n",
      "[[ 1.32157214 -0.04825949]]\n",
      "[[ 0.81336553 -0.04299587]]\n",
      "[[0.84711532 0.10995459]]\n",
      "[[1.0672979  0.10114249]]\n",
      "[[ 1.5702916  -0.12862911]]\n",
      "[[ 1.2568153  -0.02939413]]\n",
      "[[1.04281177 0.06347346]]\n",
      "[[ 0.73148606 -0.01687932]]\n",
      "[[ 0.21121323 -0.0107778 ]]\n",
      "[[0.51663625 0.03010044]]\n",
      "[[ 1.07146066 -0.13295445]]\n",
      "[[0.59028635 0.04189321]]\n",
      "[[0.91229273 0.01032327]]\n",
      "[[ 1.2929606  -0.02698733]]\n",
      "[[ 0.53961679 -0.00340043]]\n",
      "[[ 1.40027581 -0.02411358]]\n",
      "[[ 1.32923842 -0.05174993]]\n",
      "[[0.1622045  0.05137131]]\n",
      "[[0.74741168 0.01308043]]\n",
      "[[1.15681505 0.02541624]]\n",
      "[[0.73466124 0.03591155]]\n",
      "[[ 0.67290525 -0.02574499]]\n",
      "[[ 0.51203738 -0.04450947]]\n",
      "[[ 1.17025981 -0.0119614 ]]\n",
      "[[1.13896685 0.03586765]]\n",
      "[[0.87892697 0.00262513]]\n",
      "[[ 1.04287654 -0.01813919]]\n",
      "[[0.85849076 0.04008008]]\n",
      "[[0.70229512 0.05829814]]\n",
      "[[0.72380267 0.00831109]]\n",
      "[[ 1.19066377 -0.0300285 ]]\n",
      "[[ 1.11733136 -0.09195893]]\n",
      "[[ 0.75991983 -0.01307754]]\n",
      "[[ 1.56105611 -0.09945808]]\n",
      "[[ 0.47516074 -0.00861988]]\n",
      "[[ 1.07709524 -0.05017741]]\n",
      "[[0.93764396 0.03675253]]\n",
      "[[0.88286873 0.0410508 ]]\n",
      "[[ 1.0255831  -0.00690055]]\n",
      "[[ 0.8705577  -0.05778158]]\n",
      "[[0.95393133 0.00969342]]\n",
      "[[0.23614481 0.09106887]]\n",
      "[[ 1.10273686e+00 -1.09475931e-03]]\n",
      "[[0.20873346 0.0393076 ]]\n",
      "[[0.206015   0.06120847]]\n",
      "[[ 0.68730102 -0.03182801]]\n",
      "[[1.06506461 0.05153983]]\n",
      "[[ 1.46600483 -0.0359972 ]]\n",
      "[[1.22549102 0.05678937]]\n",
      "[[1.24248174 0.01243303]]\n",
      "[[0.98897264 0.01935278]]\n",
      "[[8.55843589e-01 9.49780418e-05]]\n",
      "[[0.20965699 0.07581115]]\n",
      "[[ 0.86196933 -0.01903191]]\n",
      "[[ 1.14553481 -0.01852374]]\n",
      "[[1.12053561 0.01693015]]\n",
      "[[0.23467721 0.02131863]]\n",
      "[[ 1.25136065 -0.03347067]]\n",
      "[[1.0729496  0.00963666]]\n",
      "[[ 0.81902443 -0.01169124]]\n",
      "[[ 0.66222485 -0.03995369]]\n",
      "[[ 0.4828098  -0.01425062]]\n",
      "[[ 0.38714082 -0.01652808]]\n",
      "[[0.90282751 0.01869691]]\n",
      "[[ 0.62759824 -0.084767  ]]\n",
      "[[ 0.22977693 -0.01945883]]\n",
      "[[0.32425756 0.04760578]]\n",
      "[[ 0.99396436 -0.00470417]]\n",
      "[[0.9846038  0.10198584]]\n",
      "[[ 0.44099796 -0.0017436 ]]\n",
      "[[ 0.93206102 -0.00603565]]\n",
      "[[1.02811458 0.0363069 ]]\n",
      "[[ 1.37815122 -0.10082451]]\n",
      "[[ 0.96756654 -0.00718434]]\n",
      "[[0.4596066  0.01215912]]\n",
      "[[ 1.08654297 -0.02852626]]\n",
      "[[ 0.87505732 -0.07367351]]\n",
      "[[ 1.2280742  -0.00584288]]\n",
      "[[0.32229906 0.01632596]]\n",
      "[[0.91579961 0.0238972 ]]\n",
      "[[ 0.93781191 -0.04678499]]\n",
      "[[ 1.23287249 -0.02947126]]\n",
      "[[ 1.31657    -0.01156999]]\n",
      "[[ 1.10809173 -0.02806858]]\n",
      "[[ 0.94999711 -0.02224939]]\n",
      "[[1.15035152 0.03193265]]\n",
      "[[1.12892229 0.02182206]]\n",
      "[[ 1.31336280e+00 -1.16482394e-03]]\n",
      "[[ 2.1263458  -0.05270657]]\n",
      "[[0.94145718 0.0522577 ]]\n",
      "[[0.90380374 0.08585173]]\n",
      "[[0.92197754 0.02130653]]\n",
      "[[0.87609877 0.00313618]]\n",
      "[[ 1.04083998 -0.032611  ]]\n",
      "[[0.4803131  0.02555242]]\n",
      "[[ 1.19697753 -0.04141421]]\n",
      "[[ 0.791005   -0.04099341]]\n",
      "[[ 0.96230549 -0.01144029]]\n",
      "[[1.04493283 0.00900042]]\n",
      "[[ 1.272631  -0.0074009]]\n",
      "[[1.17685661 0.00686171]]\n",
      "[[ 0.84872864 -0.04762646]]\n",
      "[[ 1.32875485 -0.01498069]]\n",
      "[[ 0.95869757 -0.03854133]]\n",
      "[[1.13295345 0.08374938]]\n",
      "[[ 1.07209626 -0.00566174]]\n",
      "[[0.89770383 0.0553533 ]]\n",
      "[[ 0.84936522 -0.05434506]]\n",
      "[[ 1.4210225  -0.08855409]]\n",
      "[[0.77057859 0.06862132]]\n",
      "[[ 1.51569545 -0.07454298]]\n",
      "[[1.06124262 0.04437375]]\n",
      "[[0.83347203 0.04378091]]\n",
      "[[0.8818252  0.00145462]]\n",
      "[[1.02383135 0.0381136 ]]\n",
      "[[0.52158721 0.00193498]]\n",
      "[[ 0.89810093 -0.01575664]]\n",
      "[[1.19113813 0.07736262]]\n",
      "[[ 0.65373158 -0.0081596 ]]\n",
      "[[ 1.14187878 -0.0297339 ]]\n",
      "[[ 0.8881748  -0.03322149]]\n",
      "[[ 0.8790242 -0.0771094]]\n",
      "[[0.65406901 0.11606853]]\n",
      "[[1.0441287  0.08431057]]\n",
      "[[1.1155269  0.01753216]]\n",
      "[[1.32129451 0.00651421]]\n",
      "[[1.19456659 0.0307719 ]]\n",
      "[[ 0.79239469 -0.00713333]]\n",
      "[[0.86513834 0.06070957]]\n",
      "[[ 1.04168958 -0.00149616]]\n",
      "[[ 0.95566648 -0.00441193]]\n",
      "[[0.85791817 0.03733541]]\n",
      "[[1.17437018 0.03156394]]\n",
      "[[0.93472827 0.05565221]]\n",
      "[[ 1.44479202 -0.0628908 ]]\n",
      "[[ 0.83271357 -0.05493088]]\n",
      "[[0.62163842 0.02055786]]\n",
      "[[ 0.86341582 -0.04103259]]\n",
      "[[ 0.45232149 -0.00114114]]\n",
      "[[0.62677002 0.0074082 ]]\n",
      "[[ 0.918013   -0.00392794]]\n",
      "[[1.28783814 0.00359602]]\n",
      "[[0.92070224 0.06590373]]\n",
      "[[1.11940728 0.04586109]]\n",
      "[[0.44355185 0.03976794]]\n",
      "[[ 1.27370301 -0.04914617]]\n",
      "[[0.54200374 0.02132284]]\n",
      "[[ 0.51820124 -0.01414906]]\n",
      "[[ 1.14938467 -0.06071782]]\n",
      "[[1.21668293 0.02672605]]\n",
      "[[ 0.95108316 -0.00588041]]\n",
      "[[ 0.87293983 -0.25228124]]\n",
      "[[ 0.88067427 -0.00714763]]\n",
      "[[ 0.71808617 -0.00682967]]\n",
      "[[ 1.46747662 -0.05155395]]\n",
      "[[0.92808518 0.04021588]]\n",
      "[[ 0.99994511 -0.01200797]]\n",
      "[[ 0.65879602 -0.0457649 ]]\n",
      "[[ 1.59019458 -0.01261381]]\n",
      "[[0.98584728 0.07855668]]\n",
      "[[ 0.78602561 -0.01793237]]\n",
      "[[ 0.94275468 -0.02153779]]\n",
      "[[0.96611898 0.03722068]]\n",
      "[[1.33721708 0.05421492]]\n",
      "[[1.0683582  0.02752633]]\n",
      "[[ 0.65094046 -0.0155504 ]]\n",
      "[[1.02012118 0.0261554 ]]\n",
      "[[ 1.77523119 -0.08978012]]\n",
      "[[1.22895859 0.04367805]]\n",
      "[[1.024609   0.06740212]]\n",
      "[[ 0.86099517 -0.04420287]]\n",
      "[[ 0.9536702  -0.01032035]]\n",
      "[[ 1.0536379  -0.03517649]]\n",
      "[[1.15606263 0.00513401]]\n",
      "[[0.81272704 0.01727342]]\n",
      "[[ 0.48672043 -0.02546216]]\n",
      "[[0.65416898 0.08021258]]\n",
      "[[0.77617166 0.01059431]]\n",
      "[[0.83658102 0.05946289]]\n",
      "[[0.77580667 0.05651888]]\n",
      "[[1.37016832 0.0170043 ]]\n",
      "[[0.97644654 0.01388447]]\n",
      "[[ 1.46160201 -0.04633262]]\n",
      "[[1.33480342 0.00867726]]\n",
      "[[ 1.82080551 -0.10192682]]\n",
      "[[1.24689472 0.11133619]]\n",
      "[[ 0.43047468 -0.00714792]]\n",
      "[[ 1.03946237 -0.06367672]]\n",
      "[[ 0.68930507 -0.02038279]]\n",
      "[[0.68790939 0.0787892 ]]\n",
      "[[ 0.72974803 -0.06614971]]\n",
      "[[1.09692502 0.00565541]]\n",
      "[[ 1.58857178 -0.04979664]]\n",
      "[[ 0.73897674 -0.00960189]]\n",
      "[[1.1691751  0.05876986]]\n",
      "[[0.88446749 0.01572978]]\n",
      "[[ 1.28080174 -0.02302687]]\n",
      "[[1.05756084 0.01806231]]\n",
      "[[1.17401338 0.07064121]]\n",
      "[[ 1.71894124 -0.13064913]]\n",
      "[[ 0.98641418 -0.02338206]]\n",
      "[[-0.30492239  0.00148079]]\n",
      "[[0.94800767 0.02379888]]\n",
      "[[0.90758479 0.04368433]]\n",
      "[[0.28173047 0.00664783]]\n",
      "[[0.91472987 0.07417914]]\n",
      "[[1.10328963 0.06965284]]\n",
      "[[0.26677458 0.06088831]]\n",
      "[[ 1.52952749 -0.06007211]]\n",
      "[[ 0.88342163 -0.00349349]]\n",
      "[[1.02653393 0.04355186]]\n",
      "[[ 1.17533105 -0.02386606]]\n",
      "[[ 0.84662607 -0.067812  ]]\n",
      "[[1.05282492 0.04589345]]\n",
      "[[0.78098711 0.02073226]]\n",
      "[[ 1.24371516 -0.03343838]]\n",
      "[[ 1.65994796 -0.04310171]]\n",
      "[[ 0.74251788 -0.04185787]]\n",
      "[[ 1.09764113 -0.02705705]]\n",
      "[[0.80976779 0.00502081]]\n",
      "[[ 1.17883859 -0.01931665]]\n",
      "[[0.97181106 0.07998687]]\n",
      "[[1.15095105 0.01268818]]\n",
      "[[0.93003901 0.00979517]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12969618e+00 8.20299350e-04]]\n",
      "[[0.72533604 0.06207415]]\n",
      "[[0.90331191 0.01196432]]\n",
      "[[ 1.15813342 -0.04568495]]\n",
      "[[ 0.92672348 -0.04328592]]\n",
      "[[0.55101839 0.08598244]]\n",
      "[[ 1.00349764 -0.051604  ]]\n",
      "[[ 7.84423395e-01 -5.83530074e-04]]\n",
      "[[0.71208081 0.07239722]]\n",
      "[[0.30861491 0.26097271]]\n",
      "[[ 0.52900286 -0.0888156 ]]\n",
      "[[0.96461163 0.00937016]]\n",
      "[[0.17948205 0.03016967]]\n",
      "[[ 1.33490809 -0.03141734]]\n",
      "[[1.10648118 0.00404322]]\n",
      "[[ 1.03077349 -0.01030724]]\n",
      "[[0.94641129 0.05527681]]\n",
      "[[0.3283804  0.04140402]]\n",
      "[[ 1.3488315  -0.04723728]]\n",
      "[[0.61456743 0.06349997]]\n",
      "[[ 0.85215624 -0.01185122]]\n",
      "[[0.70408654 0.02167737]]\n",
      "[[ 1.4187817 -0.0090648]]\n",
      "[[0.26181956 0.02246174]]\n",
      "[[0.36747218 0.06890689]]\n",
      "[[ 1.03862414 -0.03418474]]\n",
      "[[ 1.00264592 -0.00247819]]\n",
      "[[1.44611701e+00 9.31506665e-04]]\n",
      "[[ 1.14793148 -0.21200067]]\n",
      "[[1.12790559 0.0061275 ]]\n",
      "[[0.77604195 0.04010972]]\n",
      "[[ 1.3408859  -0.03036535]]\n",
      "[[ 1.31128872 -0.04497727]]\n",
      "[[0.36932388 0.03850791]]\n",
      "[[0.50443787 0.03952733]]\n",
      "[[ 0.98253225 -0.044861  ]]\n",
      "[[ 1.45723412 -0.05795539]]\n",
      "[[0.62930219 0.01650947]]\n",
      "[[0.75509503 0.03721595]]\n",
      "[[1.13964819 0.06822684]]\n",
      "[[1.14228587 0.04900247]]\n",
      "[[0.94999689 0.03760477]]\n",
      "[[ 0.96611553 -0.00953713]]\n",
      "[[1.17036451 0.01887754]]\n",
      "[[1.07107849 0.04123716]]\n",
      "[[1.28006579 0.05015241]]\n",
      "[[ 0.72904255 -0.00942769]]\n",
      "[[ 1.14438125 -0.0179582 ]]\n",
      "[[1.44829232 0.02957318]]\n",
      "[[ 0.9154693  -0.01479437]]\n",
      "[[0.320706   0.00500861]]\n",
      "[[0.77174775 0.03082082]]\n",
      "[[1.01503863 0.02621049]]\n",
      "[[0.57303203 0.04123282]]\n",
      "[[ 1.5890454  -0.09576701]]\n",
      "[[0.65391888 0.02516614]]\n",
      "[[0.95838406 0.01844298]]\n",
      "[[0.23551938 0.07845874]]\n",
      "[[ 0.96336723 -0.04758087]]\n",
      "[[1.10199551 0.02586355]]\n",
      "[[0.97968015 0.07748697]]\n",
      "[[ 1.35911595 -0.06744891]]\n",
      "[[0.73257787 0.03128145]]\n",
      "[[0.8502429  0.08221674]]\n",
      "[[ 1.27130552e+00 -3.77184898e-04]]\n",
      "[[ 1.03319021 -0.04039789]]\n",
      "[[0.9361904  0.06193814]]\n",
      "[[0.50819291 0.05445951]]\n",
      "[[1.16711398e+00 1.08751866e-03]]\n",
      "[[ 0.980506  -0.0499353]]\n",
      "[[ 0.89086827 -0.01980197]]\n",
      "[[1.07394618 0.0097252 ]]\n",
      "[[1.72003116 0.02803872]]\n",
      "[[ 1.1965978  -0.03702365]]\n",
      "[[ 1.22359752 -0.00346127]]\n",
      "[[ 1.22973001 -0.01353095]]\n",
      "[[0.41691107 0.01951941]]\n",
      "[[ 0.69714005 -0.03195929]]\n",
      "[[0.43778213 0.08586533]]\n",
      "[[ 1.14168448 -0.00768157]]\n",
      "[[ 0.80218806 -0.05003762]]\n",
      "[[0.94645673 0.00610835]]\n",
      "[[0.97188218 0.07516572]]\n",
      "[[0.91223821 0.06834907]]\n",
      "[[ 0.88620304 -0.00874462]]\n",
      "[[0.94996121 0.01285289]]\n",
      "[[ 0.98701868 -0.06807589]]\n",
      "[[1.16471963 0.10632412]]\n",
      "[[0.53067918 0.04721514]]\n",
      "[[ 1.09557498 -0.03401627]]\n",
      "[[ 0.6356248  -0.00188457]]\n",
      "[[ 1.02668294 -0.09474373]]\n",
      "[[ 1.16640902 -0.01570731]]\n",
      "[[1.06281665 0.05375818]]\n",
      "[[ 1.10825778 -0.01121769]]\n",
      "[[ 0.86478153 -0.03049559]]\n",
      "[[ 0.82557659 -0.01129225]]\n",
      "[[1.61847217 0.00576912]]\n",
      "[[0.78164186 0.02426844]]\n",
      "[[ 1.33968213 -0.08704394]]\n",
      "[[ 0.9198664  -0.00990734]]\n",
      "[[1.09506479 0.03978959]]\n",
      "[[0.84570172 0.02976569]]\n",
      "[[0.3503151  0.01474112]]\n",
      "[[0.96030472 0.05590764]]\n",
      "[[ 0.80822228 -0.02292449]]\n",
      "[[ 0.51942664 -0.01476696]]\n",
      "[[1.11613389 0.04835673]]\n",
      "[[1.24859078 0.02949613]]\n",
      "[[0.4928291  0.02372951]]\n",
      "[[1.00578305 0.04940428]]\n",
      "[[ 0.70874942 -0.08283728]]\n",
      "[[0.86554757 0.08332619]]\n",
      "[[ 0.64055371 -0.0090636 ]]\n",
      "[[0.87081118 0.05420037]]\n",
      "[[0.17790673 0.03269807]]\n",
      "[[ 1.22616309 -0.04579557]]\n",
      "[[ 1.47191783 -0.08782848]]\n",
      "[[ 0.93256185 -0.01659512]]\n",
      "[[ 0.7436731  -0.02198431]]\n",
      "[[1.04612986 0.05720096]]\n",
      "[[1.27925297 0.08574912]]\n",
      "[[0.81141186 0.03730646]]\n",
      "[[1.5218713  0.01573344]]\n",
      "[[0.22054821 0.0232874 ]]\n",
      "[[ 1.10292317 -0.01642392]]\n",
      "[[1.24839245 0.13921284]]\n",
      "[[1.04870347 0.01320777]]\n",
      "[[0.8692402  0.06411041]]\n",
      "[[0.77274481 0.07613115]]\n",
      "[[1.26207964 0.00851515]]\n",
      "[[0.90009482 0.0318328 ]]\n",
      "[[1.00000000e+00 4.28381481e-18]]\n"
     ]
    }
   ],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map_vwap_close_reverse = {}\n",
    "mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "X1 = data_training_return['SPY'][mask]['close_open_return'][1:].to_numpy()\n",
    "X1 = np.expand_dims(X1, axis=1)\n",
    "        \n",
    "X0 = data_training_return['SPY'][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y1 =  data_training_return[symbol][mask]['close_open_return'][1:].to_numpy()\n",
    "        y1 = np.expand_dims(y1, axis=1)\n",
    "        y0 = data_training_return[symbol][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "        y0 = np.expand_dims(y0, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if symbol in reg_map:\n",
    " \n",
    "            pred = reg_map[symbol].predict(X0)\n",
    "            pred = np.expand_dims(pred, axis=1)\n",
    "            error = y0-pred\n",
    "           # print(X1.shape, y0.shape, y1.shape, error.shape)\n",
    " \n",
    "            X = np.concatenate([X1, error], axis=1)\n",
    "         \n",
    "            #if len(dates_X)>0 and X.shape[0] == len(dates_X):\n",
    "            reg = LinearRegression().fit(X, y1)\n",
    "            reg_map_vwap_close_reverse[symbol] = reg\n",
    "            print(reg.coef_)\n",
    "\n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  -0.002447721415484358\n",
      "Sharp ratio:  -1.404564110131498\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.014\n",
      "Model:                            OLS   Adj. R-squared:                  0.010\n",
      "Method:                 Least Squares   F-statistic:                     3.532\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):             0.0614\n",
      "Time:                        23:05:54   Log-Likelihood:                 545.11\n",
      "No. Observations:                 250   AIC:                            -1086.\n",
      "Df Residuals:                     248   BIC:                            -1079.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0080      0.004     -2.159      0.032      -0.015      -0.001\n",
      "Close          0.0002      0.000      1.879      0.061   -1.12e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       71.037   Durbin-Watson:                   1.771\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              937.904\n",
      "Skew:                           0.676   Prob(JB):                    2.17e-204\n",
      "Kurtosis:                      12.392   Cond. No.                         63.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fefa94d9ac0>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 0.0003\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k= 1\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    if index+1 <len(testing_dates):\n",
    "        for symbol in symbols:\n",
    "\n",
    "\n",
    "            if symbol in reg_map and symbol in reg_map_vwap_close_reverse and symbol !='SPY':\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #             try:\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date     \n",
    " \n",
    " \n",
    "                y0 = data_training_return[symbol][mask]['vwap_close_return'].to_numpy()\n",
    "                y0 = np.expand_dims(y0, axis=1)\n",
    "        \n",
    "        \n",
    "                mask = data_training_return['SPY']['Date'] == date     \n",
    "                X0 = data_training_return['SPY'][mask]['vwap_close_return'] \n",
    "                X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "                X1 =  np.zeros([len(X0),1])\n",
    "                #print(X1.shape, y0.shape)\n",
    "                if X1.shape == y0.shape:\n",
    "\n",
    "                    pred0  = reg_map[symbol].predict(X0)\n",
    "                    pred0  = np.expand_dims(pred0, axis=1)\n",
    "                    error = y0-pred0\n",
    "                    #print(\"pred0 shape\", pred0.shape)\n",
    "                    X = np.concatenate([X1, error], axis=1)\n",
    "\n",
    "                    pred = reg_map_vwap_close_reverse[symbol].predict(X)\n",
    "                    #print(\"pred .shape\", pred.shape)\n",
    "\n",
    "                    error_map[pred[0][0]] = symbol\n",
    "    #             except:\n",
    "    #                 pass\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range(k):\n",
    "            if j< len(error_list) and index <len(testing_dates) -1:   \n",
    "                symbol = error_list[j][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                #Here use the previouse date for the return from close to open for conevnience of VIX calculation\n",
    "                result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                symbol = error_list[-j-1][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                \n",
    "\n",
    "pm.Performance(result, c)\n",
    "pm.VIX(result, 'Close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63596469]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# X, y = make_regression(n_features=4, n_informative=2,\n",
    "#                        random_state=0, shuffle=False)\n",
    "# regr = RandomForestRegressor(n_estimators=1000,max_depth=100, criterion='mae',random_state=0)\n",
    "# regr.fit(X, y)\n",
    "\n",
    "# print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYPL 2015-02-27T00:00:00.000000000\n",
      "FTV 2015-02-27T00:00:00.000000000\n",
      "HPE 2015-02-27T00:00:00.000000000\n",
      "ARNC 2015-02-27T00:00:00.000000000\n",
      "PX 2015-02-27T00:00:00.000000000\n",
      "UA 2015-02-27T00:00:00.000000000\n",
      "BHF 2015-02-27T00:00:00.000000000\n",
      "IR 2015-02-27T00:00:00.000000000\n",
      "CSRA 2015-02-27T00:00:00.000000000\n",
      "KHC 2015-02-27T00:00:00.000000000\n",
      "FOXA 2015-02-27T00:00:00.000000000\n",
      "FOX 2015-02-27T00:00:00.000000000\n",
      "SCG 2015-02-27T00:00:00.000000000\n",
      "WRK 2015-02-27T00:00:00.000000000\n",
      "PYPL 2015-03-02T00:00:00.000000000\n",
      "FTV 2015-03-02T00:00:00.000000000\n",
      "HPE 2015-03-02T00:00:00.000000000\n",
      "ARNC 2015-03-02T00:00:00.000000000\n",
      "PX 2015-03-02T00:00:00.000000000\n",
      "UA 2015-03-02T00:00:00.000000000\n",
      "BHF 2015-03-02T00:00:00.000000000\n",
      "IR 2015-03-02T00:00:00.000000000\n",
      "CSRA 2015-03-02T00:00:00.000000000\n",
      "KHC 2015-03-02T00:00:00.000000000\n",
      "FOXA 2015-03-02T00:00:00.000000000\n",
      "FOX 2015-03-02T00:00:00.000000000\n",
      "SCG 2015-03-02T00:00:00.000000000\n",
      "WRK 2015-03-02T00:00:00.000000000\n",
      "PYPL 2015-03-03T00:00:00.000000000\n",
      "FTV 2015-03-03T00:00:00.000000000\n",
      "(760, 349) (760,)\n"
     ]
    }
   ],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "c = 0\n",
    "for index, date in enumerate(dates[:-testing_length]):\n",
    "    if c>=1000:\n",
    "        break\n",
    "    if index>=history-1:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "             \n",
    " \n",
    "        if data_training[mask]['Open'].to_numpy()[0]:\n",
    "            sample_spy.append(data_training[mask]['Open'].to_numpy()[0])  \n",
    "            for symbol in symbols:\n",
    "                c +=1\n",
    "                if c>=1000:\n",
    "                    break\n",
    "                try:\n",
    "                    sample = []\n",
    "                    mask = data_training['Symbol'] == symbol\n",
    "                    mask &= data_training['Date']<date\n",
    "                    mask &= data_training['Date']>= dates[index-history+1]\n",
    "                    sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                    sample +=sample_spy\n",
    "\n",
    "\n",
    "\n",
    "                    mask = data_training_return[symbol]['Date'] == date\n",
    "\n",
    "                    r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                    if sample and r:\n",
    "                        X.append(sample)\n",
    "                        y.append(r)\n",
    "\n",
    "                except:\n",
    "                    print(symbol, date)\n",
    "    #                 print(data_training_return[symbol]['Date'] )\n",
    "    #                 raise\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-94577dfce90c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[0;32m--> 303\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    " \n",
    "regr = RandomForestRegressor(n_estimators=1000,max_depth=100, criterion='mae',random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "k=5\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "result = np.zeros(testing_length)\n",
    "print(len(dates))\n",
    "for index, date in enumerate(dates ):\n",
    " \n",
    "    if index>=len(dates)-testing_length:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "        sample_spy.append(data_training[mask]['Open'].to_numpy()[0]) \n",
    "        print(sample_spy)\n",
    "        symbol_return = {}\n",
    "        symbol_pred_return = {}\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                sample = []\n",
    "                mask = data_training['Symbol'] == symbol\n",
    "                mask &= data_training['Date']<date\n",
    "                mask &= data_training['Date']>= dates[index-history+1]\n",
    "                sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                sample +=sample_spy\n",
    "                \n",
    "\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "         \n",
    "                r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                if sample and r:\n",
    "                    X.append(sample)\n",
    "                    symbol_pred_return[symbol] = regr.predict(X)\n",
    "                    symbol_return[symbol] = r \n",
    "                \n",
    "            except:\n",
    "                print(\"Error\", symbol, date)\n",
    "#                 print(data_training_return[symbol]['Date'] )\n",
    "#                 raise\n",
    "        error_map = {}\n",
    "        for symbol in  symbol_return:\n",
    "            error_map[symbol] = symbol_return[symbol] - symbol_pred_return[symbol]\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "       # print(error_list)\n",
    "        if len(error_list)>=k:\n",
    "            for j in range(k): \n",
    "                symbol = error_list[j][1]\n",
    "                print(symbol)\n",
    "                result[index-len(dates)+testing_length] +=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "                symbol = error_list[-j-1][1]\n",
    "                result[index-len(dates)+testing_length] -=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "    X=np.array(X)\n",
    "y=np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "Performance(result, c)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
