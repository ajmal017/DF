{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "import util.performance_metrics as pm\n",
    " \n",
    "reload(pm)\n",
    "\n",
    "url =  \"https://raw.githubusercontent.com/xuda1979/DF/master/sp500_companies/data/constituents.csv\"\n",
    "df_symbols =pd.read_csv('./sp500_companies/data/constituents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_symbols.head()\n",
    "all_symbols = list(df_symbols['Symbol'].unique())\n",
    "all_symbols.append('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AGN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BHGE: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BBT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: 1d data not available for startTime=-2208988800 and endTime=1607198989. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBG: 1d data not available for startTime=-2208988800 and endTime=1607198993. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CELG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DWDP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: 1d data not available for startTime=-2208988800 and endTime=1607199020. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: 1d data not available for startTime=-2208988800 and endTime=1607199046. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HRS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JEC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LUK: 1d data not available for startTime=-2208988800 and endTime=1607199084. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KORS: 1d data not available for startTime=-2208988800 and endTime=1607199099. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCLN: 1d data not available for startTime=-2208988800 and endTime=1607199138. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RTN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TMK: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UTX: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCN: 1d data not available for startTime=-2208988800 and endTime=1607199214. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: 1d data not available for startTime=-2208988800 and endTime=1607199219. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Import yfinance\n",
    "import yfinance as yf  \n",
    " \n",
    "# Get the data for the stock Apple by specifying the stock ticker, start date, and end date\n",
    "data_all =pd.DataFrame({})\n",
    "for symbol in all_symbols:\n",
    "    \n",
    "    data = yf.download(symbol)#,'2016-01-01','2018-01-01')\n",
    "    data['Symbol'] = symbol\n",
    "    if(len(data)>0):\n",
    "        data_all = pd.concat([data_all,data])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "vix=yf.download('^VIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>17.240000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>22.639999</td>\n",
       "      <td>22.889999</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.570000</td>\n",
       "      <td>20.570000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>20.209999</td>\n",
       "      <td>20.920000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.770000</td>\n",
       "      <td>20.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>21.240000</td>\n",
       "      <td>21.879999</td>\n",
       "      <td>20.719999</td>\n",
       "      <td>21.280001</td>\n",
       "      <td>21.280001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>21.049999</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>20.790001</td>\n",
       "      <td>20.790001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7794 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close  Volume\n",
       "Date                                                                     \n",
       "1990-01-02  17.240000  17.240000  17.240000  17.240000  17.240000       0\n",
       "1990-01-03  18.190001  18.190001  18.190001  18.190001  18.190001       0\n",
       "1990-01-04  19.219999  19.219999  19.219999  19.219999  19.219999       0\n",
       "1990-01-05  20.110001  20.110001  20.110001  20.110001  20.110001       0\n",
       "1990-01-08  20.260000  20.260000  20.260000  20.260000  20.260000       0\n",
       "...               ...        ...        ...        ...        ...     ...\n",
       "2020-11-30  22.639999  22.889999  20.480000  20.570000  20.570000       0\n",
       "2020-12-01  20.209999  20.920000  20.000000  20.770000  20.770000       0\n",
       "2020-12-02  21.000000  21.250000  20.040001  21.170000  21.170000       0\n",
       "2020-12-03  21.240000  21.879999  20.719999  21.280001  21.280001       0\n",
       "2020-12-04  21.049999  21.150000  19.969999  20.790001  20.790001       0\n",
       "\n",
       "[7794 rows x 6 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>1.483333</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>1.491789</td>\n",
       "      <td>446400.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-06</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>6.882812</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>1.507011</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-07</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>7.015625</td>\n",
       "      <td>6.945312</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.515469</td>\n",
       "      <td>164800.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.109375</td>\n",
       "      <td>6.984375</td>\n",
       "      <td>7.093750</td>\n",
       "      <td>1.535765</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0 1970-01-02  6.851562  6.890625  6.843750  6.851562   1.483333   72000.0   \n",
       "1 1970-01-05  6.859375  6.898438  6.859375  6.890625   1.491789  446400.0   \n",
       "2 1970-01-06  6.890625  6.960938  6.882812  6.960938   1.507011  176000.0   \n",
       "3 1970-01-07  6.960938  7.015625  6.945312  7.000000   1.515469  164800.0   \n",
       "4 1970-01-08  7.000000  7.109375  6.984375  7.093750   1.535765  304000.0   \n",
       "\n",
       "  Symbol  \n",
       "0    MMM  \n",
       "1    MMM  \n",
       "2    MMM  \n",
       "3    MMM  \n",
       "4    MMM  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = list(data_all['Symbol'].unique())\n",
    "\n",
    "data_all.reset_index(inplace=True)\n",
    "\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_date = '2015-01-15'\n",
    "training_end_date = '2020-09-30'\n",
    "mask = data_all['Date'] >= training_start_date\n",
    "mask &= data_all['Date'] <= training_end_date\n",
    "\n",
    "data_training= data_all[mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_filter(df, start_date, end_date):\n",
    "    mask = df['Date'] >=  start_date\n",
    "    mask &= df['Date'] <= end_date\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.85042934e-04 7.44584306e-06]\n",
      " [7.44584306e-06 3.88371563e-04]]\n"
     ]
    }
   ],
   "source": [
    "def covariance(df, date, symbols, history):\n",
    "    df_recent = pd.DataFrame({})\n",
    "    dates = list(df['Date'].unique())\n",
    "    dates.sort()\n",
    "    df_recent['Date']= dates[-(history+1):-1]\n",
    "    for symbol in symbols:\n",
    "        mask = df['Symbol'] == symbol\n",
    " \n",
    "        if all([date in list(df[mask]['Date'].unique()) for date in dates[-(history+1):-1]]):\n",
    "            #print(df[mask]['Close'][-(history+1):-1])\n",
    "            df_recent[symbol] = df[mask]['Close'].to_list()[-(history+1):-1]\n",
    "    df_return = pd.DataFrame({})\n",
    "    df_return['Date'] = df_recent['Date']\n",
    "    for symbol in df_recent.columns:\n",
    "        if symbol !='Date':\n",
    "            #print(symbol,df_recent[symbol].div(df_recent[symbol].shift(1)))\n",
    "            df_return[symbol] = df_recent[symbol].div(df_recent[symbol].shift(1))\n",
    "    return df_return[1:].set_index('Date').cov() \n",
    " \n",
    "            \n",
    "symbols = ['AAPL', 'MMM']\n",
    "df_cov = covariance(data_training, list(data_training['Date'].unique())[-1], symbols, 10)\n",
    "cov=df_cov.to_numpy() \n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.0006603349124938092\n",
      "            Iterations: 2\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-988-e88c3116b488>:11: OptimizeWarning: Unknown solver options: gtol\n",
      "  res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25038093, 1.24961907])"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(x):\n",
    "    l = len(x)\n",
    "    assert l == cov.shape[0]\n",
    "    return x.dot(cov.dot(x))\n",
    "\n",
    "def constraint(x):\n",
    "    return np.atleast_1d(np.sum(np.abs(x)) - 1.5)\n",
    "\n",
    " \n",
    "bounds=[[0, 1], [1, 2]]\n",
    "res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n",
    "res.x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def portfolio_optimization(cov, k):        \n",
    " \n",
    "    assert 2*k == cov.shape[0]\n",
    "    def objective(x):\n",
    "        return x.dot(cov.dot(x))\n",
    "\n",
    "    def constraint(x):\n",
    "        return np.atleast_1d(np.sum(np.abs(x))-1)\n",
    "    x0 = [1/(2*k)]*k+[-1/(2*k)]*k\n",
    "    x0 = np.array(x0)\n",
    "    bounds = []\n",
    "    for i in range(k):\n",
    "        bounds.append([1/(4*k),1/k])\n",
    "    for i in range(k):\n",
    "        bounds.append([-1/k, -1/(4*k)])\n",
    "        \n",
    "    res=optimize.minimize(objective, x0, constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': False}, bounds=bounds )\n",
    "    s= sum(np.abs(res.x))\n",
    "    return res.x/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genearte DataFrames of various returns for each symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM\n",
      "AOS\n",
      "ABT\n",
      "ABBV\n",
      "ACN\n",
      "ATVI\n",
      "AYI\n",
      "ADBE\n",
      "AAP\n",
      "AMD\n",
      "AES\n",
      "AET\n",
      "AMG\n",
      "AFL\n",
      "A\n",
      "APD\n",
      "AKAM\n",
      "ALK\n",
      "ALB\n",
      "ARE\n",
      "ALXN\n",
      "ALGN\n",
      "ALLE\n",
      "ADS\n",
      "LNT\n",
      "ALL\n",
      "GOOGL\n",
      "GOOG\n",
      "MO\n",
      "AMZN\n",
      "AEE\n",
      "AAL\n",
      "AEP\n",
      "AXP\n",
      "AIG\n",
      "AMT\n",
      "AWK\n",
      "AMP\n",
      "ABC\n",
      "AME\n",
      "AMGN\n",
      "APH\n",
      "ADI\n",
      "ANDV\n",
      "ANSS\n",
      "ANTM\n",
      "AON\n",
      "APA\n",
      "AIV\n",
      "AAPL\n",
      "AMAT\n",
      "APTV\n",
      "ADM\n",
      "ARNC\n",
      "AJG\n",
      "AIZ\n",
      "T\n",
      "ADSK\n",
      "ADP\n",
      "AZO\n",
      "AVB\n",
      "AVY\n",
      "BLL\n",
      "BAC\n",
      "BAX\n",
      "BDX\n",
      "BBY\n",
      "BIIB\n",
      "BLK\n",
      "HRB\n",
      "BA\n",
      "BWA\n",
      "BXP\n",
      "BSX\n",
      "BHF\n",
      "BMY\n",
      "AVGO\n",
      "CHRW\n",
      "CA\n",
      "COG\n",
      "CDNS\n",
      "CPB\n",
      "COF\n",
      "CAH\n",
      "KMX\n",
      "CCL\n",
      "CAT\n",
      "CBOE\n",
      "CNC\n",
      "CNP\n",
      "CTL\n",
      "CERN\n",
      "CF\n",
      "SCHW\n",
      "CHTR\n",
      "CHK\n",
      "CVX\n",
      "CMG\n",
      "CB\n",
      "CHD\n",
      "CI\n",
      "XEC\n",
      "CINF\n",
      "CTAS\n",
      "CSCO\n",
      "C\n",
      "CFG\n",
      "CTXS\n",
      "CME\n",
      "CMS\n",
      "KO\n",
      "CTSH\n",
      "CL\n",
      "CMCSA\n",
      "CMA\n",
      "CAG\n",
      "CXO\n",
      "COP\n",
      "ED\n",
      "STZ\n",
      "GLW\n",
      "COST\n",
      "COTY\n",
      "CCI\n",
      "CSRA\n",
      "CSX\n",
      "CMI\n",
      "CVS\n",
      "DHI\n",
      "DHR\n",
      "DRI\n",
      "DVA\n",
      "DE\n",
      "DAL\n",
      "XRAY\n",
      "DVN\n",
      "DLR\n",
      "DFS\n",
      "DISCA\n",
      "DISCK\n",
      "DISH\n",
      "DG\n",
      "DLTR\n",
      "D\n",
      "DOV\n",
      "DTE\n",
      "DUK\n",
      "DRE\n",
      "DXC\n",
      "ETFC\n",
      "EMN\n",
      "ETN\n",
      "EBAY\n",
      "ECL\n",
      "EIX\n",
      "EW\n",
      "EA\n",
      "EMR\n",
      "ETR\n",
      "EVHC\n",
      "EOG\n",
      "EQT\n",
      "EFX\n",
      "EQIX\n",
      "EQR\n",
      "ESS\n",
      "EL\n",
      "RE\n",
      "ES\n",
      "EXC\n",
      "EXPE\n",
      "EXPD\n",
      "ESRX\n",
      "EXR\n",
      "XOM\n",
      "FFIV\n",
      "FB\n",
      "FAST\n",
      "FRT\n",
      "FDX\n",
      "FIS\n",
      "FITB\n",
      "FE\n",
      "FISV\n",
      "FLIR\n",
      "FLS\n",
      "FLR\n",
      "FMC\n",
      "FL\n",
      "F\n",
      "FTV\n",
      "FBHS\n",
      "BEN\n",
      "FCX\n",
      "GPS\n",
      "GRMN\n",
      "IT\n",
      "GD\n",
      "GE\n",
      "GIS\n",
      "GM\n",
      "GPC\n",
      "GILD\n",
      "GPN\n",
      "GS\n",
      "GT\n",
      "GWW\n",
      "HAL\n",
      "HBI\n",
      "HOG\n",
      "HIG\n",
      "HAS\n",
      "HCA\n",
      "HP\n",
      "HSIC\n",
      "HES\n",
      "HPE\n",
      "HLT\n",
      "HOLX\n",
      "HD\n",
      "HON\n",
      "HRL\n",
      "HST\n",
      "HPQ\n",
      "HUM\n",
      "HBAN\n",
      "HII\n",
      "IDXX\n",
      "INFO\n",
      "ITW\n",
      "ILMN\n",
      "INCY\n",
      "IR\n",
      "INTC\n",
      "ICE\n",
      "IBM\n",
      "IP\n",
      "IPG\n",
      "IFF\n",
      "INTU\n",
      "ISRG\n",
      "IVZ\n",
      "IQV\n",
      "IRM\n",
      "JBHT\n",
      "SJM\n",
      "JNJ\n",
      "JCI\n",
      "JPM\n",
      "JNPR\n",
      "KSU\n",
      "K\n",
      "KEY\n",
      "KMB\n",
      "KIM\n",
      "KMI\n",
      "KLAC\n",
      "KSS\n",
      "KHC\n",
      "KR\n",
      "LB\n",
      "LH\n",
      "LRCX\n",
      "LEG\n",
      "LEN\n",
      "LLY\n",
      "LNC\n",
      "LKQ\n",
      "LMT\n",
      "L\n",
      "LOW\n",
      "LYB\n",
      "MTB\n",
      "MAC\n",
      "M\n",
      "MRO\n",
      "MPC\n",
      "MAR\n",
      "MMC\n",
      "MLM\n",
      "MAS\n",
      "MA\n",
      "MAT\n",
      "MKC\n",
      "MCD\n",
      "MCK\n",
      "MDT\n",
      "MRK\n",
      "MET\n",
      "MTD\n",
      "MGM\n",
      "MCHP\n",
      "MU\n",
      "MSFT\n",
      "MAA\n",
      "MHK\n",
      "TAP\n",
      "MDLZ\n",
      "MON\n",
      "MNST\n",
      "MCO\n",
      "MS\n",
      "MSI\n",
      "MYL\n",
      "NDAQ\n",
      "NOV\n",
      "NAVI\n",
      "NTAP\n",
      "NFLX\n",
      "NWL\n",
      "NFX\n",
      "NEM\n",
      "NWSA\n",
      "NWS\n",
      "NEE\n",
      "NLSN\n",
      "NKE\n",
      "NI\n",
      "NBL\n",
      "JWN\n",
      "NSC\n",
      "NTRS\n",
      "NOC\n",
      "NCLH\n",
      "NRG\n",
      "NUE\n",
      "NVDA\n",
      "ORLY\n",
      "OXY\n",
      "OMC\n",
      "OKE\n",
      "ORCL\n",
      "PCAR\n",
      "PKG\n",
      "PH\n",
      "PDCO\n",
      "PAYX\n",
      "PYPL\n",
      "PNR\n",
      "PBCT\n",
      "PEP\n",
      "PKI\n",
      "PRGO\n",
      "PFE\n",
      "PCG\n",
      "PM\n",
      "PSX\n",
      "PNW\n",
      "PXD\n",
      "PNC\n",
      "RL\n",
      "PPG\n",
      "PPL\n",
      "PX\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PLD\n",
      "PRU\n",
      "PEG\n",
      "PSA\n",
      "PHM\n",
      "PVH\n",
      "QRVO\n",
      "QCOM\n",
      "PWR\n",
      "DGX\n",
      "RRC\n",
      "RJF\n",
      "O\n",
      "REG\n",
      "REGN\n",
      "RF\n",
      "RSG\n",
      "RMD\n",
      "RHI\n",
      "ROK\n",
      "COL\n",
      "ROP\n",
      "ROST\n",
      "RCL\n",
      "SPGI\n",
      "CRM\n",
      "SBAC\n",
      "SCG\n",
      "SLB\n",
      "SNI\n",
      "STX\n",
      "SEE\n",
      "SRE\n",
      "SHW\n",
      "SIG\n",
      "SPG\n",
      "SWKS\n",
      "SLG\n",
      "SNA\n",
      "SO\n",
      "LUV\n",
      "SWK\n",
      "SBUX\n",
      "STT\n",
      "SRCL\n",
      "SYK\n",
      "STI\n",
      "SYF\n",
      "SNPS\n",
      "SYY\n",
      "TROW\n",
      "TPR\n",
      "TGT\n",
      "TEL\n",
      "FTI\n",
      "TXN\n",
      "TXT\n",
      "BK\n",
      "CLX\n",
      "COO\n",
      "HSY\n",
      "MOS\n",
      "TRV\n",
      "DIS\n",
      "TMO\n",
      "TIF\n",
      "TWX\n",
      "TJX\n",
      "TSCO\n",
      "TDG\n",
      "TRIP\n",
      "FOXA\n",
      "FOX\n",
      "TSN\n",
      "USB\n",
      "UDR\n",
      "ULTA\n",
      "UAA\n",
      "UA\n",
      "UNP\n",
      "UAL\n",
      "UNH\n",
      "UPS\n",
      "URI\n",
      "UHS\n",
      "UNM\n",
      "VFC\n",
      "VLO\n",
      "VAR\n",
      "VTR\n",
      "VRSN\n",
      "VRSK\n",
      "VZ\n",
      "VRTX\n",
      "V\n",
      "VNO\n",
      "VMC\n",
      "WMT\n",
      "WBA\n",
      "WM\n",
      "WAT\n",
      "WEC\n",
      "WFC\n",
      "WDC\n",
      "WU\n",
      "WRK\n",
      "WY\n",
      "WHR\n",
      "WMB\n",
      "WLTW\n",
      "WYNN\n",
      "XEL\n",
      "XRX\n",
      "XLNX\n",
      "XL\n",
      "XYL\n",
      "YUM\n",
      "ZBH\n",
      "ZION\n",
      "ZTS\n",
      "SPY\n"
     ]
    }
   ],
   "source": [
    "data_training_return = {}\n",
    " \n",
    "for symbol in symbols:\n",
    "#     print(symbol)\n",
    "    mask = data_training['Symbol'] == symbol\n",
    "    data_training_return[symbol] = pd.DataFrame({})\n",
    "    data_training_return[symbol]['Date'] = data_training[mask]['Date']\n",
    "    \n",
    "    data_training_return[symbol]['close_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Close'].shift(1))-1  \n",
    "    data_training_return[symbol]['open_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Open'] )-1\n",
    "    data_training_return[symbol]['close_open_return']  = data_training[mask]['Open'].div(data_training[mask]['Close'].shift(1) )-1\n",
    "    data_training_return[symbol]['vwap_open_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['High'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Low'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Close'].shift(1))-1\n",
    "    \n",
    "    data_training_return[symbol]['vwap_close_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open']+ \\\n",
    "                                                                                        data_training[mask]['High']+ \\\n",
    "                                                                                        data_training[mask]['Low']+ \\\n",
    "                                                                                        data_training[mask]['Close'])-1\n",
    "    \n",
    "    \n",
    "    data_training_return[symbol].fillna(0, inplace=True)\n",
    "    data_training_return[symbol].reset_index(inplace=True,drop=True)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 1) (1188,) MMM\n",
      "(1188, 1) (1188,) AOS\n",
      "(1188, 1) (1188,) ABT\n",
      "(1188, 1) (1188,) ABBV\n",
      "(1188, 1) (1188,) ACN\n",
      "(1188, 1) (1188,) ATVI\n",
      "(1188, 1) (1188,) AYI\n",
      "(1188, 1) (1188,) ADBE\n",
      "(1188, 1) (1188,) AAP\n",
      "(1188, 1) (1188,) AMD\n",
      "(1188, 1) (1188,) AES\n",
      "(977, 1) (977,) AET\n",
      "(1188, 1) (1188,) AMG\n",
      "(1188, 1) (1188,) AFL\n",
      "(1188, 1) (1188,) A\n",
      "(1188, 1) (1188,) APD\n",
      "(1188, 1) (1188,) AKAM\n",
      "(1188, 1) (1188,) ALK\n",
      "(1188, 1) (1188,) ALB\n",
      "(1188, 1) (1188,) ARE\n",
      "(1188, 1) (1188,) ALXN\n",
      "(1188, 1) (1188,) ALGN\n",
      "(1188, 1) (1188,) ALLE\n",
      "(1188, 1) (1188,) ADS\n",
      "(1188, 1) (1188,) LNT\n",
      "(1188, 1) (1188,) ALL\n",
      "(1188, 1) (1188,) GOOGL\n",
      "(1188, 1) (1188,) GOOG\n",
      "(1188, 1) (1188,) MO\n",
      "(1188, 1) (1188,) AMZN\n",
      "(1188, 1) (1188,) AEE\n",
      "(1188, 1) (1188,) AAL\n",
      "(1188, 1) (1188,) AEP\n",
      "(1188, 1) (1188,) AXP\n",
      "(1188, 1) (1188,) AIG\n",
      "(1188, 1) (1188,) AMT\n",
      "(1188, 1) (1188,) AWK\n",
      "(1188, 1) (1188,) AMP\n",
      "(1188, 1) (1188,) ABC\n",
      "(1188, 1) (1188,) AME\n",
      "(1188, 1) (1188,) AMGN\n",
      "(1188, 1) (1188,) APH\n",
      "(1188, 1) (1188,) ADI\n",
      "(934, 1) (934,) ANDV\n",
      "(1188, 1) (1188,) ANSS\n",
      "(1188, 1) (1188,) ANTM\n",
      "(1188, 1) (1188,) AON\n",
      "(1188, 1) (1188,) APA\n",
      "(1188, 1) (1188,) AIV\n",
      "(1188, 1) (1188,) AAPL\n",
      "(1188, 1) (1188,) AMAT\n",
      "(1188, 1) (1188,) APTV\n",
      "(1188, 1) (1188,) ADM\n",
      "(0, 1) (0,) ARNC\n",
      "(1188, 1) (1188,) AJG\n",
      "(1188, 1) (1188,) AIZ\n",
      "(1188, 1) (1188,) T\n",
      "(1188, 1) (1188,) ADSK\n",
      "(1188, 1) (1188,) ADP\n",
      "(1188, 1) (1188,) AZO\n",
      "(1188, 1) (1188,) AVB\n",
      "(1188, 1) (1188,) AVY\n",
      "(1188, 1) (1188,) BLL\n",
      "(1188, 1) (1188,) BAC\n",
      "(1188, 1) (1188,) BAX\n",
      "(1188, 1) (1188,) BDX\n",
      "(1188, 1) (1188,) BBY\n",
      "(1188, 1) (1188,) BIIB\n",
      "(1188, 1) (1188,) BLK\n",
      "(1188, 1) (1188,) HRB\n",
      "(1188, 1) (1188,) BA\n",
      "(1188, 1) (1188,) BWA\n",
      "(1188, 1) (1188,) BXP\n",
      "(1188, 1) (1188,) BSX\n",
      "(559, 1) (559,) BHF\n",
      "(1188, 1) (1188,) BMY\n",
      "(1188, 1) (1188,) AVGO\n",
      "(1188, 1) (1188,) CHRW\n",
      "(1004, 1) (1004,) CA\n",
      "(1188, 1) (1188,) COG\n",
      "(1188, 1) (1188,) CDNS\n",
      "(1188, 1) (1188,) CPB\n",
      "(1188, 1) (1188,) COF\n",
      "(1188, 1) (1188,) CAH\n",
      "(1188, 1) (1188,) KMX\n",
      "(1188, 1) (1188,) CCL\n",
      "(1188, 1) (1188,) CAT\n",
      "(1188, 1) (1188,) CBOE\n",
      "(1188, 1) (1188,) CNC\n",
      "(1188, 1) (1188,) CNP\n",
      "(1188, 1) (1188,) CTL\n",
      "(1188, 1) (1188,) CERN\n",
      "(1188, 1) (1188,) CF\n",
      "(1188, 1) (1188,) SCHW\n",
      "(1188, 1) (1188,) CHTR\n",
      "(1188, 1) (1188,) CHK\n",
      "(1188, 1) (1188,) CVX\n",
      "(1188, 1) (1188,) CMG\n",
      "(1188, 1) (1188,) CB\n",
      "(1188, 1) (1188,) CHD\n",
      "(1188, 1) (1188,) CI\n",
      "(1188, 1) (1188,) XEC\n",
      "(1188, 1) (1188,) CINF\n",
      "(1188, 1) (1188,) CTAS\n",
      "(1188, 1) (1188,) CSCO\n",
      "(1188, 1) (1188,) C\n",
      "(1188, 1) (1188,) CFG\n",
      "(1188, 1) (1188,) CTXS\n",
      "(1188, 1) (1188,) CME\n",
      "(1188, 1) (1188,) CMS\n",
      "(1188, 1) (1188,) KO\n",
      "(1188, 1) (1188,) CTSH\n",
      "(1188, 1) (1188,) CL\n",
      "(1188, 1) (1188,) CMCSA\n",
      "(1188, 1) (1188,) CMA\n",
      "(1188, 1) (1188,) CAG\n",
      "(1188, 1) (1188,) CXO\n",
      "(1188, 1) (1188,) COP\n",
      "(1188, 1) (1188,) ED\n",
      "(1188, 1) (1188,) STZ\n",
      "(1188, 1) (1188,) GLW\n",
      "(1188, 1) (1188,) COST\n",
      "(1188, 1) (1188,) COTY\n",
      "(1188, 1) (1188,) CCI\n",
      "(598, 1) (598,) CSRA\n",
      "(1188, 1) (1188,) CSX\n",
      "(1188, 1) (1188,) CMI\n",
      "(1188, 1) (1188,) CVS\n",
      "(1188, 1) (1188,) DHI\n",
      "(1188, 1) (1188,) DHR\n",
      "(1188, 1) (1188,) DRI\n",
      "(1188, 1) (1188,) DVA\n",
      "(1188, 1) (1188,) DE\n",
      "(1188, 1) (1188,) DAL\n",
      "(1188, 1) (1188,) XRAY\n",
      "(1188, 1) (1188,) DVN\n",
      "(1188, 1) (1188,) DLR\n",
      "(1188, 1) (1188,) DFS\n",
      "(1188, 1) (1188,) DISCA\n",
      "(1188, 1) (1188,) DISCK\n",
      "(1188, 1) (1188,) DISH\n",
      "(1188, 1) (1188,) DG\n",
      "(1188, 1) (1188,) DLTR\n",
      "(1188, 1) (1188,) D\n",
      "(1188, 1) (1188,) DOV\n",
      "(1188, 1) (1188,) DTE\n",
      "(1188, 1) (1188,) DUK\n",
      "(1188, 1) (1188,) DRE\n",
      "(1188, 1) (1188,) DXC\n",
      "(1188, 1) (1188,) ETFC\n",
      "(1188, 1) (1188,) EMN\n",
      "(1188, 1) (1188,) ETN\n",
      "(1188, 1) (1188,) EBAY\n",
      "(1188, 1) (1188,) ECL\n",
      "(1188, 1) (1188,) EIX\n",
      "(1188, 1) (1188,) EW\n",
      "(1188, 1) (1188,) EA\n",
      "(1188, 1) (1188,) EMR\n",
      "(1188, 1) (1188,) ETR\n",
      "(984, 1) (984,) EVHC\n",
      "(1188, 1) (1188,) EOG\n",
      "(1188, 1) (1188,) EQT\n",
      "(1188, 1) (1188,) EFX\n",
      "(1188, 1) (1188,) EQIX\n",
      "(1188, 1) (1188,) EQR\n",
      "(1188, 1) (1188,) ESS\n",
      "(1188, 1) (1188,) EL\n",
      "(1188, 1) (1188,) RE\n",
      "(1188, 1) (1188,) ES\n",
      "(1188, 1) (1188,) EXC\n",
      "(1188, 1) (1188,) EXPE\n",
      "(1188, 1) (1188,) EXPD\n",
      "(991, 1) (991,) ESRX\n",
      "(1188, 1) (1188,) EXR\n",
      "(1188, 1) (1188,) XOM\n",
      "(1188, 1) (1188,) FFIV\n",
      "(1188, 1) (1188,) FB\n",
      "(1188, 1) (1188,) FAST\n",
      "(1188, 1) (1188,) FRT\n",
      "(1188, 1) (1188,) FDX\n",
      "(1188, 1) (1188,) FIS\n",
      "(1188, 1) (1188,) FITB\n",
      "(1188, 1) (1188,) FE\n",
      "(1188, 1) (1188,) FISV\n",
      "(1188, 1) (1188,) FLIR\n",
      "(1188, 1) (1188,) FLS\n",
      "(1188, 1) (1188,) FLR\n",
      "(1188, 1) (1188,) FMC\n",
      "(1188, 1) (1188,) FL\n",
      "(1188, 1) (1188,) F\n",
      "(819, 1) (819,) FTV\n",
      "(1188, 1) (1188,) FBHS\n",
      "(1188, 1) (1188,) BEN\n",
      "(1188, 1) (1188,) FCX\n",
      "(1188, 1) (1188,) GPS\n",
      "(1188, 1) (1188,) GRMN\n",
      "(1188, 1) (1188,) IT\n",
      "(1188, 1) (1188,) GD\n",
      "(1188, 1) (1188,) GE\n",
      "(1188, 1) (1188,) GIS\n",
      "(1188, 1) (1188,) GM\n",
      "(1188, 1) (1188,) GPC\n",
      "(1188, 1) (1188,) GILD\n",
      "(1188, 1) (1188,) GPN\n",
      "(1188, 1) (1188,) GS\n",
      "(1188, 1) (1188,) GT\n",
      "(1188, 1) (1188,) GWW\n",
      "(1188, 1) (1188,) HAL\n",
      "(1188, 1) (1188,) HBI\n",
      "(1188, 1) (1188,) HOG\n",
      "(1188, 1) (1188,) HIG\n",
      "(1188, 1) (1188,) HAS\n",
      "(1188, 1) (1188,) HCA\n",
      "(1188, 1) (1188,) HP\n",
      "(1188, 1) (1188,) HSIC\n",
      "(1188, 1) (1188,) HES\n",
      "(997, 1) (997,) HPE\n",
      "(1188, 1) (1188,) HLT\n",
      "(1188, 1) (1188,) HOLX\n",
      "(1188, 1) (1188,) HD\n",
      "(1188, 1) (1188,) HON\n",
      "(1188, 1) (1188,) HRL\n",
      "(1188, 1) (1188,) HST\n",
      "(1188, 1) (1188,) HPQ\n",
      "(1188, 1) (1188,) HUM\n",
      "(1188, 1) (1188,) HBAN\n",
      "(1188, 1) (1188,) HII\n",
      "(1188, 1) (1188,) IDXX\n",
      "(1188, 1) (1188,) INFO\n",
      "(1188, 1) (1188,) ITW\n",
      "(1188, 1) (1188,) ILMN\n",
      "(1188, 1) (1188,) INCY\n",
      "(603, 1) (603,) IR\n",
      "(1188, 1) (1188,) INTC\n",
      "(1188, 1) (1188,) ICE\n",
      "(1188, 1) (1188,) IBM\n",
      "(1188, 1) (1188,) IP\n",
      "(1188, 1) (1188,) IPG\n",
      "(1188, 1) (1188,) IFF\n",
      "(1188, 1) (1188,) INTU\n",
      "(1188, 1) (1188,) ISRG\n",
      "(1188, 1) (1188,) IVZ\n",
      "(1188, 1) (1188,) IQV\n",
      "(1188, 1) (1188,) IRM\n",
      "(1188, 1) (1188,) JBHT\n",
      "(1188, 1) (1188,) SJM\n",
      "(1188, 1) (1188,) JNJ\n",
      "(1188, 1) (1188,) JCI\n",
      "(1188, 1) (1188,) JPM\n",
      "(1188, 1) (1188,) JNPR\n",
      "(1188, 1) (1188,) KSU\n",
      "(1188, 1) (1188,) K\n",
      "(1188, 1) (1188,) KEY\n",
      "(1188, 1) (1188,) KMB\n",
      "(1188, 1) (1188,) KIM\n",
      "(1188, 1) (1188,) KMI\n",
      "(1188, 1) (1188,) KLAC\n",
      "(1188, 1) (1188,) KSS\n",
      "(1071, 1) (1071,) KHC\n",
      "(1188, 1) (1188,) KR\n",
      "(1188, 1) (1188,) LB\n",
      "(1188, 1) (1188,) LH\n",
      "(1188, 1) (1188,) LRCX\n",
      "(1188, 1) (1188,) LEG\n",
      "(1188, 1) (1188,) LEN\n",
      "(1188, 1) (1188,) LLY\n",
      "(1188, 1) (1188,) LNC\n",
      "(1188, 1) (1188,) LKQ\n",
      "(1188, 1) (1188,) LMT\n",
      "(1188, 1) (1188,) L\n",
      "(1188, 1) (1188,) LOW\n",
      "(1188, 1) (1188,) LYB\n",
      "(1188, 1) (1188,) MTB\n",
      "(1188, 1) (1188,) MAC\n",
      "(1188, 1) (1188,) M\n",
      "(1188, 1) (1188,) MRO\n",
      "(1188, 1) (1188,) MPC\n",
      "(1188, 1) (1188,) MAR\n",
      "(1188, 1) (1188,) MMC\n",
      "(1188, 1) (1188,) MLM\n",
      "(1188, 1) (1188,) MAS\n",
      "(1188, 1) (1188,) MA\n",
      "(1188, 1) (1188,) MAT\n",
      "(1188, 1) (1188,) MKC\n",
      "(1188, 1) (1188,) MCD\n",
      "(1188, 1) (1188,) MCK\n",
      "(1188, 1) (1188,) MDT\n",
      "(1188, 1) (1188,) MRK\n",
      "(1188, 1) (1188,) MET\n",
      "(1188, 1) (1188,) MTD\n",
      "(1188, 1) (1188,) MGM\n",
      "(1188, 1) (1188,) MCHP\n",
      "(1188, 1) (1188,) MU\n",
      "(1188, 1) (1188,) MSFT\n",
      "(1188, 1) (1188,) MAA\n",
      "(1188, 1) (1188,) MHK\n",
      "(1188, 1) (1188,) TAP\n",
      "(1188, 1) (1188,) MDLZ\n",
      "(854, 1) (854,) MON\n",
      "(1188, 1) (1188,) MNST\n",
      "(1188, 1) (1188,) MCO\n",
      "(1188, 1) (1188,) MS\n",
      "(1188, 1) (1188,) MSI\n",
      "(1188, 1) (1188,) MYL\n",
      "(1188, 1) (1188,) NDAQ\n",
      "(1188, 1) (1188,) NOV\n",
      "(1188, 1) (1188,) NAVI\n",
      "(1188, 1) (1188,) NTAP\n",
      "(1188, 1) (1188,) NFLX\n",
      "(1188, 1) (1188,) NWL\n",
      "(1026, 1) (1026,) NFX\n",
      "(1188, 1) (1188,) NEM\n",
      "(1188, 1) (1188,) NWSA\n",
      "(1188, 1) (1188,) NWS\n",
      "(1188, 1) (1188,) NEE\n",
      "(1188, 1) (1188,) NLSN\n",
      "(1188, 1) (1188,) NKE\n",
      "(1188, 1) (1188,) NI\n",
      "(1188, 1) (1188,) NBL\n",
      "(1188, 1) (1188,) JWN\n",
      "(1188, 1) (1188,) NSC\n",
      "(1188, 1) (1188,) NTRS\n",
      "(1188, 1) (1188,) NOC\n",
      "(1188, 1) (1188,) NCLH\n",
      "(1188, 1) (1188,) NRG\n",
      "(1188, 1) (1188,) NUE\n",
      "(1188, 1) (1188,) NVDA\n",
      "(1188, 1) (1188,) ORLY\n",
      "(1188, 1) (1188,) OXY\n",
      "(1188, 1) (1188,) OMC\n",
      "(1188, 1) (1188,) OKE\n",
      "(1188, 1) (1188,) ORCL\n",
      "(1188, 1) (1188,) PCAR\n",
      "(1188, 1) (1188,) PKG\n",
      "(1188, 1) (1188,) PH\n",
      "(1188, 1) (1188,) PDCO\n",
      "(1188, 1) (1188,) PAYX\n",
      "(1071, 1) (1071,) PYPL\n",
      "(1188, 1) (1188,) PNR\n",
      "(1188, 1) (1188,) PBCT\n",
      "(1188, 1) (1188,) PEP\n",
      "(1188, 1) (1188,) PKI\n",
      "(1188, 1) (1188,) PRGO\n",
      "(1188, 1) (1188,) PFE\n",
      "(1188, 1) (1188,) PCG\n",
      "(1188, 1) (1188,) PM\n",
      "(1188, 1) (1188,) PSX\n",
      "(1188, 1) (1188,) PNW\n",
      "(1188, 1) (1188,) PXD\n",
      "(1188, 1) (1188,) PNC\n",
      "(1188, 1) (1188,) RL\n",
      "(1188, 1) (1188,) PPG\n",
      "(1188, 1) (1188,) PPL\n",
      "(37, 1) (37,) PX\n",
      "(1188, 1) (1188,) PFG\n",
      "(1188, 1) (1188,) PG\n",
      "(1188, 1) (1188,) PGR\n",
      "(1188, 1) (1188,) PLD\n",
      "(1188, 1) (1188,) PRU\n",
      "(1188, 1) (1188,) PEG\n",
      "(1188, 1) (1188,) PSA\n",
      "(1188, 1) (1188,) PHM\n",
      "(1188, 1) (1188,) PVH\n",
      "(1188, 1) (1188,) QRVO\n",
      "(1188, 1) (1188,) QCOM\n",
      "(1188, 1) (1188,) PWR\n",
      "(1188, 1) (1188,) DGX\n",
      "(1188, 1) (1188,) RRC\n",
      "(1188, 1) (1188,) RJF\n",
      "(1188, 1) (1188,) O\n",
      "(1188, 1) (1188,) REG\n",
      "(1188, 1) (1188,) REGN\n",
      "(1188, 1) (1188,) RF\n",
      "(1188, 1) (1188,) RSG\n",
      "(1188, 1) (1188,) RMD\n",
      "(1188, 1) (1188,) RHI\n",
      "(1188, 1) (1188,) ROK\n",
      "(1187, 1) (1187,) COL\n",
      "(1188, 1) (1188,) ROP\n",
      "(1188, 1) (1188,) ROST\n",
      "(1188, 1) (1188,) RCL\n",
      "(1188, 1) (1188,) SPGI\n",
      "(1188, 1) (1188,) CRM\n",
      "(1188, 1) (1188,) SBAC\n",
      "(1063, 1) (1063,) SCG\n",
      "(1188, 1) (1188,) SLB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 1) (791,) SNI\n",
      "(1188, 1) (1188,) STX\n",
      "(1188, 1) (1188,) SEE\n",
      "(1188, 1) (1188,) SRE\n",
      "(1188, 1) (1188,) SHW\n",
      "(1188, 1) (1188,) SIG\n",
      "(1188, 1) (1188,) SPG\n",
      "(1188, 1) (1188,) SWKS\n",
      "(1188, 1) (1188,) SLG\n",
      "(1188, 1) (1188,) SNA\n",
      "(1188, 1) (1188,) SO\n",
      "(1188, 1) (1188,) LUV\n",
      "(1188, 1) (1188,) SWK\n",
      "(1188, 1) (1188,) SBUX\n",
      "(1188, 1) (1188,) STT\n",
      "(1188, 1) (1188,) SRCL\n",
      "(1188, 1) (1188,) SYK\n",
      "(1188, 1) (1188,) STI\n",
      "(1188, 1) (1188,) SYF\n",
      "(1188, 1) (1188,) SNPS\n",
      "(1188, 1) (1188,) SYY\n",
      "(1188, 1) (1188,) TROW\n",
      "(1188, 1) (1188,) TPR\n",
      "(1188, 1) (1188,) TGT\n",
      "(1188, 1) (1188,) TEL\n",
      "(1188, 1) (1188,) FTI\n",
      "(1188, 1) (1188,) TXN\n",
      "(1188, 1) (1188,) TXT\n",
      "(1188, 1) (1188,) BK\n",
      "(1188, 1) (1188,) CLX\n",
      "(1188, 1) (1188,) COO\n",
      "(1188, 1) (1188,) HSY\n",
      "(1188, 1) (1188,) MOS\n",
      "(1188, 1) (1188,) TRV\n",
      "(1188, 1) (1188,) DIS\n",
      "(1188, 1) (1188,) TMO\n",
      "(1188, 1) (1188,) TIF\n",
      "(860, 1) (860,) TWX\n",
      "(1188, 1) (1188,) TJX\n",
      "(1188, 1) (1188,) TSCO\n",
      "(1188, 1) (1188,) TDG\n",
      "(1188, 1) (1188,) TRIP\n",
      "(144, 1) (144,) FOXA\n",
      "(143, 1) (143,) FOX\n",
      "(1188, 1) (1188,) TSN\n",
      "(1188, 1) (1188,) USB\n",
      "(1188, 1) (1188,) UDR\n",
      "(1188, 1) (1188,) ULTA\n",
      "(1188, 1) (1188,) UAA\n",
      "(1068, 1) (1068,) UA\n",
      "(1188, 1) (1188,) UNP\n",
      "(1188, 1) (1188,) UAL\n",
      "(1188, 1) (1188,) UNH\n",
      "(1188, 1) (1188,) UPS\n",
      "(1188, 1) (1188,) URI\n",
      "(1188, 1) (1188,) UHS\n",
      "(1188, 1) (1188,) UNM\n",
      "(1188, 1) (1188,) VFC\n",
      "(1188, 1) (1188,) VLO\n",
      "(1188, 1) (1188,) VAR\n",
      "(1188, 1) (1188,) VTR\n",
      "(1188, 1) (1188,) VRSN\n",
      "(1188, 1) (1188,) VRSK\n",
      "(1188, 1) (1188,) VZ\n",
      "(1188, 1) (1188,) VRTX\n",
      "(1188, 1) (1188,) V\n",
      "(1188, 1) (1188,) VNO\n",
      "(1188, 1) (1188,) VMC\n",
      "(1188, 1) (1188,) WMT\n",
      "(1188, 1) (1188,) WBA\n",
      "(1188, 1) (1188,) WM\n",
      "(1188, 1) (1188,) WAT\n",
      "(1188, 1) (1188,) WEC\n",
      "(1188, 1) (1188,) WFC\n",
      "(1188, 1) (1188,) WDC\n",
      "(1188, 1) (1188,) WU\n",
      "(1078, 1) (1078,) WRK\n",
      "(1188, 1) (1188,) WY\n",
      "(1188, 1) (1188,) WHR\n",
      "(1188, 1) (1188,) WMB\n",
      "(1188, 1) (1188,) WLTW\n",
      "(1188, 1) (1188,) WYNN\n",
      "(1188, 1) (1188,) XEL\n",
      "(1188, 1) (1188,) XRX\n",
      "(1188, 1) (1188,) XLNX\n",
      "(922, 1) (922,) XL\n",
      "(1188, 1) (1188,) XYL\n",
      "(1188, 1) (1188,) YUM\n",
      "(1188, 1) (1188,) ZBH\n",
      "(1188, 1) (1188,) ZION\n",
      "(1188, 1) (1188,) ZTS\n",
      "(1188, 1) (1188,) SPY\n"
     ]
    }
   ],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = data_training_return['SPY']['close_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y =  data_training_return[symbol][mask]['close_close_return'] \n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_here = data_training_return['SPY'][mask]['close_close_return'] \n",
    "        X_here = np.expand_dims(X_here, axis=1)\n",
    "       # print(X_here.shape, y.shape, symbol)\n",
    "        if X_here.shape[0] == len(dates_X):\n",
    "            reg = LinearRegression().fit(X_here, y)\n",
    "            reg_map[symbol] = reg\n",
    " \n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade at open using pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Net Profit\n",
      "0 2019-10-04   -0.002090\n",
      "1 2019-10-07    0.013615\n",
      "2 2019-10-08   -0.016029\n",
      "3 2019-10-09   -0.004583\n",
      "4 2019-10-10   -0.005565\n",
      "Daily mean return:  0.004011713428848835\n",
      "Sharp ratio:  2.1599123311370256\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.011\n",
      "Model:                            OLS   Adj. R-squared:                  0.007\n",
      "Method:                 Least Squares   F-statistic:                     2.825\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):             0.0940\n",
      "Time:                        18:26:50   Log-Likelihood:                 528.83\n",
      "No. Observations:                 250   AIC:                            -1054.\n",
      "Df Residuals:                     248   BIC:                            -1047.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0013      0.004     -0.327      0.744      -0.009       0.007\n",
      "Open           0.0002      0.000      1.681      0.094   -3.81e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       59.730   Durbin-Watson:                   2.430\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              329.395\n",
      "Skew:                          -0.798   Prob(JB):                     2.97e-72\n",
      "Kurtosis:                       8.392   Cond. No.                         64.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.Performance at 0x7fefa6f3d640>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c= 0.0003\n",
    "\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "\n",
    "k= 2\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['close_open_return'].to_numpy()\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "pm.Performance(result, c)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Net Profit\n",
      "0 2019-10-04   -0.010073\n",
      "1 2019-10-07   -0.013986\n",
      "2 2019-10-08   -0.000701\n",
      "3 2019-10-09    0.006010\n",
      "4 2019-10-10    0.001247\n",
      "Daily mean return:  0.001979262757973859\n",
      "Sharp ratio:  1.5912231137875967\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.225\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):              0.137\n",
      "Time:                        18:29:24   Log-Likelihood:                 628.76\n",
      "No. Observations:                 250   AIC:                            -1254.\n",
      "Df Residuals:                     248   BIC:                            -1246.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0009      0.003     -0.352      0.725      -0.006       0.004\n",
      "Open           0.0001   8.85e-05      1.492      0.137   -4.23e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       31.684   Durbin-Watson:                   2.353\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              176.272\n",
      "Skew:                          -0.195   Prob(JB):                     5.28e-39\n",
      "Kurtosis:                       7.095   Cond. No.                         64.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.Performance at 0x7fef9bd1b280>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using vwap open return instead of close open return\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k= 5\n",
    "c=0.0003\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['vwap_open_return'].to_numpy()\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['vwap_open_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "pm.Performance(result, c)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade at close using pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.0022294429092509986\n",
      "Sharp ratio:  2.2458297291326113\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.013\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     3.301\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):             0.0705\n",
      "Time:                        18:47:21   Log-Likelihood:                 685.69\n",
      "No. Observations:                 250   AIC:                            -1367.\n",
      "Df Residuals:                     248   BIC:                            -1360.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0006      0.002     -0.265      0.792      -0.005       0.004\n",
      "Close          0.0001   7.07e-05      1.817      0.070   -1.08e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      161.817   Durbin-Watson:                   1.964\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2734.399\n",
      "Skew:                           2.226   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.578   Cond. No.                         63.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fefa9522430>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k=5\n",
    "c=0.0003\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-250:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    for symbol in symbols:\n",
    "        \n",
    "        if symbol in reg_map and symbol !='SPY':\n",
    "   \n",
    "\n",
    " \n",
    "            try:\n",
    "                mask = data_training_return['SPY']['Date'] == date\n",
    "                X = data_training_return['SPY'][mask]['vwap_close_return']\n",
    "                X = np.expand_dims(X, axis=1)\n",
    "                pred = reg_map[symbol].predict(X)\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "                error = data_training_return[symbol][mask]['vwap_close_return'].to_numpy()[0] - pred[0]\n",
    "                error_map[error] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list) and index+1<len(testing_dates): \n",
    "            try:\n",
    "                symbol = error_list[j][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==testing_dates[index+1], 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                symbol = error_list[-j-1][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==testing_dates[index+1], 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "\n",
    " \n",
    " \n",
    "pm.Performance(result,c)\n",
    "pm.VIX(result,'Close')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Reverse Effect at opening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close open error as a regressor at opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_open_close = data_training_return['SPY']['open_close_return'] \n",
    "X_close_open = data_training_return['SPY']['open_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map_reverse = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y_open_close =  data_training_return[symbol][mask]['open_close_return']\n",
    "#         y_open_close = np.expand_dims(y_open_close, axis=1)\n",
    "        y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "        y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_open_close = data_training_return['SPY'][mask]['open_close_return'] \n",
    "        X_open_close = np.expand_dims(X_open_close, axis=1)\n",
    "        \n",
    "        X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "        X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "        \n",
    "        if symbol in reg_map:\n",
    "            pred_close_open = reg_map[symbol].predict(X_close_open)\n",
    "            pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "            error_close_open = y_close_open-pred_close_open\n",
    "#             print(error_close_open.shape, y_close_open.shape, pred_close_open.shape)\n",
    "#             break\n",
    "            X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    " \n",
    "            if len(dates_X)>0 and X.shape[0] == len(dates_X):\n",
    "                reg = LinearRegression().fit(X, y_open_close)\n",
    "                reg_map_reverse[symbol] = reg\n",
    " \n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade at Open(close-open error as regressor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.007004596394565973\n",
      "Sharp ratio:  4.240669686271918\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.009\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.300\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):              0.131\n",
      "Time:                        19:23:24   Log-Likelihood:                 557.89\n",
      "No. Observations:                 250   AIC:                            -1112.\n",
      "Df Residuals:                     248   BIC:                            -1105.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0029      0.004      0.808      0.420      -0.004       0.010\n",
      "Open           0.0002      0.000      1.517      0.131   -5.32e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       20.989   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.330\n",
      "Skew:                           0.356   Prob(JB):                     1.18e-11\n",
      "Kurtosis:                       5.079   Cond. No.                         64.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fefa95015e0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 0.0003\n",
    "k= 1\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "result.head()\n",
    "\n",
    " \n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    " \n",
    "        \n",
    "        if symbol in reg_map and symbol in reg_map_reverse and symbol !='SPY':\n",
    "  \n",
    "\n",
    "   \n",
    "\n",
    " \n",
    "#             try:\n",
    " \n",
    "            mask = data_training_return[symbol]['Date'] == date     \n",
    "            y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "            y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "            mask = data_training_return['SPY']['Date'] == date     \n",
    "            X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "            X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "            \n",
    "            X_open_close =  np.zeros([len(X_close_open),1])\n",
    "\n",
    "            if X_open_close.shape == X_close_open.shape == y_close_open.shape:\n",
    "\n",
    "                pred_close_open = reg_map[symbol].predict(X_close_open)\n",
    "                pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "                error_close_open = y_close_open-pred_close_open\n",
    "                \n",
    "                X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    "#                 print(X.shape)\n",
    "\n",
    "                pred = reg_map_reverse[symbol].predict(X)\n",
    "\n",
    "                error_map[pred[0]] = symbol\n",
    "#             except:\n",
    "#                 pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "            \n",
    "\n",
    "pm.Performance(result, c)\n",
    "pm.VIX(result, 'Open')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trade at Close(open close error as regressor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87633934 -0.03968184]]\n",
      "[[1.20186789 0.02018615]]\n",
      "[[0.89871129 0.11020738]]\n",
      "[[0.9412648  0.02656301]]\n",
      "[[1.00942267 0.04549461]]\n",
      "[[ 1.31440331 -0.02069873]]\n",
      "[[ 1.13812032 -0.09489471]]\n",
      "[[1.21766337 0.05103626]]\n",
      "[[0.79390771 0.03257613]]\n",
      "[[ 1.87635525 -0.03937646]]\n",
      "[[0.65856373 0.01670917]]\n",
      "[[ 1.40667812 -0.04010685]]\n",
      "[[ 0.92218792 -0.03010474]]\n",
      "[[1.12514427 0.08901187]]\n",
      "[[0.93258187 0.06554611]]\n",
      "[[1.05797977 0.07961114]]\n",
      "[[ 0.97789008 -0.02376775]]\n",
      "[[ 1.17862203 -0.03620403]]\n",
      "[[0.52694646 0.0042412 ]]\n",
      "[[1.09886982 0.05027293]]\n",
      "[[ 1.17751209 -0.08241091]]\n",
      "[[ 0.91498046 -0.02096731]]\n",
      "[[1.02736076 0.04500753]]\n",
      "[[0.2194318  0.01877074]]\n",
      "[[ 0.74568733 -0.01428044]]\n",
      "[[ 1.1856343  -0.00453171]]\n",
      "[[1.19146264 0.0154215 ]]\n",
      "[[ 0.66754668 -0.0844241 ]]\n",
      "[[1.36654121 0.08950003]]\n",
      "[[0.23248536 0.0229671 ]]\n",
      "[[ 1.27155955 -0.03676953]]\n",
      "[[0.21354501 0.02813489]]\n",
      "[[ 0.91483252 -0.0396084 ]]\n",
      "[[ 1.13782097 -0.0202112 ]]\n",
      "[[0.59833729 0.05206952]]\n",
      "[[0.26393502 0.01378676]]\n",
      "[[ 1.27234965 -0.05771015]]\n",
      "[[0.77811097 0.03237747]]\n",
      "[[1.104159   0.05515931]]\n",
      "[[0.90665148 0.00286883]]\n",
      "[[ 1.08374652e+00 -4.63066861e-04]]\n",
      "[[ 1.26237736 -0.03988509]]\n",
      "[[ 1.01504292 -0.04251216]]\n",
      "[[0.79430532 0.04341334]]\n",
      "[[0.8138934  0.06265867]]\n",
      "[[ 1.41218204 -0.02307504]]\n",
      "[[ 0.50823262 -0.06139982]]\n",
      "[[ 1.34563686 -0.06525385]]\n",
      "[[ 1.34561734 -0.03809986]]\n",
      "[[ 1.3769507  -0.00395235]]\n",
      "[[0.81285084 0.00188311]]\n",
      "[[ 0.80537914 -0.00551106]]\n",
      "[[ 0.80853316 -0.02029145]]\n",
      "[[ 0.59398851 -0.03270526]]\n",
      "[[ 1.30598787 -0.00648519]]\n",
      "[[ 0.98578413 -0.04412734]]\n",
      "[[ 0.69404006 -0.07518606]]\n",
      "[[ 0.41913844 -0.01271373]]\n",
      "[[0.9681108  0.02949889]]\n",
      "[[0.95355163 0.02965152]]\n",
      "[[ 1.47269016 -0.12722775]]\n",
      "[[0.76813302 0.03287774]]\n",
      "[[ 7.58847472e-01 -1.20540673e-04]]\n",
      "[[1.09261486 0.09051489]]\n",
      "[[1.03603778 0.02009927]]\n",
      "[[ 1.26979045 -0.01827489]]\n",
      "[[0.77397481 0.02348298]]\n",
      "[[ 1.23701367 -0.03137238]]\n",
      "[[ 1.41719179 -0.04639574]]\n",
      "[[0.53021149 0.03529092]]\n",
      "[[ 0.9255317  -0.01056826]]\n",
      "[[0.74733603 0.06550465]]\n",
      "[[1.48263179 0.01646171]]\n",
      "[[ 0.78076309 -0.0013683 ]]\n",
      "[[1.05040964 0.00967651]]\n",
      "[[ 0.98123772 -0.01643505]]\n",
      "[[ 0.4529625  -0.00372895]]\n",
      "[[1.23096441 0.04081737]]\n",
      "[[0.87049115 0.07338739]]\n",
      "[[1.05720518 0.00737255]]\n",
      "[[1.02625923 0.12718636]]\n",
      "[[ 1.40889759 -0.01978503]]\n",
      "[[ 0.53691789 -0.05699376]]\n",
      "[[1.03237358 0.01499707]]\n",
      "[[0.40861261 0.00264014]]\n",
      "[[0.84544504 0.02100935]]\n",
      "[[ 0.88625158 -0.04853896]]\n",
      "[[ 1.24182073 -0.01681168]]\n",
      "[[ 1.56524611 -0.00738774]]\n",
      "[[ 0.828783   -0.08537772]]\n",
      "[[2.19085    0.00382607]]\n",
      "[[ 0.97993858 -0.07028052]]\n",
      "[[ 0.71220461 -0.03483804]]\n",
      "[[ 0.75060471 -0.0784135 ]]\n",
      "[[0.48834066 0.03638977]]\n",
      "[[ 0.84858439 -0.03552249]]\n",
      "[[ 1.32157214 -0.04825949]]\n",
      "[[ 0.81336553 -0.04299587]]\n",
      "[[0.84711532 0.10995459]]\n",
      "[[1.0672979  0.10114249]]\n",
      "[[ 1.5702916  -0.12862911]]\n",
      "[[ 1.2568153  -0.02939413]]\n",
      "[[1.04281177 0.06347346]]\n",
      "[[ 0.73148606 -0.01687932]]\n",
      "[[ 0.21121323 -0.0107778 ]]\n",
      "[[0.51663625 0.03010044]]\n",
      "[[ 1.07146066 -0.13295445]]\n",
      "[[0.59028635 0.04189321]]\n",
      "[[0.91229273 0.01032327]]\n",
      "[[ 1.2929606  -0.02698733]]\n",
      "[[ 0.53961679 -0.00340043]]\n",
      "[[ 1.40027581 -0.02411358]]\n",
      "[[ 1.32923842 -0.05174993]]\n",
      "[[0.1622045  0.05137131]]\n",
      "[[0.74741168 0.01308043]]\n",
      "[[1.15681505 0.02541624]]\n",
      "[[0.73466124 0.03591155]]\n",
      "[[ 0.67290525 -0.02574499]]\n",
      "[[ 0.51203738 -0.04450947]]\n",
      "[[ 1.17025981 -0.0119614 ]]\n",
      "[[1.13896685 0.03586765]]\n",
      "[[0.87892697 0.00262513]]\n",
      "[[ 1.04287654 -0.01813919]]\n",
      "[[0.85849076 0.04008008]]\n",
      "[[0.70229512 0.05829814]]\n",
      "[[0.72380267 0.00831109]]\n",
      "[[ 1.19066377 -0.0300285 ]]\n",
      "[[ 1.11733136 -0.09195893]]\n",
      "[[ 0.75991983 -0.01307754]]\n",
      "[[ 1.56105611 -0.09945808]]\n",
      "[[ 0.47516074 -0.00861988]]\n",
      "[[ 1.07709524 -0.05017741]]\n",
      "[[0.93764396 0.03675253]]\n",
      "[[0.88286873 0.0410508 ]]\n",
      "[[ 1.0255831  -0.00690055]]\n",
      "[[ 0.8705577  -0.05778158]]\n",
      "[[0.95393133 0.00969342]]\n",
      "[[0.23614481 0.09106887]]\n",
      "[[ 1.10273686e+00 -1.09475931e-03]]\n",
      "[[0.20873346 0.0393076 ]]\n",
      "[[0.206015   0.06120847]]\n",
      "[[ 0.68730102 -0.03182801]]\n",
      "[[1.06506461 0.05153983]]\n",
      "[[ 1.46600483 -0.0359972 ]]\n",
      "[[1.22549102 0.05678937]]\n",
      "[[1.24248174 0.01243303]]\n",
      "[[0.98897264 0.01935278]]\n",
      "[[8.55843589e-01 9.49780418e-05]]\n",
      "[[0.20965699 0.07581115]]\n",
      "[[ 0.86196933 -0.01903191]]\n",
      "[[ 1.14553481 -0.01852374]]\n",
      "[[1.12053561 0.01693015]]\n",
      "[[0.23467721 0.02131863]]\n",
      "[[ 1.25136065 -0.03347067]]\n",
      "[[1.0729496  0.00963666]]\n",
      "[[ 0.81902443 -0.01169124]]\n",
      "[[ 0.66222485 -0.03995369]]\n",
      "[[ 0.4828098  -0.01425062]]\n",
      "[[ 0.38714082 -0.01652808]]\n",
      "[[0.90282751 0.01869691]]\n",
      "[[ 0.62759824 -0.084767  ]]\n",
      "[[ 0.22977693 -0.01945883]]\n",
      "[[0.32425756 0.04760578]]\n",
      "[[ 0.99396436 -0.00470417]]\n",
      "[[0.9846038  0.10198584]]\n",
      "[[ 0.44099796 -0.0017436 ]]\n",
      "[[ 0.93206102 -0.00603565]]\n",
      "[[1.02811458 0.0363069 ]]\n",
      "[[ 1.37815122 -0.10082451]]\n",
      "[[ 0.96756654 -0.00718434]]\n",
      "[[0.4596066  0.01215912]]\n",
      "[[ 1.08654297 -0.02852626]]\n",
      "[[ 0.87505732 -0.07367351]]\n",
      "[[ 1.2280742  -0.00584288]]\n",
      "[[0.32229906 0.01632596]]\n",
      "[[0.91579961 0.0238972 ]]\n",
      "[[ 0.93781191 -0.04678499]]\n",
      "[[ 1.23287249 -0.02947126]]\n",
      "[[ 1.31657    -0.01156999]]\n",
      "[[ 1.10809173 -0.02806858]]\n",
      "[[ 0.94999711 -0.02224939]]\n",
      "[[1.15035152 0.03193265]]\n",
      "[[1.12892229 0.02182206]]\n",
      "[[ 1.31336280e+00 -1.16482394e-03]]\n",
      "[[ 2.1263458  -0.05270657]]\n",
      "[[0.94145718 0.0522577 ]]\n",
      "[[0.90380374 0.08585173]]\n",
      "[[0.92197754 0.02130653]]\n",
      "[[0.87609877 0.00313618]]\n",
      "[[ 1.04083998 -0.032611  ]]\n",
      "[[0.4803131  0.02555242]]\n",
      "[[ 1.19697753 -0.04141421]]\n",
      "[[ 0.791005   -0.04099341]]\n",
      "[[ 0.96230549 -0.01144029]]\n",
      "[[1.04493283 0.00900042]]\n",
      "[[ 1.272631  -0.0074009]]\n",
      "[[1.17685661 0.00686171]]\n",
      "[[ 0.84872864 -0.04762646]]\n",
      "[[ 1.32875485 -0.01498069]]\n",
      "[[ 0.95869757 -0.03854133]]\n",
      "[[1.13295345 0.08374938]]\n",
      "[[ 1.07209626 -0.00566174]]\n",
      "[[0.89770383 0.0553533 ]]\n",
      "[[ 0.84936522 -0.05434506]]\n",
      "[[ 1.4210225  -0.08855409]]\n",
      "[[0.77057859 0.06862132]]\n",
      "[[ 1.51569545 -0.07454298]]\n",
      "[[1.06124262 0.04437375]]\n",
      "[[0.83347203 0.04378091]]\n",
      "[[0.8818252  0.00145462]]\n",
      "[[1.02383135 0.0381136 ]]\n",
      "[[0.52158721 0.00193498]]\n",
      "[[ 0.89810093 -0.01575664]]\n",
      "[[1.19113813 0.07736262]]\n",
      "[[ 0.65373158 -0.0081596 ]]\n",
      "[[ 1.14187878 -0.0297339 ]]\n",
      "[[ 0.8881748  -0.03322149]]\n",
      "[[ 0.8790242 -0.0771094]]\n",
      "[[0.65406901 0.11606853]]\n",
      "[[1.0441287  0.08431057]]\n",
      "[[1.1155269  0.01753216]]\n",
      "[[1.32129451 0.00651421]]\n",
      "[[1.19456659 0.0307719 ]]\n",
      "[[ 0.79239469 -0.00713333]]\n",
      "[[0.86513834 0.06070957]]\n",
      "[[ 1.04168958 -0.00149616]]\n",
      "[[ 0.95566648 -0.00441193]]\n",
      "[[0.85791817 0.03733541]]\n",
      "[[1.17437018 0.03156394]]\n",
      "[[0.93472827 0.05565221]]\n",
      "[[ 1.44479202 -0.0628908 ]]\n",
      "[[ 0.83271357 -0.05493088]]\n",
      "[[0.62163842 0.02055786]]\n",
      "[[ 0.86341582 -0.04103259]]\n",
      "[[ 0.45232149 -0.00114114]]\n",
      "[[0.62677002 0.0074082 ]]\n",
      "[[ 0.918013   -0.00392794]]\n",
      "[[1.28783814 0.00359602]]\n",
      "[[0.92070224 0.06590373]]\n",
      "[[1.11940728 0.04586109]]\n",
      "[[0.44355185 0.03976794]]\n",
      "[[ 1.27370301 -0.04914617]]\n",
      "[[0.54200374 0.02132284]]\n",
      "[[ 0.51820124 -0.01414906]]\n",
      "[[ 1.14938467 -0.06071782]]\n",
      "[[1.21668293 0.02672605]]\n",
      "[[ 0.95108316 -0.00588041]]\n",
      "[[ 0.87293983 -0.25228124]]\n",
      "[[ 0.88067427 -0.00714763]]\n",
      "[[ 0.71808617 -0.00682967]]\n",
      "[[ 1.46747662 -0.05155395]]\n",
      "[[0.92808518 0.04021588]]\n",
      "[[ 0.99994511 -0.01200797]]\n",
      "[[ 0.65879602 -0.0457649 ]]\n",
      "[[ 1.59019458 -0.01261381]]\n",
      "[[0.98584728 0.07855668]]\n",
      "[[ 0.78602561 -0.01793237]]\n",
      "[[ 0.94275468 -0.02153779]]\n",
      "[[0.96611898 0.03722068]]\n",
      "[[1.33721708 0.05421492]]\n",
      "[[1.0683582  0.02752633]]\n",
      "[[ 0.65094046 -0.0155504 ]]\n",
      "[[1.02012118 0.0261554 ]]\n",
      "[[ 1.77523119 -0.08978012]]\n",
      "[[1.22895859 0.04367805]]\n",
      "[[1.024609   0.06740212]]\n",
      "[[ 0.86099517 -0.04420287]]\n",
      "[[ 0.9536702  -0.01032035]]\n",
      "[[ 1.0536379  -0.03517649]]\n",
      "[[1.15606263 0.00513401]]\n",
      "[[0.81272704 0.01727342]]\n",
      "[[ 0.48672043 -0.02546216]]\n",
      "[[0.65416898 0.08021258]]\n",
      "[[0.77617166 0.01059431]]\n",
      "[[0.83658102 0.05946289]]\n",
      "[[0.77580667 0.05651888]]\n",
      "[[1.37016832 0.0170043 ]]\n",
      "[[0.97644654 0.01388447]]\n",
      "[[ 1.46160201 -0.04633262]]\n",
      "[[1.33480342 0.00867726]]\n",
      "[[ 1.82080551 -0.10192682]]\n",
      "[[1.24689472 0.11133619]]\n",
      "[[ 0.43047468 -0.00714792]]\n",
      "[[ 1.03946237 -0.06367672]]\n",
      "[[ 0.68930507 -0.02038279]]\n",
      "[[0.68790939 0.0787892 ]]\n",
      "[[ 0.72974803 -0.06614971]]\n",
      "[[1.09692502 0.00565541]]\n",
      "[[ 1.58857178 -0.04979664]]\n",
      "[[ 0.73897674 -0.00960189]]\n",
      "[[1.1691751  0.05876986]]\n",
      "[[0.88446749 0.01572978]]\n",
      "[[ 1.28080174 -0.02302687]]\n",
      "[[1.05756084 0.01806231]]\n",
      "[[1.17401338 0.07064121]]\n",
      "[[ 1.71894124 -0.13064913]]\n",
      "[[ 0.98641418 -0.02338206]]\n",
      "[[-0.30492239  0.00148079]]\n",
      "[[0.94800767 0.02379888]]\n",
      "[[0.90758479 0.04368433]]\n",
      "[[0.28173047 0.00664783]]\n",
      "[[0.91472987 0.07417914]]\n",
      "[[1.10328963 0.06965284]]\n",
      "[[0.26677458 0.06088831]]\n",
      "[[ 1.52952749 -0.06007211]]\n",
      "[[ 0.88342163 -0.00349349]]\n",
      "[[1.02653393 0.04355186]]\n",
      "[[ 1.17533105 -0.02386606]]\n",
      "[[ 0.84662607 -0.067812  ]]\n",
      "[[1.05282492 0.04589345]]\n",
      "[[0.78098711 0.02073226]]\n",
      "[[ 1.24371516 -0.03343838]]\n",
      "[[ 1.65994796 -0.04310171]]\n",
      "[[ 0.74251788 -0.04185787]]\n",
      "[[ 1.09764113 -0.02705705]]\n",
      "[[0.80976779 0.00502081]]\n",
      "[[ 1.17883859 -0.01931665]]\n",
      "[[0.97181106 0.07998687]]\n",
      "[[1.15095105 0.01268818]]\n",
      "[[0.93003901 0.00979517]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12969618e+00 8.20299350e-04]]\n",
      "[[0.72533604 0.06207415]]\n",
      "[[0.90331191 0.01196432]]\n",
      "[[ 1.15813342 -0.04568495]]\n",
      "[[ 0.92672348 -0.04328592]]\n",
      "[[0.55101839 0.08598244]]\n",
      "[[ 1.00349764 -0.051604  ]]\n",
      "[[ 7.84423395e-01 -5.83530074e-04]]\n",
      "[[0.71208081 0.07239722]]\n",
      "[[0.30861491 0.26097271]]\n",
      "[[ 0.52900286 -0.0888156 ]]\n",
      "[[0.96461163 0.00937016]]\n",
      "[[0.17948205 0.03016967]]\n",
      "[[ 1.33490809 -0.03141734]]\n",
      "[[1.10648118 0.00404322]]\n",
      "[[ 1.03077349 -0.01030724]]\n",
      "[[0.94641129 0.05527681]]\n",
      "[[0.3283804  0.04140402]]\n",
      "[[ 1.3488315  -0.04723728]]\n",
      "[[0.61456743 0.06349997]]\n",
      "[[ 0.85215624 -0.01185122]]\n",
      "[[0.70408654 0.02167737]]\n",
      "[[ 1.4187817 -0.0090648]]\n",
      "[[0.26181956 0.02246174]]\n",
      "[[0.36747218 0.06890689]]\n",
      "[[ 1.03862414 -0.03418474]]\n",
      "[[ 1.00264592 -0.00247819]]\n",
      "[[1.44611701e+00 9.31506665e-04]]\n",
      "[[ 1.14793148 -0.21200067]]\n",
      "[[1.12790559 0.0061275 ]]\n",
      "[[0.77604195 0.04010972]]\n",
      "[[ 1.3408859  -0.03036535]]\n",
      "[[ 1.31128872 -0.04497727]]\n",
      "[[0.36932388 0.03850791]]\n",
      "[[0.50443787 0.03952733]]\n",
      "[[ 0.98253225 -0.044861  ]]\n",
      "[[ 1.45723412 -0.05795539]]\n",
      "[[0.62930219 0.01650947]]\n",
      "[[0.75509503 0.03721595]]\n",
      "[[1.13964819 0.06822684]]\n",
      "[[1.14228587 0.04900247]]\n",
      "[[0.94999689 0.03760477]]\n",
      "[[ 0.96611553 -0.00953713]]\n",
      "[[1.17036451 0.01887754]]\n",
      "[[1.07107849 0.04123716]]\n",
      "[[1.28006579 0.05015241]]\n",
      "[[ 0.72904255 -0.00942769]]\n",
      "[[ 1.14438125 -0.0179582 ]]\n",
      "[[1.44829232 0.02957318]]\n",
      "[[ 0.9154693  -0.01479437]]\n",
      "[[0.320706   0.00500861]]\n",
      "[[0.77174775 0.03082082]]\n",
      "[[1.01503863 0.02621049]]\n",
      "[[0.57303203 0.04123282]]\n",
      "[[ 1.5890454  -0.09576701]]\n",
      "[[0.65391888 0.02516614]]\n",
      "[[0.95838406 0.01844298]]\n",
      "[[0.23551938 0.07845874]]\n",
      "[[ 0.96336723 -0.04758087]]\n",
      "[[1.10199551 0.02586355]]\n",
      "[[0.97968015 0.07748697]]\n",
      "[[ 1.35911595 -0.06744891]]\n",
      "[[0.73257787 0.03128145]]\n",
      "[[0.8502429  0.08221674]]\n",
      "[[ 1.27130552e+00 -3.77184898e-04]]\n",
      "[[ 1.03319021 -0.04039789]]\n",
      "[[0.9361904  0.06193814]]\n",
      "[[0.50819291 0.05445951]]\n",
      "[[1.16711398e+00 1.08751866e-03]]\n",
      "[[ 0.980506  -0.0499353]]\n",
      "[[ 0.89086827 -0.01980197]]\n",
      "[[1.07394618 0.0097252 ]]\n",
      "[[1.72003116 0.02803872]]\n",
      "[[ 1.1965978  -0.03702365]]\n",
      "[[ 1.22359752 -0.00346127]]\n",
      "[[ 1.22973001 -0.01353095]]\n",
      "[[0.41691107 0.01951941]]\n",
      "[[ 0.69714005 -0.03195929]]\n",
      "[[0.43778213 0.08586533]]\n",
      "[[ 1.14168448 -0.00768157]]\n",
      "[[ 0.80218806 -0.05003762]]\n",
      "[[0.94645673 0.00610835]]\n",
      "[[0.97188218 0.07516572]]\n",
      "[[0.91223821 0.06834907]]\n",
      "[[ 0.88620304 -0.00874462]]\n",
      "[[0.94996121 0.01285289]]\n",
      "[[ 0.98701868 -0.06807589]]\n",
      "[[1.16471963 0.10632412]]\n",
      "[[0.53067918 0.04721514]]\n",
      "[[ 1.09557498 -0.03401627]]\n",
      "[[ 0.6356248  -0.00188457]]\n",
      "[[ 1.02668294 -0.09474373]]\n",
      "[[ 1.16640902 -0.01570731]]\n",
      "[[1.06281665 0.05375818]]\n",
      "[[ 1.10825778 -0.01121769]]\n",
      "[[ 0.86478153 -0.03049559]]\n",
      "[[ 0.82557659 -0.01129225]]\n",
      "[[1.61847217 0.00576912]]\n",
      "[[0.78164186 0.02426844]]\n",
      "[[ 1.33968213 -0.08704394]]\n",
      "[[ 0.9198664  -0.00990734]]\n",
      "[[1.09506479 0.03978959]]\n",
      "[[0.84570172 0.02976569]]\n",
      "[[0.3503151  0.01474112]]\n",
      "[[0.96030472 0.05590764]]\n",
      "[[ 0.80822228 -0.02292449]]\n",
      "[[ 0.51942664 -0.01476696]]\n",
      "[[1.11613389 0.04835673]]\n",
      "[[1.24859078 0.02949613]]\n",
      "[[0.4928291  0.02372951]]\n",
      "[[1.00578305 0.04940428]]\n",
      "[[ 0.70874942 -0.08283728]]\n",
      "[[0.86554757 0.08332619]]\n",
      "[[ 0.64055371 -0.0090636 ]]\n",
      "[[0.87081118 0.05420037]]\n",
      "[[0.17790673 0.03269807]]\n",
      "[[ 1.22616309 -0.04579557]]\n",
      "[[ 1.47191783 -0.08782848]]\n",
      "[[ 0.93256185 -0.01659512]]\n",
      "[[ 0.7436731  -0.02198431]]\n",
      "[[1.04612986 0.05720096]]\n",
      "[[1.27925297 0.08574912]]\n",
      "[[0.81141186 0.03730646]]\n",
      "[[1.5218713  0.01573344]]\n",
      "[[0.22054821 0.0232874 ]]\n",
      "[[ 1.10292317 -0.01642392]]\n",
      "[[1.24839245 0.13921284]]\n",
      "[[1.04870347 0.01320777]]\n",
      "[[0.8692402  0.06411041]]\n",
      "[[0.77274481 0.07613115]]\n",
      "[[1.26207964 0.00851515]]\n",
      "[[0.90009482 0.0318328 ]]\n",
      "[[1.00000000e+00 4.28381481e-18]]\n"
     ]
    }
   ],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map_vwap_close_reverse = {}\n",
    "mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "X1 = data_training_return['SPY'][mask]['close_open_return'][1:].to_numpy()\n",
    "X1 = np.expand_dims(X1, axis=1)\n",
    "        \n",
    "X0 = data_training_return['SPY'][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y1 =  data_training_return[symbol][mask]['close_open_return'][1:].to_numpy()\n",
    "        y1 = np.expand_dims(y1, axis=1)\n",
    "        y0 = data_training_return[symbol][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "        y0 = np.expand_dims(y0, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if symbol in reg_map:\n",
    " \n",
    "            pred = reg_map[symbol].predict(X0)\n",
    "            pred = np.expand_dims(pred, axis=1)\n",
    "            error = y0-pred\n",
    "           # print(X1.shape, y0.shape, y1.shape, error.shape)\n",
    " \n",
    "            X = np.concatenate([X1, error], axis=1)\n",
    "         \n",
    "            #if len(dates_X)>0 and X.shape[0] == len(dates_X):\n",
    "            reg = LinearRegression().fit(X, y1)\n",
    "            reg_map_vwap_close_reverse[symbol] = reg\n",
    "            print(reg.coef_)\n",
    "\n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= 0.0003\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k= 5\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    if index+1 <len(testing_dates):\n",
    "        for symbol in symbols:\n",
    "\n",
    "\n",
    "            if symbol in reg_map and symbol in reg_map_vwap_close_reverse and symbol !='SPY':\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #             try:\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date     \n",
    " \n",
    " \n",
    "                y0 = data_training_return[symbol][mask]['vwap_close_return'].to_numpy()\n",
    "                y0 = np.expand_dims(y0, axis=1)\n",
    "        \n",
    "        \n",
    "                mask = data_training_return['SPY']['Date'] == date     \n",
    "                X0 = data_training_return['SPY'][mask]['vwap_close_return'] \n",
    "                X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "                X1 =  np.zeros([len(X0),1])\n",
    "                #print(X1.shape, y0.shape)\n",
    "                if X1.shape == y0.shape:\n",
    "\n",
    "                    pred0  = reg_map[symbol].predict(X0)\n",
    "                    pred0  = np.expand_dims(pred0, axis=1)\n",
    "                    error = y0-pred0\n",
    "                    #print(\"pred0 shape\", pred0.shape)\n",
    "                    X = np.concatenate([X1, error], axis=1)\n",
    "\n",
    "                    pred = reg_map_vwap_close_reverse[symbol].predict(X)\n",
    "                    #print(\"pred .shape\", pred.shape)\n",
    "\n",
    "                    error_map[pred[0][0]] = symbol\n",
    "    #             except:\n",
    "    #                 pass\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range(k):\n",
    "            if j< len(error_list) and index <len(testing_dates) -1:   \n",
    "                symbol = error_list[j][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                #Here use the previouse date for the return from close to open for conevnience of VIX calculation\n",
    "                result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                symbol = error_list[-j-1][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  -0.0009509922910564214\n",
      "Sharp ratio:  -1.3275444756508763\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.2734\n",
      "Date:                Sun, 06 Dec 2020   Prob (F-statistic):              0.602\n",
      "Time:                        19:17:57   Log-Likelihood:                 765.73\n",
      "No. Observations:                 250   AIC:                            -1527.\n",
      "Df Residuals:                     248   BIC:                            -1520.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0004      0.002      0.233      0.816      -0.003       0.003\n",
      "Close      -2.683e-05   5.13e-05     -0.523      0.602      -0.000    7.42e-05\n",
      "==============================================================================\n",
      "Omnibus:                      128.222   Durbin-Watson:                   2.255\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3989.408\n",
      "Skew:                           1.374   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.376   Cond. No.                         63.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fef993b67f0>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.Performance(result, c)\n",
    "pm.VIX(result, 'Close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63596469]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# X, y = make_regression(n_features=4, n_informative=2,\n",
    "#                        random_state=0, shuffle=False)\n",
    "# regr = RandomForestRegressor(n_estimators=1000,max_depth=100, criterion='mae',random_state=0)\n",
    "# regr.fit(X, y)\n",
    "\n",
    "# print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "c = 0\n",
    "for index, date in enumerate(dates[:-testing_length]):\n",
    "    if c>=1000:\n",
    "        break\n",
    "    if index>=history-1:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "             \n",
    " \n",
    "        if data_training[mask]['Open'].to_numpy()[0]:\n",
    "            sample_spy.append(data_training[mask]['Open'].to_numpy()[0])  \n",
    "            for symbol in symbols:\n",
    "                c +=1\n",
    "                if c>=1000:\n",
    "                    break\n",
    "                try:\n",
    "                    sample = []\n",
    "                    mask = data_training['Symbol'] == symbol\n",
    "                    mask &= data_training['Date']<date\n",
    "                    mask &= data_training['Date']>= dates[index-history+1]\n",
    "                    sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                    sample +=sample_spy\n",
    "\n",
    "\n",
    "\n",
    "                    mask = data_training_return[symbol]['Date'] == date\n",
    "\n",
    "                    r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                    if sample and r:\n",
    "                        X.append(sample)\n",
    "                        y.append(r)\n",
    "\n",
    "                except:\n",
    "                    print(symbol, date)\n",
    "    #                 print(data_training_return[symbol]['Date'] )\n",
    "    #                 raise\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-94577dfce90c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[0;32m--> 303\u001b[0;31m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    " \n",
    "regr = RandomForestRegressor(n_estimators=1000,max_depth=100, criterion='mae',random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "k=5\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "result = np.zeros(testing_length)\n",
    "print(len(dates))\n",
    "for index, date in enumerate(dates ):\n",
    " \n",
    "    if index>=len(dates)-testing_length:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "        sample_spy.append(data_training[mask]['Open'].to_numpy()[0]) \n",
    "        print(sample_spy)\n",
    "        symbol_return = {}\n",
    "        symbol_pred_return = {}\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                sample = []\n",
    "                mask = data_training['Symbol'] == symbol\n",
    "                mask &= data_training['Date']<date\n",
    "                mask &= data_training['Date']>= dates[index-history+1]\n",
    "                sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                sample +=sample_spy\n",
    "                \n",
    "\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "         \n",
    "                r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                if sample and r:\n",
    "                    X.append(sample)\n",
    "                    symbol_pred_return[symbol] = regr.predict(X)\n",
    "                    symbol_return[symbol] = r \n",
    "                \n",
    "            except:\n",
    "                print(\"Error\", symbol, date)\n",
    "#                 print(data_training_return[symbol]['Date'] )\n",
    "#                 raise\n",
    "        error_map = {}\n",
    "        for symbol in  symbol_return:\n",
    "            error_map[symbol] = symbol_return[symbol] - symbol_pred_return[symbol]\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "       # print(error_list)\n",
    "        if len(error_list)>=k:\n",
    "            for j in range(k): \n",
    "                symbol = error_list[j][1]\n",
    "                print(symbol)\n",
    "                result[index-len(dates)+testing_length] +=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "                symbol = error_list[-j-1][1]\n",
    "                result[index-len(dates)+testing_length] -=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "    X=np.array(X)\n",
    "y=np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "Performance(result, c)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
