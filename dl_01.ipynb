{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AGN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- APC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BHGE: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BBT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: 1d data not available for startTime=-2208988800 and endTime=1611787380. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBG: 1d data not available for startTime=-2208988800 and endTime=1611787384. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CBS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CELG: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DWDP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DPS: 1d data not available for startTime=-2208988800 and endTime=1611787408. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GGP: 1d data not available for startTime=-2208988800 and endTime=1611787434. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HRS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCP: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JEC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LLL: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LUK: 1d data not available for startTime=-2208988800 and endTime=1611787468. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KORS: 1d data not available for startTime=-2208988800 and endTime=1611787485. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCLN: 1d data not available for startTime=-2208988800 and endTime=1611787521. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RTN: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RHT: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SYMC: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TMK: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TSS: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UTX: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HCN: 1d data not available for startTime=-2208988800 and endTime=1611787592. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WYN: 1d data not available for startTime=-2208988800 and endTime=1611787597. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-01-02</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>1.483333</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-01-05</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>6.859375</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>1.491789</td>\n",
       "      <td>446400.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-01-06</td>\n",
       "      <td>6.890625</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>6.882812</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>1.507011</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-01-07</td>\n",
       "      <td>6.960938</td>\n",
       "      <td>7.015625</td>\n",
       "      <td>6.945312</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.515469</td>\n",
       "      <td>164800.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-01-08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.109375</td>\n",
       "      <td>6.984375</td>\n",
       "      <td>7.093750</td>\n",
       "      <td>1.535765</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0 1970-01-02  6.851562  6.890625  6.843750  6.851562   1.483333   72000.0   \n",
       "1 1970-01-05  6.859375  6.898438  6.859375  6.890625   1.491789  446400.0   \n",
       "2 1970-01-06  6.890625  6.960938  6.882812  6.960938   1.507011  176000.0   \n",
       "3 1970-01-07  6.960938  7.015625  6.945312  7.000000   1.515469  164800.0   \n",
       "4 1970-01-08  7.000000  7.109375  6.984375  7.093750   1.535765  304000.0   \n",
       "\n",
       "  Symbol  \n",
       "0    MMM  \n",
       "1    MMM  \n",
       "2    MMM  \n",
       "3    MMM  \n",
       "4    MMM  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload \n",
    "\n",
    "import util.performance_metrics as pm\n",
    " \n",
    "reload(pm)\n",
    "\n",
    "url =  \"https://raw.githubusercontent.com/xuda1979/DF/master/sp500_companies/data/constituents.csv\"\n",
    "df_symbols =pd.read_csv('./sp500_companies/data/constituents.csv')\n",
    "\n",
    "df_symbols.head()\n",
    "all_symbols = list(df_symbols['Symbol'].unique())\n",
    "all_symbols.append('SPY')\n",
    "\n",
    "# Import yfinance\n",
    "import yfinance as yf  \n",
    " \n",
    "# Get the data for the stock Apple by specifying the stock ticker, start date, and end date\n",
    "data_all =pd.DataFrame({})\n",
    "for symbol in all_symbols:\n",
    "    \n",
    "    data = yf.download(symbol)#,'2016-01-01','2018-01-01')\n",
    "    data['Symbol'] = symbol\n",
    "    if(len(data)>0):\n",
    "        data_all = pd.concat([data_all,data])\n",
    " \n",
    "\n",
    "vix=yf.download('^VIX')\n",
    "\n",
    "symbols = list(data_all['Symbol'].unique())\n",
    "\n",
    "data_all.reset_index(inplace=True)\n",
    "\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_date = '2015-01-15'\n",
    "training_end_date = '2020-09-30'\n",
    "mask = data_all['Date'] >= training_start_date\n",
    "mask &= data_all['Date'] <= training_end_date\n",
    "\n",
    "data_training= data_all[mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_filter(df, start_date, end_date):\n",
    "    mask = df['Date'] >=  start_date\n",
    "    mask &= df['Date'] <= end_date\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.85042934e-04 7.44584306e-06]\n",
      " [7.44584306e-06 3.88371563e-04]]\n"
     ]
    }
   ],
   "source": [
    "def covariance(df, date, symbols, history):\n",
    "    df_recent = pd.DataFrame({})\n",
    "    dates = list(df['Date'].unique())\n",
    "    dates.sort()\n",
    "    df_recent['Date']= dates[-(history+1):-1]\n",
    "    for symbol in symbols:\n",
    "        mask = df['Symbol'] == symbol\n",
    " \n",
    "        if all([date in list(df[mask]['Date'].unique()) for date in dates[-(history+1):-1]]):\n",
    "            #print(df[mask]['Close'][-(history+1):-1])\n",
    "            df_recent[symbol] = df[mask]['Close'].to_list()[-(history+1):-1]\n",
    "    df_return = pd.DataFrame({})\n",
    "    df_return['Date'] = df_recent['Date']\n",
    "    for symbol in df_recent.columns:\n",
    "        if symbol !='Date':\n",
    "            #print(symbol,df_recent[symbol].div(df_recent[symbol].shift(1)))\n",
    "            df_return[symbol] = df_recent[symbol].div(df_recent[symbol].shift(1))\n",
    "    return df_return[1:].set_index('Date').cov() \n",
    " \n",
    "            \n",
    "symbols = ['AAPL', 'MMM']\n",
    "df_cov = covariance(data_training, list(data_training['Date'].unique())[-1], symbols, 10)\n",
    "cov=df_cov.to_numpy() \n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.0006603349124938092\n",
      "            Iterations: 2\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-988-e88c3116b488>:11: OptimizeWarning: Unknown solver options: gtol\n",
      "  res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25038093, 1.24961907])"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(x):\n",
    "    l = len(x)\n",
    "    assert l == cov.shape[0]\n",
    "    return x.dot(cov.dot(x))\n",
    "\n",
    "def constraint(x):\n",
    "    return np.atleast_1d(np.sum(np.abs(x)) - 1.5)\n",
    "\n",
    " \n",
    "bounds=[[0, 1], [1, 2]]\n",
    "res=optimize.minimize(objective, np.array([0, 0]), constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': True}, bounds=bounds )\n",
    "res.x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def portfolio_optimization(cov, k):        \n",
    " \n",
    "    assert 2*k == cov.shape[0]\n",
    "    def objective(x):\n",
    "        return x.dot(cov.dot(x))\n",
    "\n",
    "    def constraint(x):\n",
    "        return np.atleast_1d(np.sum(np.abs(x))-1)\n",
    "    x0 = [1/(2*k)]*k+[-1/(2*k)]*k\n",
    "    x0 = np.array(x0)\n",
    "    bounds = []\n",
    "    for i in range(k):\n",
    "        bounds.append([1/(4*k),1/k])\n",
    "    for i in range(k):\n",
    "        bounds.append([-1/k, -1/(4*k)])\n",
    "        \n",
    "    res=optimize.minimize(objective, x0, constraints={\"fun\": constraint, \"type\": \"ineq\"},options={'gtol': 1e-8, 'disp': False}, bounds=bounds )\n",
    "    s= sum(np.abs(res.x))\n",
    "    return res.x/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training_return = {}\n",
    " \n",
    "for symbol in symbols:\n",
    "#     print(symbol)\n",
    "    mask = data_training['Symbol'] == symbol\n",
    "    data_training_return[symbol] = pd.DataFrame({})\n",
    "    data_training_return[symbol]['Date'] = data_training[mask]['Date']\n",
    "    \n",
    "    data_training_return[symbol]['close_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Close'].shift(1))-1  \n",
    "    data_training_return[symbol]['open_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Open'] )-1\n",
    "    data_training_return[symbol]['close_open_return']  = data_training[mask]['Open'].div(data_training[mask]['Close'].shift(1) )-1\n",
    "    data_training_return[symbol]['vwap_open_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['High'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Low'].shift(1)+ \\\n",
    "                                                                                        data_training[mask]['Close'].shift(1))-1\n",
    "    \n",
    "    data_training_return[symbol]['vwap_close_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open']+ \\\n",
    "                                                                                        data_training[mask]['High']+ \\\n",
    "                                                                                        data_training[mask]['Low']+ \\\n",
    "                                                                                        data_training[mask]['Close'])-1\n",
    "    \n",
    "    \n",
    "    data_training_return[symbol].fillna(0, inplace=True)\n",
    "    data_training_return[symbol].reset_index(inplace=True,drop=True)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model in sm\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][ :-testing_length])\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = data_training_return['SPY']['close_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "sm_reg_map = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y =  data_training_return[symbol][mask]['close_close_return'] \n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_here = data_training_return['SPY'][mask]['close_close_return'] \n",
    "        X_here = np.expand_dims(X_here, axis=1)\n",
    "       # print(X_here.shape, y.shape, symbol)\n",
    "        if X_here.shape[0] == len(dates_X):\n",
    "            X_here = sm.add_constant(X_here)\n",
    "           # print(X_here)\n",
    "            model = sm.RLM(y,X_here)#,M=sm.robust.norms.TrimmedMean())\n",
    "            results = model.fit()\n",
    "#             print(results.params[0])\n",
    "            sm_reg_map[symbol] = results\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Reverse Effect at opening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with mean reverse effcet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model in sm\n",
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    " \n",
    "X_open_close = data_training_return['SPY']['open_close_return'] \n",
    "X_close_open = data_training_return['SPY']['open_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "sm_reg_map_reverse = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y_open_close =  data_training_return[symbol][mask]['open_close_return']\n",
    "#         y_open_close = np.expand_dims(y_open_close, axis=1)\n",
    "        y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "        y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "        mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "        X_open_close = data_training_return['SPY'][mask]['open_close_return'] \n",
    "        X_open_close = np.expand_dims(X_open_close, axis=1)\n",
    "        \n",
    "        X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "        X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "        \n",
    "        if symbol in sm_reg_map:\n",
    " \n",
    "            X_close_open = sm.add_constant(X_close_open)\n",
    "            pred_close_open = sm_reg_map[symbol].predict(X_close_open)\n",
    "            pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "            error_close_open = y_close_open-pred_close_open\n",
    "  \n",
    "            X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    " \n",
    "            if len(X)>0 and X.shape[0] == len(y_open_close):\n",
    "\n",
    "                X  = sm.add_constant(X)\n",
    "                model = sm.RLM(y_open_close,X)\n",
    "                results = model.fit()\n",
    "                sm_reg_map_reverse[symbol] = results\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade at Open(close-open error as regressor)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering reverse coefficient and its t-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_set=set(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy EQT\n",
      "sell HPQ\n",
      "buy ZBH\n",
      "sell CBOE\n",
      "buy CMCSA\n",
      "sell JBHT\n",
      "buy TMO\n",
      "sell TEL\n",
      "buy HUM\n",
      "sell PCG\n",
      "buy FAST\n",
      "sell ES\n",
      "buy DHR\n",
      "sell EXPD\n",
      "buy UNH\n",
      "sell JBHT\n",
      "buy USB\n",
      "sell CDNS\n",
      "buy MS\n",
      "sell TXT\n",
      "buy ETFC\n",
      "sell CBOE\n",
      "buy GT\n",
      "sell BDX\n",
      "buy CDNS\n",
      "sell TRV\n",
      "buy TMO\n",
      "sell TXN\n",
      "buy FFIV\n",
      "sell EBAY\n",
      "buy CHTR\n",
      "sell PFG\n",
      "buy MSFT\n",
      "sell PCG\n",
      "buy SPGI\n",
      "sell WAT\n",
      "buy MAT\n",
      "sell CHRW\n",
      "buy LKQ\n",
      "sell FLIR\n",
      "buy CBOE\n",
      "sell STX\n",
      "buy EQT\n",
      "sell FLIR\n",
      "buy ZBH\n",
      "sell BDX\n",
      "buy HPQ\n",
      "sell PCG\n",
      "buy FISV\n",
      "sell ANSS\n",
      "buy APD\n",
      "sell MTD\n",
      "buy WBA\n",
      "sell INFO\n",
      "buy ROK\n",
      "sell AZO\n",
      "buy PCG\n",
      "sell CTAS\n",
      "buy FISV\n",
      "sell CSCO\n",
      "buy DHR\n",
      "sell CNP\n",
      "buy PCG\n",
      "sell JBHT\n",
      "buy CBOE\n",
      "sell HD\n",
      "buy HOLX\n",
      "sell HSIC\n",
      "buy DISH\n",
      "sell ETFC\n",
      "buy SPGI\n",
      "sell INTU\n",
      "buy EBAY\n",
      "sell COG\n",
      "buy NWSA\n",
      "sell HOLX\n",
      "buy NWS\n",
      "sell CERN\n",
      "buy INCY\n",
      "sell FTI\n",
      "buy NBL\n",
      "sell CBOE\n",
      "buy NWSA\n",
      "sell ANSS\n",
      "buy ZBH\n",
      "sell PKI\n",
      "buy PDCO\n",
      "sell FFIV\n",
      "buy ALXN\n",
      "sell COO\n",
      "buy PCG\n",
      "sell COG\n",
      "buy AZO\n",
      "sell MKC\n",
      "buy SLG\n",
      "sell HD\n",
      "buy GE\n",
      "sell ANSS\n",
      "buy PPL\n",
      "sell PBCT\n",
      "buy CTAS\n",
      "sell PCG\n",
      "buy NBL\n",
      "sell BAX\n",
      "buy PCG\n",
      "sell EXPD\n",
      "buy ECL\n",
      "sell PCAR\n",
      "buy CBOE\n",
      "sell FFIV\n",
      "buy NWSA\n",
      "sell ROK\n",
      "buy PDCO\n",
      "sell ANSS\n",
      "buy EQT\n",
      "sell FISV\n",
      "buy DVN\n",
      "sell VNO\n",
      "buy GT\n",
      "sell AVB\n",
      "buy NWSA\n",
      "sell CBOE\n",
      "buy MTD\n",
      "sell ANSS\n",
      "buy COG\n",
      "sell INCY\n",
      "buy LMT\n",
      "sell JBHT\n",
      "buy PDCO\n",
      "sell CB\n",
      "buy A\n",
      "sell WAT\n",
      "buy C\n",
      "sell MKC\n",
      "buy ISRG\n",
      "sell TRV\n",
      "buy BAX\n",
      "sell CI\n",
      "buy DAL\n",
      "sell INFO\n",
      "buy PCG\n",
      "sell USB\n",
      "buy MS\n",
      "sell CHTR\n",
      "buy CMCSA\n",
      "sell EXPD\n",
      "buy JBHT\n",
      "sell MS\n",
      "buy CBOE\n",
      "sell NTRS\n",
      "buy CTXS\n",
      "sell VFC\n",
      "buy ZTS\n",
      "sell SYF\n",
      "buy AOS\n",
      "sell HSIC\n",
      "buy NUE\n",
      "sell JNPR\n",
      "buy GE\n",
      "sell ADP\n",
      "buy MSFT\n",
      "sell PKG\n",
      "buy AMZN\n",
      "sell WY\n",
      "buy ANSS\n",
      "sell NOC\n",
      "buy GT\n",
      "sell WAT\n",
      "buy CB\n",
      "sell FISV\n",
      "buy CAH\n",
      "sell BDX\n",
      "buy NOV\n",
      "sell EBAY\n",
      "buy L\n",
      "sell LLY\n",
      "buy DISH\n",
      "sell GT\n",
      "buy IQV\n",
      "sell WU\n",
      "buy INCY\n",
      "sell NTAP\n",
      "buy EBAY\n",
      "sell AIG\n",
      "buy KR\n",
      "sell ALLE\n",
      "buy GRMN\n",
      "sell VRSK\n",
      "buy ETFC\n",
      "sell SNPS\n",
      "buy EQIX\n",
      "sell COG\n",
      "buy WLTW\n",
      "sell MA\n",
      "buy PRGO\n",
      "sell AOS\n",
      "buy TJX\n",
      "sell NI\n",
      "buy PDCO\n",
      "sell ANSS\n",
      "buy CBOE\n",
      "sell AES\n",
      "buy MA\n",
      "sell FISV\n",
      "buy DAL\n",
      "sell AZO\n",
      "buy CI\n",
      "sell NWSA\n",
      "buy V\n",
      "sell MPC\n",
      "buy COO\n",
      "sell FISV\n",
      "buy WLTW\n",
      "sell XEC\n",
      "buy OXY\n",
      "sell XYL\n",
      "buy CBOE\n",
      "sell ROK\n",
      "buy JBHT\n",
      "sell PNW\n",
      "buy CCL\n",
      "sell CDNS\n",
      "buy NWSA\n",
      "sell ROP\n",
      "buy HOLX\n",
      "sell NWS\n",
      "buy NWSA\n",
      "sell CTAS\n",
      "buy NBL\n",
      "sell VNO\n",
      "buy GT\n",
      "sell NWSA\n",
      "buy FTI\n",
      "sell CB\n",
      "buy INFO\n",
      "sell ALLE\n",
      "buy DAL\n",
      "sell SLG\n",
      "buy BLL\n",
      "sell CBOE\n",
      "buy ABT\n",
      "sell PAYX\n",
      "buy PKI\n",
      "sell FTI\n",
      "buy MPC\n",
      "sell CCL\n",
      "buy AON\n",
      "sell CNP\n",
      "buy MPC\n",
      "sell ESS\n",
      "buy XEC\n",
      "sell PDCO\n",
      "buy VNO\n",
      "sell CTXS\n",
      "buy CCL\n",
      "sell NWSA\n",
      "buy NBL\n",
      "sell ALLE\n",
      "buy NAVI\n",
      "sell FLIR\n",
      "buy FTI\n",
      "sell NDAQ\n",
      "buy FAST\n",
      "sell INFO\n",
      "buy JBHT\n",
      "sell VNO\n",
      "buy FISV\n",
      "sell EQIX\n",
      "buy INFO\n",
      "sell CTXS\n",
      "buy FLIR\n",
      "sell UDR\n",
      "buy LH\n",
      "sell CB\n",
      "buy CDNS\n",
      "sell ABT\n",
      "buy NDAQ\n",
      "sell CTXS\n",
      "buy PBCT\n",
      "sell EQR\n",
      "buy LH\n",
      "sell CB\n",
      "buy ROP\n",
      "sell CINF\n",
      "buy SLG\n",
      "sell LH\n",
      "buy HOLX\n",
      "sell CMCSA\n",
      "buy FBHS\n",
      "sell WY\n",
      "buy COG\n",
      "sell DAL\n",
      "buy MPC\n",
      "sell XYL\n",
      "buy FLIR\n",
      "sell VNO\n",
      "buy CNP\n",
      "sell ANSS\n",
      "buy NWSA\n",
      "sell CTSH\n",
      "buy CAH\n",
      "sell NTAP\n",
      "buy ES\n",
      "sell BLK\n",
      "buy LH\n",
      "sell NWS\n",
      "buy CTAS\n",
      "sell FTI\n",
      "buy MCO\n",
      "sell PAYX\n",
      "buy SLG\n",
      "sell CDNS\n",
      "buy AZO\n",
      "sell CBOE\n",
      "buy ADI\n",
      "sell BDX\n",
      "buy TJX\n",
      "sell ALLE\n",
      "buy A\n",
      "sell INTU\n",
      "buy SLG\n",
      "sell EQT\n",
      "buy VNO\n",
      "sell ANSS\n",
      "buy BDX\n",
      "sell HPQ\n",
      "buy PCG\n",
      "sell PFG\n",
      "buy TEL\n",
      "sell PFE\n",
      "buy WU\n",
      "sell CB\n",
      "buy MAT\n",
      "sell SBAC\n",
      "buy EBAY\n",
      "sell INFO\n",
      "buy AAL\n",
      "sell CTXS\n",
      "buy NBL\n",
      "sell ANSS\n",
      "buy HOLX\n",
      "sell WY\n",
      "buy FLIR\n",
      "sell DAL\n",
      "buy CDNS\n",
      "sell SLG\n",
      "buy VNO\n",
      "sell CERN\n",
      "buy CDNS\n",
      "sell SLG\n",
      "buy VNO\n",
      "sell CTXS\n",
      "buy JBHT\n",
      "sell CCL\n",
      "buy MYL\n",
      "sell PFG\n",
      "buy MPC\n",
      "sell NWSA\n",
      "buy ANSS\n",
      "sell AAL\n",
      "buy JBHT\n",
      "sell CBOE\n",
      "buy PDCO\n",
      "sell CCL\n",
      "buy SNPS\n",
      "sell VNO\n",
      "buy GPS\n",
      "sell PBCT\n",
      "buy NAVI\n",
      "sell CDNS\n",
      "buy EQIX\n",
      "sell CBOE\n",
      "buy PFE\n",
      "sell GT\n",
      "buy VNO\n",
      "sell ANSS\n",
      "buy PAYX\n",
      "sell D\n",
      "buy APD\n",
      "sell CBOE\n",
      "buy FTI\n",
      "sell CB\n",
      "buy PNR\n",
      "sell WBA\n",
      "buy PBCT\n",
      "sell INFO\n",
      "buy PFE\n",
      "sell ADI\n",
      "buy XYL\n",
      "sell PAYX\n",
      "buy FLIR\n",
      "sell CTXS\n",
      "buy PKI\n",
      "sell CCL\n",
      "buy JBHT\n",
      "sell CDNS\n",
      "buy NBL\n",
      "sell AVB\n",
      "buy LMT\n",
      "sell NDAQ\n",
      "buy NAVI\n",
      "sell FE\n",
      "buy DHR\n",
      "sell CTXS\n",
      "buy CMCSA\n",
      "sell GRMN\n",
      "buy PBCT\n",
      "sell EQT\n",
      "buy PFG\n",
      "sell IQV\n",
      "buy PKI\n",
      "sell ADP\n",
      "buy HOLX\n",
      "sell BAX\n",
      "buy CHTR\n",
      "sell PBCT\n",
      "buy VAR\n",
      "sell L\n",
      "buy VNO\n",
      "sell ZBH\n",
      "buy COG\n",
      "sell EXPD\n",
      "buy FISV\n",
      "sell BDX\n",
      "buy FLIR\n",
      "sell ILMN\n",
      "buy MGM\n",
      "sell SPGI\n",
      "buy PBCT\n",
      "sell CDNS\n",
      "buy FTI\n",
      "sell ANSS\n",
      "buy FLIR\n",
      "sell CSCO\n",
      "buy EQT\n",
      "sell MTD\n",
      "buy LOW\n",
      "sell PBCT\n",
      "buy ORCL\n",
      "sell NWSA\n",
      "buy TGT\n",
      "sell TJX\n",
      "buy SNPS\n",
      "sell INFO\n",
      "buy SBAC\n",
      "sell AJG\n",
      "buy NWSA\n",
      "sell APH\n",
      "buy MDT\n",
      "sell SNPS\n",
      "buy CRM\n",
      "sell ANSS\n",
      "buy NTAP\n",
      "sell HOLX\n",
      "buy HPQ\n",
      "sell FRT\n",
      "buy DISH\n",
      "sell CERN\n",
      "buy PKI\n",
      "sell COG\n",
      "buy ANSS\n",
      "sell CBOE\n",
      "buy CCL\n",
      "sell JNPR\n",
      "buy PBCT\n",
      "sell ANSS\n",
      "buy BDX\n",
      "sell CDNS\n",
      "buy QRVO\n",
      "sell ESS\n",
      "buy FTI\n",
      "sell CTXS\n",
      "buy HOLX\n",
      "sell CERN\n",
      "buy ORCL\n",
      "sell KR\n",
      "buy NEE\n",
      "sell CCL\n",
      "buy EXPD\n",
      "sell SPGI\n",
      "buy AOS\n",
      "sell ANSS\n",
      "buy CTAS\n",
      "sell NWSA\n",
      "buy ORCL\n",
      "sell UHS\n",
      "buy AZO\n",
      "sell PDCO\n",
      "buy CTAS\n",
      "sell EQIX\n",
      "buy JBHT\n",
      "sell FISV\n",
      "buy CCL\n",
      "sell FTI\n",
      "buy VNO\n",
      "sell MTD\n",
      "buy ABT\n",
      "sell HST\n",
      "buy INFO\n",
      "sell CDNS\n",
      "Daily mean return:  0.0075484424028850194\n",
      "Sharp ratio:  4.635916472512836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.Performance at 0x7fe8c55ce9a0>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c= 0.0006\n",
    "k= 1\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "result.head()\n",
    "\n",
    "last_symbol = ['1','1']\n",
    "not_trade_set = set({'CHK'}) \n",
    "buy_symbols = []\n",
    "sell_symbols= []\n",
    "#not_trade_set = set()\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    mask = data_training_return['SPY']['Date'] == date     \n",
    "    X_close_open = data_training_return['SPY'][mask]['close_open_return'].iloc[0]\n",
    "    for symbol in list(symbols_set-not_trade_set):\n",
    "         \n",
    "        if symbol not in last_symbol and symbol in sm_reg_map and symbol in sm_reg_map_reverse and symbol !='SPY'and sm_reg_map_reverse[symbol].params[2] < 0:\n",
    "#         and (sm_reg_map_reverse[symbol].tvalues[2] > ):\n",
    "                     #and sm_reg_map_reverse[symbol].params[2] < 0:\n",
    " \n",
    "            try:\n",
    " \n",
    " \n",
    "                mask = data_training_return[symbol]['Date'] == date     \n",
    "                y_close_open = data_training_return[symbol][mask]['close_open_return'].iloc[0]\n",
    "\n",
    "\n",
    "#                 mask = data_training_return['SPY']['Date'] == date     \n",
    "#                 X_close_open = data_training_return['SPY'][mask]['close_open_return'].iloc[0]\n",
    "\n",
    "\n",
    "#                 print(symbol, X_close_open)\n",
    "                #X_close_open= sm.add_constant(X_close_open)\n",
    "                X_close_open1 = np.array([[1,X_close_open]])\n",
    "                pred_close_open = sm_reg_map[symbol].predict(X_close_open1)\n",
    "\n",
    "                error_close_open = y_close_open-pred_close_open\n",
    "\n",
    "                X = np.array([[1, 0, error_close_open[0]]])\n",
    "\n",
    "                #X  = sm.add_constant(X)\n",
    "                pred = sm_reg_map_reverse[symbol].predict(X)\n",
    "                #print(X, pred)\n",
    "\n",
    "                error_map[pred[0]] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "            last_symbol[0] = symbol\n",
    "            buy_symbols.append(symbol)\n",
    "            print(f\"buy {symbol}\")\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "            last_symbol[1] = symbol\n",
    "            sell_symbols.append(symbol)\n",
    "            print(f\"sell {symbol}\")\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "            \n",
    "\n",
    "pm.Performance(result, c)\n",
    " \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model in sm\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    " \n",
    "X_open_close = data_training_return['SPY']['open_close_return'] \n",
    "X_close_open = data_training_return['SPY']['open_close_return'] \n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "sm_direct_mp = {}\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y_open_close =  data_training_return[symbol][mask]['open_close_return']\n",
    "#         y_open_close = np.expand_dims(y_open_close, axis=1)\n",
    "        y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "        y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "        \n",
    "        if len(y_close_open) >0:\n",
    " \n",
    "            X = sm.add_constant(y_close_open)\n",
    "            X  = sm.add_constant(X)\n",
    "            model = sm.OLS(y_open_close,X)\n",
    "            results = model.fit()\n",
    "            sm_direct_mp[symbol] = results\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.0014219780221216445\n",
      "Sharp ratio:  2.577145356688219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.Performance at 0x7faa4aa3ef10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c= 0.0006\n",
    "k= 10\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "result.head()\n",
    "\n",
    "last_symbol = ['1','1']\n",
    "not_trade_set = set({'CHK'}) \n",
    "buy_symbols = []\n",
    "sell_symbols= []\n",
    "#not_trade_set = set()\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    mask = data_training_return['SPY']['Date'] == date     \n",
    "    X_close_open = data_training_return['SPY'][mask]['close_open_return'].iloc[0]\n",
    "    for symbol in symbols:\n",
    "         \n",
    "        if (\n",
    "            symbol in sm_direct_mp and symbol !='SPY'and \n",
    "            sm_direct_mp[symbol].params[1] < 0\n",
    "        ):\n",
    " \n",
    " \n",
    "            try:\n",
    " \n",
    " \n",
    "                mask = data_training_return[symbol]['Date'] == date     \n",
    "                y_close_open = data_training_return[symbol][mask]['close_open_return'].iloc[0]\n",
    " \n",
    "\n",
    "                #X  = sm.add_constant(X)\n",
    "                pred = sm_direct_mp[symbol].predict([1, y_close_open])\n",
    "      \n",
    "                error_map[pred[0]] = symbol\n",
    "            except:\n",
    "                pass\n",
    "    error_list = list(error_map.items())\n",
    "    error_list.sort()\n",
    " \n",
    " \n",
    " \n",
    "    for j in range(k):\n",
    "        if j< len(error_list):   \n",
    "            symbol = error_list[j][1]\n",
    "\n",
    "            buy_symbols.append(symbol)\n",
    "\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "            \n",
    "            symbol = error_list[-j-1][1]\n",
    "\n",
    "            sell_symbols.append(symbol)\n",
    "\n",
    "            mask = data_training_return[symbol]['Date'] == date\n",
    "            result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['open_close_return'].to_numpy()[0] \n",
    "\n",
    "            \n",
    "\n",
    "pm.Performance(result, c)\n",
    " \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(columns=['symbol','const','x1','x2'])\n",
    "\n",
    "for symbol  in sm_reg_map_reverse:\n",
    "    params = sm_reg_map_reverse[symbol].params.to_list()\n",
    "    print([symbol ]+params)\n",
    "    #{'symbol': symbol, 'const':params[0],'x1':params[1],'x2':params[2]}\n",
    "    a_series = pd.Series([symbol ]+params, index = df_params.columns)\n",
    "    df_params = df_params.append(a_series, ignore_index=True)\n",
    "    #df_params.append([symbol ]+params, ignore_index=True)\n",
    "\n",
    "df_params.to_csv('params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328918322295805"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(sm_reg_map_reverse)\n",
    "c = 0\n",
    "for key, value in sm_reg_map_reverse.items():\n",
    "    if value.params[2]<0:\n",
    "        c += 1\n",
    "c/l\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trade at Close(open close error as regressor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87633934 -0.03968184]]\n",
      "[[1.20186789 0.02018615]]\n",
      "[[0.89871129 0.11020738]]\n",
      "[[0.9412648  0.02656301]]\n",
      "[[1.00942267 0.04549461]]\n",
      "[[ 1.31440331 -0.02069873]]\n",
      "[[ 1.13812032 -0.09489471]]\n",
      "[[1.21766337 0.05103626]]\n",
      "[[0.79390771 0.03257613]]\n",
      "[[ 1.87635525 -0.03937646]]\n",
      "[[0.65856373 0.01670917]]\n",
      "[[ 1.40667812 -0.04010685]]\n",
      "[[ 0.92218792 -0.03010474]]\n",
      "[[1.12514427 0.08901187]]\n",
      "[[0.93258187 0.06554611]]\n",
      "[[1.05797977 0.07961114]]\n",
      "[[ 0.97789008 -0.02376775]]\n",
      "[[ 1.17862203 -0.03620403]]\n",
      "[[0.52694646 0.0042412 ]]\n",
      "[[1.09886982 0.05027293]]\n",
      "[[ 1.17751209 -0.08241091]]\n",
      "[[ 0.91498046 -0.02096731]]\n",
      "[[1.02736076 0.04500753]]\n",
      "[[0.2194318  0.01877074]]\n",
      "[[ 0.74568733 -0.01428044]]\n",
      "[[ 1.1856343  -0.00453171]]\n",
      "[[1.19146264 0.0154215 ]]\n",
      "[[ 0.66754668 -0.0844241 ]]\n",
      "[[1.36654121 0.08950003]]\n",
      "[[0.23248536 0.0229671 ]]\n",
      "[[ 1.27155955 -0.03676953]]\n",
      "[[0.21354501 0.02813489]]\n",
      "[[ 0.91483252 -0.0396084 ]]\n",
      "[[ 1.13782097 -0.0202112 ]]\n",
      "[[0.59833729 0.05206952]]\n",
      "[[0.26393502 0.01378676]]\n",
      "[[ 1.27234965 -0.05771015]]\n",
      "[[0.77811097 0.03237747]]\n",
      "[[1.104159   0.05515931]]\n",
      "[[0.90665148 0.00286883]]\n",
      "[[ 1.08374652e+00 -4.63066861e-04]]\n",
      "[[ 1.26237736 -0.03988509]]\n",
      "[[ 1.01504292 -0.04251216]]\n",
      "[[0.79430532 0.04341334]]\n",
      "[[0.8138934  0.06265867]]\n",
      "[[ 1.41218204 -0.02307504]]\n",
      "[[ 0.50823271 -0.06140016]]\n",
      "[[ 1.34563686 -0.06525385]]\n",
      "[[ 1.34561734 -0.03809986]]\n",
      "[[ 1.3769507  -0.00395235]]\n",
      "[[0.81285084 0.00188311]]\n",
      "[[ 0.80537914 -0.00551106]]\n",
      "[[ 0.80853316 -0.02029145]]\n",
      "[[ 0.59398851 -0.03270526]]\n",
      "[[ 1.30598787 -0.00648519]]\n",
      "[[ 0.98578413 -0.04412734]]\n",
      "[[ 0.69404006 -0.07518606]]\n",
      "[[ 0.41913844 -0.01271373]]\n",
      "[[0.9681108  0.02949889]]\n",
      "[[0.95355163 0.02965152]]\n",
      "[[ 1.47269016 -0.12722775]]\n",
      "[[0.76813302 0.03287774]]\n",
      "[[ 7.58847472e-01 -1.20540673e-04]]\n",
      "[[1.09261486 0.09051489]]\n",
      "[[1.03603778 0.02009927]]\n",
      "[[ 1.26979045 -0.01827489]]\n",
      "[[0.77397481 0.02348298]]\n",
      "[[ 1.23701367 -0.03137238]]\n",
      "[[ 1.41719179 -0.04639574]]\n",
      "[[0.53021149 0.03529092]]\n",
      "[[ 0.9255317  -0.01056826]]\n",
      "[[0.74733603 0.06550465]]\n",
      "[[1.48263179 0.01646171]]\n",
      "[[ 0.78076309 -0.0013683 ]]\n",
      "[[1.05040964 0.00967651]]\n",
      "[[ 0.98123772 -0.01643505]]\n",
      "[[ 0.4529625  -0.00372895]]\n",
      "[[1.23096441 0.04081737]]\n",
      "[[0.87049115 0.07338739]]\n",
      "[[1.05720518 0.00737255]]\n",
      "[[1.02625923 0.12718636]]\n",
      "[[ 1.40889759 -0.01978503]]\n",
      "[[ 0.53691789 -0.05699376]]\n",
      "[[1.03237358 0.01499707]]\n",
      "[[0.40861261 0.00264014]]\n",
      "[[0.84544504 0.02100935]]\n",
      "[[ 0.88625158 -0.04853896]]\n",
      "[[ 1.24182073 -0.01681168]]\n",
      "[[ 1.56524611 -0.00738774]]\n",
      "[[ 0.828783   -0.08537772]]\n",
      "[[2.19085    0.00382607]]\n",
      "[[ 0.97993858 -0.07028052]]\n",
      "[[ 0.71220461 -0.03483804]]\n",
      "[[ 0.75060471 -0.0784135 ]]\n",
      "[[0.48834066 0.03638977]]\n",
      "[[ 0.84858439 -0.03552249]]\n",
      "[[ 1.32157214 -0.04825949]]\n",
      "[[ 0.81336553 -0.04299587]]\n",
      "[[0.84711532 0.10995459]]\n",
      "[[1.0672979  0.10114249]]\n",
      "[[ 1.5702916  -0.12862911]]\n",
      "[[ 1.2568153  -0.02939413]]\n",
      "[[1.04281177 0.06347346]]\n",
      "[[ 0.73148606 -0.01687932]]\n",
      "[[ 0.21121323 -0.0107778 ]]\n",
      "[[0.51663625 0.03010044]]\n",
      "[[ 1.07146066 -0.13295445]]\n",
      "[[0.59028635 0.04189321]]\n",
      "[[0.91229273 0.01032327]]\n",
      "[[ 1.2929606  -0.02698733]]\n",
      "[[ 0.53961679 -0.00340043]]\n",
      "[[ 1.40027581 -0.02411358]]\n",
      "[[ 1.32923842 -0.05174993]]\n",
      "[[0.1622045  0.05137131]]\n",
      "[[0.74741168 0.01308043]]\n",
      "[[1.15681505 0.02541624]]\n",
      "[[0.73466124 0.03591155]]\n",
      "[[ 0.67290525 -0.02574499]]\n",
      "[[ 0.51203738 -0.04450947]]\n",
      "[[ 1.17025981 -0.0119614 ]]\n",
      "[[1.13896685 0.03586765]]\n",
      "[[0.87892697 0.00262513]]\n",
      "[[ 1.04287654 -0.01813919]]\n",
      "[[0.85849076 0.04008008]]\n",
      "[[0.70229512 0.05829814]]\n",
      "[[0.72380267 0.00831109]]\n",
      "[[ 1.19066377 -0.0300285 ]]\n",
      "[[ 1.11733136 -0.09195893]]\n",
      "[[ 0.75991983 -0.01307754]]\n",
      "[[ 1.56105611 -0.09945808]]\n",
      "[[ 0.47516074 -0.00861988]]\n",
      "[[ 1.07709524 -0.05017741]]\n",
      "[[0.93764396 0.03675253]]\n",
      "[[0.88286873 0.0410508 ]]\n",
      "[[ 1.0255831  -0.00690055]]\n",
      "[[ 0.8705577  -0.05778158]]\n",
      "[[0.95393133 0.00969342]]\n",
      "[[0.23614481 0.09106887]]\n",
      "[[ 1.10273686e+00 -1.09475931e-03]]\n",
      "[[0.20873346 0.0393076 ]]\n",
      "[[0.206015   0.06120847]]\n",
      "[[ 0.68730102 -0.03182801]]\n",
      "[[1.06506461 0.05153983]]\n",
      "[[ 1.46600483 -0.0359972 ]]\n",
      "[[1.22549102 0.05678937]]\n",
      "[[1.24248174 0.01243303]]\n",
      "[[0.98897264 0.01935278]]\n",
      "[[8.55843589e-01 9.49780418e-05]]\n",
      "[[0.20965699 0.07581115]]\n",
      "[[ 0.86196933 -0.01903191]]\n",
      "[[ 1.14553481 -0.01852374]]\n",
      "[[1.12053561 0.01693015]]\n",
      "[[0.23467721 0.02131863]]\n",
      "[[ 1.25136065 -0.03347067]]\n",
      "[[1.0729496  0.00963666]]\n",
      "[[ 0.81902443 -0.01169124]]\n",
      "[[ 0.66222485 -0.03995369]]\n",
      "[[ 0.4828098  -0.01425062]]\n",
      "[[ 0.38714082 -0.01652808]]\n",
      "[[0.90282751 0.01869691]]\n",
      "[[ 0.62759824 -0.084767  ]]\n",
      "[[ 0.22977693 -0.01945883]]\n",
      "[[0.32425756 0.04760578]]\n",
      "[[ 0.99396436 -0.00470417]]\n",
      "[[0.9846038  0.10198584]]\n",
      "[[ 0.44099796 -0.0017436 ]]\n",
      "[[ 0.93206102 -0.00603565]]\n",
      "[[1.02811458 0.0363069 ]]\n",
      "[[ 1.37815122 -0.10082451]]\n",
      "[[ 0.96756654 -0.00718434]]\n",
      "[[0.4596066  0.01215912]]\n",
      "[[ 1.08654297 -0.02852626]]\n",
      "[[ 0.87505732 -0.07367351]]\n",
      "[[ 1.2280742  -0.00584288]]\n",
      "[[0.32229906 0.01632596]]\n",
      "[[0.91579961 0.0238972 ]]\n",
      "[[ 0.93781191 -0.04678499]]\n",
      "[[ 1.23287249 -0.02947126]]\n",
      "[[ 1.31657    -0.01156999]]\n",
      "[[ 1.10809173 -0.02806858]]\n",
      "[[ 0.94999711 -0.02224939]]\n",
      "[[1.15035152 0.03193265]]\n",
      "[[1.12892229 0.02182206]]\n",
      "[[ 1.31336280e+00 -1.16482394e-03]]\n",
      "[[ 2.1263458  -0.05270657]]\n",
      "[[0.94145718 0.0522577 ]]\n",
      "[[0.90380374 0.08585173]]\n",
      "[[0.92197754 0.02130653]]\n",
      "[[0.87609877 0.00313618]]\n",
      "[[ 1.04083998 -0.032611  ]]\n",
      "[[0.4803131  0.02555242]]\n",
      "[[ 1.19697753 -0.04141421]]\n",
      "[[ 0.791005   -0.04099341]]\n",
      "[[ 0.96230549 -0.01144029]]\n",
      "[[1.04493283 0.00900042]]\n",
      "[[ 1.272631  -0.0074009]]\n",
      "[[1.17685661 0.00686171]]\n",
      "[[ 0.84872864 -0.04762646]]\n",
      "[[ 1.32875485 -0.01498069]]\n",
      "[[ 0.95869757 -0.03854133]]\n",
      "[[1.13295345 0.08374938]]\n",
      "[[ 1.07209626 -0.00566174]]\n",
      "[[0.89770383 0.0553533 ]]\n",
      "[[ 0.84936522 -0.05434506]]\n",
      "[[ 1.4210225  -0.08855409]]\n",
      "[[0.77057859 0.06862132]]\n",
      "[[ 1.51569545 -0.07454298]]\n",
      "[[1.06124262 0.04437375]]\n",
      "[[0.83347203 0.04378091]]\n",
      "[[0.8818252  0.00145462]]\n",
      "[[1.02383135 0.0381136 ]]\n",
      "[[0.52158721 0.00193498]]\n",
      "[[ 0.89810093 -0.01575664]]\n",
      "[[1.19113813 0.07736262]]\n",
      "[[ 0.65373158 -0.0081596 ]]\n",
      "[[ 1.14187878 -0.0297339 ]]\n",
      "[[ 0.8881748  -0.03322149]]\n",
      "[[ 0.8790242 -0.0771094]]\n",
      "[[0.65406901 0.11606853]]\n",
      "[[1.0441287  0.08431057]]\n",
      "[[1.1155269  0.01753216]]\n",
      "[[1.32129451 0.00651421]]\n",
      "[[1.19456659 0.0307719 ]]\n",
      "[[ 0.79239469 -0.00713333]]\n",
      "[[0.86513834 0.06070957]]\n",
      "[[ 1.04168958 -0.00149616]]\n",
      "[[ 0.95566648 -0.00441193]]\n",
      "[[0.85791817 0.03733541]]\n",
      "[[1.17437018 0.03156394]]\n",
      "[[0.93472827 0.05565221]]\n",
      "[[ 1.44479202 -0.0628908 ]]\n",
      "[[ 0.83271357 -0.05493088]]\n",
      "[[0.62163842 0.02055786]]\n",
      "[[ 0.86341582 -0.04103259]]\n",
      "[[ 0.45232149 -0.00114114]]\n",
      "[[0.62677002 0.0074082 ]]\n",
      "[[ 0.918013   -0.00392794]]\n",
      "[[1.28783814 0.00359602]]\n",
      "[[0.92070224 0.06590373]]\n",
      "[[1.11940728 0.04586109]]\n",
      "[[0.44355185 0.03976794]]\n",
      "[[ 1.27370301 -0.04914617]]\n",
      "[[0.54200374 0.02132284]]\n",
      "[[ 0.51820124 -0.01414906]]\n",
      "[[ 1.14938467 -0.06071782]]\n",
      "[[1.21668293 0.02672605]]\n",
      "[[ 0.95108316 -0.00588041]]\n",
      "[[ 0.87293983 -0.25228124]]\n",
      "[[ 0.88067427 -0.00714763]]\n",
      "[[ 0.71808617 -0.00682967]]\n",
      "[[ 1.46747662 -0.05155395]]\n",
      "[[0.92808518 0.04021588]]\n",
      "[[ 0.99994511 -0.01200797]]\n",
      "[[ 0.65879602 -0.0457649 ]]\n",
      "[[ 1.59019458 -0.01261381]]\n",
      "[[0.98584728 0.07855668]]\n",
      "[[ 0.78602561 -0.01793237]]\n",
      "[[ 0.94275468 -0.02153779]]\n",
      "[[0.96611898 0.03722068]]\n",
      "[[1.33721708 0.05421492]]\n",
      "[[1.0683582  0.02752633]]\n",
      "[[ 0.65094046 -0.0155504 ]]\n",
      "[[1.02012118 0.0261554 ]]\n",
      "[[ 1.77523119 -0.08978012]]\n",
      "[[1.22895859 0.04367805]]\n",
      "[[1.024609   0.06740212]]\n",
      "[[ 0.86099517 -0.04420287]]\n",
      "[[ 0.9536702  -0.01032035]]\n",
      "[[ 1.0536379  -0.03517649]]\n",
      "[[1.15606263 0.00513401]]\n",
      "[[0.81272704 0.01727342]]\n",
      "[[ 0.48672043 -0.02546216]]\n",
      "[[0.65416898 0.08021258]]\n",
      "[[0.77617166 0.01059431]]\n",
      "[[0.83658102 0.05946289]]\n",
      "[[0.77580667 0.05651888]]\n",
      "[[1.37016832 0.0170043 ]]\n",
      "[[0.97644654 0.01388447]]\n",
      "[[ 1.46160201 -0.04633262]]\n",
      "[[1.33480342 0.00867726]]\n",
      "[[ 1.82080551 -0.10192682]]\n",
      "[[1.24689472 0.11133619]]\n",
      "[[ 0.43047468 -0.00714792]]\n",
      "[[ 1.03946237 -0.06367672]]\n",
      "[[ 0.68930507 -0.02038279]]\n",
      "[[0.68790939 0.0787892 ]]\n",
      "[[ 0.72974803 -0.06614971]]\n",
      "[[1.09692502 0.00565541]]\n",
      "[[ 1.58857178 -0.04979664]]\n",
      "[[ 0.73897674 -0.00960189]]\n",
      "[[1.1691751  0.05876986]]\n",
      "[[0.88446749 0.01572978]]\n",
      "[[ 1.28080174 -0.02302687]]\n",
      "[[1.05756084 0.01806231]]\n",
      "[[1.17401338 0.07064121]]\n",
      "[[ 1.71894124 -0.13064913]]\n",
      "[[ 0.98641418 -0.02338206]]\n",
      "[[-0.30492239  0.00148079]]\n",
      "[[0.94800767 0.02379888]]\n",
      "[[0.90758479 0.04368433]]\n",
      "[[0.28173047 0.00664783]]\n",
      "[[0.91472987 0.07417914]]\n",
      "[[1.10328963 0.06965284]]\n",
      "[[0.26677458 0.06088831]]\n",
      "[[ 1.52952749 -0.06007211]]\n",
      "[[ 0.88342163 -0.00349349]]\n",
      "[[1.02653393 0.04355186]]\n",
      "[[ 1.17533105 -0.02386606]]\n",
      "[[ 0.84662607 -0.067812  ]]\n",
      "[[1.05282492 0.04589345]]\n",
      "[[0.78098711 0.02073226]]\n",
      "[[ 1.24371516 -0.03343838]]\n",
      "[[ 1.65994796 -0.04310171]]\n",
      "[[ 0.74251788 -0.04185787]]\n",
      "[[ 1.09764113 -0.02705705]]\n",
      "[[0.80976779 0.00502081]]\n",
      "[[ 1.17883859 -0.01931665]]\n",
      "[[0.97181106 0.07998687]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.15095105 0.01268818]]\n",
      "[[0.93003901 0.00979517]]\n",
      "[[1.12969618e+00 8.20299350e-04]]\n",
      "[[0.72533604 0.06207415]]\n",
      "[[0.90331191 0.01196432]]\n",
      "[[ 1.15813342 -0.04568495]]\n",
      "[[ 0.92672348 -0.04328592]]\n",
      "[[0.55101839 0.08598244]]\n",
      "[[ 1.00349764 -0.051604  ]]\n",
      "[[ 7.84423395e-01 -5.83530074e-04]]\n",
      "[[0.71208081 0.07239722]]\n",
      "[[0.30861491 0.26097271]]\n",
      "[[ 0.52900286 -0.0888156 ]]\n",
      "[[0.96461163 0.00937016]]\n",
      "[[0.17948205 0.03016967]]\n",
      "[[ 1.33490809 -0.03141734]]\n",
      "[[1.10648118 0.00404322]]\n",
      "[[ 1.03077349 -0.01030724]]\n",
      "[[0.94641129 0.05527681]]\n",
      "[[0.3283804  0.04140402]]\n",
      "[[ 1.3488315  -0.04723728]]\n",
      "[[0.61456743 0.06349997]]\n",
      "[[ 0.85215624 -0.01185122]]\n",
      "[[0.70408654 0.02167737]]\n",
      "[[ 1.4187817 -0.0090648]]\n",
      "[[0.26181956 0.02246174]]\n",
      "[[0.36747218 0.06890689]]\n",
      "[[ 1.03862414 -0.03418474]]\n",
      "[[ 1.00264592 -0.00247819]]\n",
      "[[1.44611701e+00 9.31506665e-04]]\n",
      "[[ 1.14793148 -0.21200067]]\n",
      "[[1.12790559 0.0061275 ]]\n",
      "[[0.77604195 0.04010972]]\n",
      "[[ 1.3408859  -0.03036535]]\n",
      "[[ 1.31128872 -0.04497727]]\n",
      "[[0.36932388 0.03850791]]\n",
      "[[0.50443787 0.03952733]]\n",
      "[[ 0.98253225 -0.044861  ]]\n",
      "[[ 1.45723412 -0.05795539]]\n",
      "[[0.62930219 0.01650947]]\n",
      "[[0.75509503 0.03721595]]\n",
      "[[1.13964819 0.06822684]]\n",
      "[[1.14228587 0.04900247]]\n",
      "[[0.94999689 0.03760477]]\n",
      "[[ 0.96611553 -0.00953713]]\n",
      "[[1.17036451 0.01887754]]\n",
      "[[1.07107849 0.04123716]]\n",
      "[[1.28006579 0.05015241]]\n",
      "[[ 0.72904255 -0.00942769]]\n",
      "[[ 1.14438125 -0.0179582 ]]\n",
      "[[1.44829232 0.02957318]]\n",
      "[[ 0.9154693  -0.01479437]]\n",
      "[[0.320706   0.00500861]]\n",
      "[[0.77174775 0.03082082]]\n",
      "[[1.01503863 0.02621049]]\n",
      "[[0.57303203 0.04123282]]\n",
      "[[ 1.5890454  -0.09576701]]\n",
      "[[0.65391888 0.02516614]]\n",
      "[[0.95838406 0.01844298]]\n",
      "[[0.23551938 0.07845874]]\n",
      "[[ 0.96336723 -0.04758087]]\n",
      "[[1.10199551 0.02586355]]\n",
      "[[0.97968015 0.07748697]]\n",
      "[[ 1.35911595 -0.06744891]]\n",
      "[[0.73257787 0.03128145]]\n",
      "[[0.8502429  0.08221674]]\n",
      "[[ 1.27130552e+00 -3.77184898e-04]]\n",
      "[[ 1.03319021 -0.04039789]]\n",
      "[[0.9361904  0.06193814]]\n",
      "[[0.50819291 0.05445951]]\n",
      "[[1.16711398e+00 1.08751866e-03]]\n",
      "[[ 0.980506  -0.0499353]]\n",
      "[[ 0.89086827 -0.01980197]]\n",
      "[[1.07394618 0.0097252 ]]\n",
      "[[1.72003116 0.02803872]]\n",
      "[[ 1.1965978  -0.03702365]]\n",
      "[[ 1.22359752 -0.00346127]]\n",
      "[[ 1.22973001 -0.01353095]]\n",
      "[[0.41691107 0.01951941]]\n",
      "[[ 0.69714005 -0.03195929]]\n",
      "[[0.43778213 0.08586533]]\n",
      "[[ 1.14168448 -0.00768157]]\n",
      "[[ 0.80218806 -0.05003762]]\n",
      "[[0.94645673 0.00610835]]\n",
      "[[0.97188218 0.07516572]]\n",
      "[[0.91223821 0.06834907]]\n",
      "[[ 0.88620304 -0.00874462]]\n",
      "[[0.94996121 0.01285289]]\n",
      "[[ 0.98701868 -0.06807589]]\n",
      "[[1.16471963 0.10632412]]\n",
      "[[0.53067918 0.04721514]]\n",
      "[[ 1.09557498 -0.03401627]]\n",
      "[[ 0.6356248  -0.00188457]]\n",
      "[[ 1.02668294 -0.09474373]]\n",
      "[[ 1.16640902 -0.01570731]]\n",
      "[[1.06281665 0.05375818]]\n",
      "[[ 1.10825778 -0.01121769]]\n",
      "[[ 0.86478153 -0.03049559]]\n",
      "[[ 0.82557659 -0.01129225]]\n",
      "[[1.61847217 0.00576912]]\n",
      "[[0.78164186 0.02426844]]\n",
      "[[ 1.33968213 -0.08704394]]\n",
      "[[ 0.9198664  -0.00990734]]\n",
      "[[1.09506479 0.03978959]]\n",
      "[[0.84570172 0.02976569]]\n",
      "[[0.3503151  0.01474112]]\n",
      "[[0.96030472 0.05590764]]\n",
      "[[ 0.80822228 -0.02292449]]\n",
      "[[ 0.51942664 -0.01476696]]\n",
      "[[1.11613389 0.04835673]]\n",
      "[[1.24859078 0.02949613]]\n",
      "[[0.4928291  0.02372951]]\n",
      "[[1.00578305 0.04940428]]\n",
      "[[ 0.70874942 -0.08283728]]\n",
      "[[0.86554757 0.08332619]]\n",
      "[[ 0.64055371 -0.0090636 ]]\n",
      "[[0.87081118 0.05420037]]\n",
      "[[0.17790673 0.03269807]]\n",
      "[[ 1.22616309 -0.04579557]]\n",
      "[[ 1.47191783 -0.08782848]]\n",
      "[[ 0.93256185 -0.01659512]]\n",
      "[[ 0.7436731  -0.02198431]]\n",
      "[[1.04612986 0.05720096]]\n",
      "[[1.27925297 0.08574912]]\n",
      "[[0.81141186 0.03730646]]\n",
      "[[1.5218713  0.01573344]]\n",
      "[[0.22054821 0.0232874 ]]\n",
      "[[ 1.10292317 -0.01642392]]\n",
      "[[1.24839245 0.13921284]]\n",
      "[[1.04870347 0.01320777]]\n",
      "[[0.8692402  0.06411041]]\n",
      "[[0.77274481 0.07613115]]\n",
      "[[1.26207964 0.00851515]]\n",
      "[[0.90009482 0.0318328 ]]\n",
      "[[1.00000000e+00 4.28381481e-18]]\n"
     ]
    }
   ],
   "source": [
    "testing_length = 250\n",
    "training_dates= set(data_training_return['SPY']['Date'][:-testing_length])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dates_X = set(data_training_return['SPY']['Date'] )\n",
    "dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "reg_map_vwap_close_reverse = {}\n",
    "mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "X1 = data_training_return['SPY'][mask]['close_open_return'][1:].to_numpy()\n",
    "X1 = np.expand_dims(X1, axis=1)\n",
    "        \n",
    "X0 = data_training_return['SPY'][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "for symbol in symbols:\n",
    " \n",
    " \n",
    "    \n",
    "        dates_y = set(data_training_return[symbol]['Date'] )\n",
    "        dates = dates_y.intersection(dates_X)\n",
    "        mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "        y1 =  data_training_return[symbol][mask]['close_open_return'][1:].to_numpy()\n",
    "        y1 = np.expand_dims(y1, axis=1)\n",
    "        y0 = data_training_return[symbol][mask]['vwap_close_return'][:-1].to_numpy()\n",
    "        y0 = np.expand_dims(y0, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if symbol in reg_map:\n",
    " \n",
    "            pred = reg_map[symbol].predict(X0)\n",
    "            pred = np.expand_dims(pred, axis=1)\n",
    "            error = y0-pred\n",
    "           # print(X1.shape, y0.shape, y1.shape, error.shape)\n",
    " \n",
    "            X = np.concatenate([X1, error], axis=1)\n",
    "         \n",
    "            #if len(dates_X)>0 and X.shape[0] == len(dates_X):\n",
    "            reg = LinearRegression().fit(X, y1)\n",
    "            reg_map_vwap_close_reverse[symbol] = reg\n",
    "            print(reg.coef_)\n",
    "\n",
    "# reg.score(X, y)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily mean return:  0.0017189087581574352\n",
      "Sharp ratio:  1.670738725561171\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Net Profit   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.1601\n",
      "Date:                Sun, 03 Jan 2021   Prob (F-statistic):              0.689\n",
      "Time:                        20:50:53   Log-Likelihood:                 675.18\n",
      "No. Observations:                 250   AIC:                            -1346.\n",
      "Df Residuals:                     248   BIC:                            -1339.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0015      0.002      0.700      0.485      -0.003       0.006\n",
      "Close       2.949e-05   7.37e-05      0.400      0.689      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      229.482   Durbin-Watson:                   1.795\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7670.728\n",
      "Skew:                           3.443   Prob(JB):                         0.00\n",
      "Kurtosis:                      29.249   Cond. No.                         63.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.performance_metrics.VIX at 0x7fcf928fc640>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 0.0003\n",
    "result = pd.DataFrame({'Date': testing_dates, 'Net Profit':0})\n",
    "k= 1\n",
    "\n",
    "testing_dates = list(data_training_return['SPY']['Date'][-testing_length:])\n",
    "for index, date in enumerate(testing_dates):\n",
    "    error_map = {}\n",
    "    if index+1 <len(testing_dates):\n",
    "        for symbol in symbols:\n",
    "\n",
    "\n",
    "            if symbol in reg_map and symbol in reg_map_vwap_close_reverse and symbol !='SPY' and reg_map_vwap_close_reverse[symbol].coef_[0][1]<0:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #             try:\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date     \n",
    " \n",
    " \n",
    "                y0 = data_training_return[symbol][mask]['vwap_close_return'].to_numpy()\n",
    "                y0 = np.expand_dims(y0, axis=1)\n",
    "        \n",
    "        \n",
    "                mask = data_training_return['SPY']['Date'] == date     \n",
    "                X0 = data_training_return['SPY'][mask]['vwap_close_return'] \n",
    "                X0 = np.expand_dims(X0, axis=1)\n",
    "\n",
    "                X1 =  np.zeros([len(X0),1])\n",
    "                #print(X1.shape, y0.shape)\n",
    "                if X1.shape == y0.shape:\n",
    "\n",
    "                    pred0  = reg_map[symbol].predict(X0)\n",
    "                    pred0  = np.expand_dims(pred0, axis=1)\n",
    "                    error = y0-pred0\n",
    "                    #print(\"pred0 shape\", pred0.shape)\n",
    "                    X = np.concatenate([X1, error], axis=1)\n",
    "\n",
    "                    pred = reg_map_vwap_close_reverse[symbol].predict(X)\n",
    "                    #print(\"pred .shape\", pred.shape)\n",
    "\n",
    "                    error_map[pred[0][0]] = symbol\n",
    "    #             except:\n",
    "    #                 pass\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range(k):\n",
    "            if j< len(error_list) and index <len(testing_dates) -1:   \n",
    "                symbol = error_list[j][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                #Here use the previouse date for the return from close to open for conevnience of VIX calculation\n",
    "                result.loc[result['Date']==date, 'Net Profit'] -= (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                symbol = error_list[-j-1][1]\n",
    "                mask = data_training_return[symbol]['Date'] == testing_dates[index+1]\n",
    "                result.loc[result['Date']==date, 'Net Profit'] += (1/(2*k))*data_training_return[symbol][mask]['close_open_return'].to_numpy()[0] \n",
    "\n",
    "                \n",
    "\n",
    "pm.Performance(result, c)\n",
    "pm.VIX(result, 'Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03968184474390066"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_map_vwap_close_reverse[symbol].coef_[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.63596469]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.datasets import make_regression\n",
    "# X, y = make_regression(n_features=4, n_informative=2,\n",
    "#                        random_state=0, shuffle=False)\n",
    "# regr = RandomForestRegressor(n_estimators=1000,max_depth=100, criterion='mae',random_state=0)\n",
    "# regr.fit(X, y)\n",
    "\n",
    "# print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYPL 2015-02-27T00:00:00.000000000\n",
      "FTV 2015-02-27T00:00:00.000000000\n",
      "HPE 2015-02-27T00:00:00.000000000\n",
      "ARNC 2015-02-27T00:00:00.000000000\n",
      "PX 2015-02-27T00:00:00.000000000\n",
      "UA 2015-02-27T00:00:00.000000000\n",
      "BHF 2015-02-27T00:00:00.000000000\n",
      "IR 2015-02-27T00:00:00.000000000\n",
      "CSRA 2015-02-27T00:00:00.000000000\n",
      "KHC 2015-02-27T00:00:00.000000000\n",
      "FOXA 2015-02-27T00:00:00.000000000\n",
      "FOX 2015-02-27T00:00:00.000000000\n",
      "SCG 2015-02-27T00:00:00.000000000\n",
      "WRK 2015-02-27T00:00:00.000000000\n",
      "PYPL 2015-03-02T00:00:00.000000000\n",
      "FTV 2015-03-02T00:00:00.000000000\n",
      "HPE 2015-03-02T00:00:00.000000000\n",
      "ARNC 2015-03-02T00:00:00.000000000\n",
      "PX 2015-03-02T00:00:00.000000000\n",
      "UA 2015-03-02T00:00:00.000000000\n",
      "BHF 2015-03-02T00:00:00.000000000\n",
      "IR 2015-03-02T00:00:00.000000000\n",
      "CSRA 2015-03-02T00:00:00.000000000\n",
      "KHC 2015-03-02T00:00:00.000000000\n",
      "FOXA 2015-03-02T00:00:00.000000000\n",
      "FOX 2015-03-02T00:00:00.000000000\n",
      "SCG 2015-03-02T00:00:00.000000000\n",
      "WRK 2015-03-02T00:00:00.000000000\n",
      "PYPL 2015-03-03T00:00:00.000000000\n",
      "FTV 2015-03-03T00:00:00.000000000\n",
      "(760, 349) (760,)\n"
     ]
    }
   ],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "c = 0\n",
    "for index, date in enumerate(dates[:-testing_length]):\n",
    "    if c>=1000:\n",
    "        break\n",
    "    if index>=history-1:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "             \n",
    " \n",
    "        if data_training[mask]['Open'].to_numpy()[0]:\n",
    "            sample_spy.append(data_training[mask]['Open'].to_numpy()[0])  \n",
    "            for symbol in symbols:\n",
    "                c +=1\n",
    "                if c>=1000:\n",
    "                    break\n",
    "                try:\n",
    "                    sample = []\n",
    "                    mask = data_training['Symbol'] == symbol\n",
    "                    mask &= data_training['Date']<date\n",
    "                    mask &= data_training['Date']>= dates[index-history+1]\n",
    "                    sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                    sample +=sample_spy\n",
    "\n",
    "\n",
    "\n",
    "                    mask = data_training_return[symbol]['Date'] == date\n",
    "\n",
    "                    r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                    if sample and r:\n",
    "                        X.append(sample)\n",
    "                        y.append(r)\n",
    "\n",
    "                except:\n",
    "                    print(symbol, date)\n",
    "    #                 print(data_training_return[symbol]['Date'] )\n",
    "    #                 raise\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 30\n",
    "testing_length=250\n",
    "k=5\n",
    "X=[]\n",
    "y=[]\n",
    "dates = list(data_training['Date'].unique())\n",
    "dates.sort()\n",
    "symbols = set(data_training['Symbol'].unique())\n",
    "result = np.zeros(testing_length)\n",
    "print(len(dates))\n",
    "for index, date in enumerate(dates ):\n",
    " \n",
    "    if index>=len(dates)-testing_length:\n",
    "         \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']<date \n",
    "        mask &= data_training['Date']>= dates[index-history+1]\n",
    "                                                    \n",
    "        sample_spy = list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    " \n",
    "        mask = data_training['Symbol'] == 'SPY'\n",
    "        mask &= data_training['Date']== date \n",
    "    \n",
    "        sample_spy.append(data_training[mask]['Open'].to_numpy()[0]) \n",
    "        print(sample_spy)\n",
    "        symbol_return = {}\n",
    "        symbol_pred_return = {}\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                sample = []\n",
    "                mask = data_training['Symbol'] == symbol\n",
    "                mask &= data_training['Date']<date\n",
    "                mask &= data_training['Date']>= dates[index-history+1]\n",
    "                sample += list(data_training[mask][['Open','High','Low','Close','Adj Close', 'Volume']].to_numpy().flat)\n",
    "                sample +=sample_spy\n",
    "                \n",
    "\n",
    "\n",
    "                mask = data_training_return[symbol]['Date'] == date\n",
    "         \n",
    "                r = data_training_return[symbol][mask]['close_open_return'].to_numpy()[0]\n",
    "                if sample and r:\n",
    "                    X.append(sample)\n",
    "                    symbol_pred_return[symbol] = regr.predict(X)\n",
    "                    symbol_return[symbol] = r \n",
    "                \n",
    "            except:\n",
    "                print(\"Error\", symbol, date)\n",
    "#                 print(data_training_return[symbol]['Date'] )\n",
    "#                 raise\n",
    "        error_map = {}\n",
    "        for symbol in  symbol_return:\n",
    "            error_map[symbol] = symbol_return[symbol] - symbol_pred_return[symbol]\n",
    "        error_list = list(error_map.items())\n",
    "        error_list.sort()\n",
    "       # print(error_list)\n",
    "        if len(error_list)>=k:\n",
    "            for j in range(k): \n",
    "                symbol = error_list[j][1]\n",
    "                print(symbol)\n",
    "                result[index-len(dates)+testing_length] +=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "                symbol = error_list[-j-1][1]\n",
    "                result[index-len(dates)+testing_length] -=(1/(2*k)*data_training[symbol]['open_close_return']\n",
    "    X=np.array(X)\n",
    "y=np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "Performance(result, c)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>const</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>-2.793105e-04</td>\n",
       "      <td>0.915876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>2.175853e-04</td>\n",
       "      <td>0.899833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>3.341339e-04</td>\n",
       "      <td>0.976538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>3.973506e-05</td>\n",
       "      <td>0.853877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>3.159727e-04</td>\n",
       "      <td>1.064565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>YUM</td>\n",
       "      <td>1.591667e-04</td>\n",
       "      <td>0.888290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>-1.308196e-04</td>\n",
       "      <td>0.946650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>ZION</td>\n",
       "      <td>-1.501804e-04</td>\n",
       "      <td>1.121337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>6.610236e-04</td>\n",
       "      <td>0.962055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>SPY</td>\n",
       "      <td>3.388132e-20</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol         const        x1\n",
       "0      MMM -2.793105e-04  0.915876\n",
       "1      AOS  2.175853e-04  0.899833\n",
       "2      ABT  3.341339e-04  0.976538\n",
       "3     ABBV  3.973506e-05  0.853877\n",
       "4      ACN  3.159727e-04  1.064565\n",
       "..     ...           ...       ...\n",
       "447    YUM  1.591667e-04  0.888290\n",
       "448    ZBH -1.308196e-04  0.946650\n",
       "449   ZION -1.501804e-04  1.121337\n",
       "450    ZTS  6.610236e-04  0.962055\n",
       "451    SPY  3.388132e-20  1.000000\n",
       "\n",
       "[452 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_training_data(start_date):\n",
    "    mask = data_all['Date'] >= start_date\n",
    "    data_training= data_all[mask]\n",
    "    return data_training\n",
    "\n",
    "data_training_de = get_training_data('20170101')\n",
    "\n",
    "def get_return_data(data_training):\n",
    "    data_training_return = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    "    #     print(symbol)\n",
    "        mask = data_training['Symbol'] == symbol\n",
    "        data_training_return[symbol] = pd.DataFrame({})\n",
    "        data_training_return[symbol]['Date'] = data_training[mask]['Date']\n",
    "\n",
    "        data_training_return[symbol]['close_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Close'].shift(1))-1  \n",
    "        data_training_return[symbol]['open_close_return']  = data_training[mask]['Close'].div(data_training[mask]['Open'] )-1\n",
    "        data_training_return[symbol]['close_open_return']  = data_training[mask]['Open'].div(data_training[mask]['Close'].shift(1) )-1\n",
    "        data_training_return[symbol]['vwap_open_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open'].shift(1)+ \\\n",
    "                                                                                            data_training[mask]['High'].shift(1)+ \\\n",
    "                                                                                            data_training[mask]['Low'].shift(1)+ \\\n",
    "                                                                                            data_training[mask]['Close'].shift(1))-1\n",
    "\n",
    "        data_training_return[symbol]['vwap_close_return']  = 4*data_training[mask]['Open'].div(data_training[mask]['Open']+ \\\n",
    "                                                                                            data_training[mask]['High']+ \\\n",
    "                                                                                            data_training[mask]['Low']+ \\\n",
    "                                                                                            data_training[mask]['Close'])-1\n",
    "\n",
    "\n",
    "        data_training_return[symbol].fillna(0, inplace=True)\n",
    "        data_training_return[symbol].reset_index(inplace=True,drop=True)\n",
    "    return data_training_return\n",
    "\n",
    "data_training_de = get_return_data(data_training_de)\n",
    "\n",
    "\n",
    "#model in sm\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "def train_model(data_training):\n",
    " \n",
    "    training_dates= set(data_training_return['SPY']['Date'])\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    X = data_training_return['SPY']['close_close_return'] \n",
    "    dates_X = set(data_training_return['SPY']['Date'] )\n",
    "    dates_X = dates_X.intersection(training_dates)\n",
    "\n",
    "    sm_reg_map = {}\n",
    "    for symbol in symbols:\n",
    "\n",
    "\n",
    "\n",
    "            dates_y = set(data_training_return[symbol]['Date'] )\n",
    "            dates = dates_y.intersection(dates_X)\n",
    "            mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "            y =  data_training_return[symbol][mask]['close_close_return'] \n",
    "\n",
    "            mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "            X_here = data_training_return['SPY'][mask]['close_close_return'] \n",
    "            X_here = np.expand_dims(X_here, axis=1)\n",
    "           # print(X_here.shape, y.shape, symbol)\n",
    "            if X_here.shape[0] == len(dates_X):\n",
    "                X_here = sm.add_constant(X_here)\n",
    "               # print(X_here)\n",
    "                model = sm.OLS(y,X_here)#,M=sm.robust.norms.TrimmedMean())\n",
    "                results = model.fit()\n",
    "    #             print(results.params[0])\n",
    "                sm_reg_map[symbol] = results\n",
    "\n",
    " \n",
    "\n",
    "    sm_reg_map_reverse = {}\n",
    "    for symbol in symbols:\n",
    "\n",
    "\n",
    "\n",
    "            dates_y = set(data_training_return[symbol]['Date'] )\n",
    "            dates = dates_y.intersection(dates_X)\n",
    "            mask = data_training_return[symbol]['Date'].isin(dates)\n",
    "            y_open_close =  data_training_return[symbol][mask]['open_close_return']\n",
    "    #         y_open_close = np.expand_dims(y_open_close, axis=1)\n",
    "            y_close_open = data_training_return[symbol][mask]['close_open_return']\n",
    "            y_close_open = np.expand_dims(y_close_open, axis=1)\n",
    "\n",
    "            mask = data_training_return['SPY']['Date'].isin(dates)\n",
    "            X_open_close = data_training_return['SPY'][mask]['open_close_return'] \n",
    "            X_open_close = np.expand_dims(X_open_close, axis=1)\n",
    "\n",
    "            X_close_open = data_training_return['SPY'][mask]['close_open_return'] \n",
    "            X_close_open = np.expand_dims(X_close_open, axis=1)\n",
    "\n",
    "            if symbol in sm_reg_map:\n",
    "\n",
    "                X_close_open = sm.add_constant(X_close_open)\n",
    "                pred_close_open = sm_reg_map[symbol].predict(X_close_open)\n",
    "                pred_close_open = np.expand_dims(pred_close_open, axis=1)\n",
    "                error_close_open = y_close_open-pred_close_open\n",
    "\n",
    "                X = np.concatenate([X_open_close, error_close_open], axis=1)\n",
    "\n",
    "                if len(X)>0 and X.shape[0] == len(y_open_close):\n",
    "\n",
    "                    X  = sm.add_constant(X)\n",
    "                    model = sm.OLS(y_open_close,X)\n",
    "                    results = model.fit()\n",
    "                    sm_reg_map_reverse[symbol] = results\n",
    "    return sm_reg_map, sm_reg_map_reverse\n",
    "\n",
    "sm_reg_map_de, sm_reg_mp_reverse_de = train_model(data_training_de)\n",
    "\n",
    "def save0(models):\n",
    "    df_params = pd.DataFrame(columns=['symbol','const','x1'])\n",
    "\n",
    "    for symbol  in models:\n",
    "        params = models[symbol].params.to_list()    \n",
    " \n",
    " \n",
    "        a_series = pd.Series([symbol ]+params, index = df_params.columns)\n",
    "        df_params = df_params.append(a_series, ignore_index=True)\n",
    "    df_params.to_csv('params0.csv', index=False)\n",
    "\n",
    "def save(models):\n",
    "    df_params = pd.DataFrame(columns=['symbol','const','x1','x2'])\n",
    "\n",
    "    for symbol  in models:\n",
    "        params = models[symbol].params.to_list()    \n",
    "        #{'symbol': symbol, 'const':params[0],'x1':params[1],'x2':params[2]}\n",
    "        if params[2]<0:\n",
    "            a_series = pd.Series([symbol ]+params, index = df_params.columns)\n",
    "            df_params = df_params.append(a_series, ignore_index=True)\n",
    "    df_params.to_csv('params.csv', index=False)\n",
    "\n",
    "save0(sm_reg_map_de)\n",
    "save(sm_reg_mp_reverse_de)\n",
    "\n",
    "df=pd.read_csv('params0.csv')\n",
    "df\n",
    "\n",
    "# Save close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_close(data_all, date):\n",
    "    dates=list(data_all.Date.unique())\n",
    "    dates.sort()\n",
    "    df_y= data_all[data_all.Date == date].reset_index(drop=True)\n",
    "    df_y = df_y[['Symbol', 'Close']]\n",
    "    df_y.columns =  df_y.columns.str.lower()\n",
    "    df_y.to_csv(f'close_{date}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_close(data_all, '20210120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
